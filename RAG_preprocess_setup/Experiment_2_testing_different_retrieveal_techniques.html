<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>5f5e2efd5c3c4bdfb797f93d59dbb48a</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div id="ba88f19e" class="cell code">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">### Experiment 2: Exploring Different Embedding Models and Retrieval Techniques</span></span></code></pre></div>
</div>
<div id="dadaff4d" class="cell code" data-execution_count="1">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install sentence_transformers pandas numpy tqdm</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Collecting sentence_transformers
  Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 345.7/345.7 KB 3.9 MB/s eta 0:00:00a 0:00:01
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 68.3 MB/s eta 0:00:0000:0100:01
py
  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.8/16.8 MB 61.8 MB/s eta 0:00:0000:0100:01

  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 KB 3.1 MB/s eta 0:00:00
ent already satisfied: typing_extensions&gt;=4.5.0 in ./test_env/lib/python3.10/site-packages (from sentence_transformers) (4.13.2)
Collecting transformers&lt;5.0.0,&gt;=4.41.0
  Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.5/10.5 MB 75.2 MB/s eta 0:00:0000:0100:01
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.7/37.7 MB 45.1 MB/s eta 0:00:0000:0100:01
anylinux_2_28_x86_64.whl (865.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 865.2/865.2 MB 3.5 MB/s eta 0:00:0000:0100:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.3/509.3 KB 54.3 MB/s eta 0:00:00
anylinux_2_28_x86_64.whl (4.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.6/4.6 MB 75.1 MB/s eta 0:00:00ta 0:00:01
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 59.8 MB/s eta 0:00:0000:0100:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 509.2/509.2 KB 25.5 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 347.8/347.8 KB 32.1 MB/s eta 0:00:00
ent already satisfied: python-dateutil&gt;=2.8.2 in ./test_env/lib/python3.10/site-packages (from pandas) (2.9.0.post0)
Collecting filelock
  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)
Collecting hf-xet&lt;2.0.0,&gt;=1.1.2
  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.2/5.2 MB 70.1 MB/s eta 0:00:00:00:0100:01
l&gt;=5.1
  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.2/751.2 KB 34.8 MB/s eta 0:00:00
ent already satisfied: packaging&gt;=20.9 in ./test_env/lib/python3.10/site-packages (from huggingface-hub&gt;=0.20.0-&gt;sentence_transformers) (25.0)
Collecting requests
  Downloading requests-2.32.3-py3-none-any.whl (64 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 64.9/64.9 KB 10.2 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 199.1/199.1 KB 28.7 MB/s eta 0:00:00
ent already satisfied: six&gt;=1.5 in ./test_env/lib/python3.10/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas) (1.17.0)
Collecting nvidia-nvtx-cu12==12.6.77
  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.3/89.3 KB 13.9 MB/s eta 0:00:00
anylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 201.3/201.3 MB 13.3 MB/s eta 0:00:0000:0100:01
anylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 216.6/216.6 MB 12.4 MB/s eta 0:00:0000:0100:01
anylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 393.1/393.1 MB 6.2 MB/s eta 0:00:0000:0100:01
anylinux_2_28_x86_64.whl (571.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 571.0/571.0 MB 5.3 MB/s eta 0:00:0000:0100:01
py&gt;=1.13.3
  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 68.8 MB/s eta 0:00:00:00:010:01
anylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.4/156.4 MB 16.8 MB/s eta 0:00:0000:0100:01
anylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.9/8.9 MB 72.2 MB/s eta 0:00:0000:0100:01
e-cu12==12.6.77
  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 897.7/897.7 KB 48.2 MB/s eta 0:00:00
anylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 42.4 MB/s eta 0:00:00
anylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.2/158.2 MB 16.2 MB/s eta 0:00:0000:0100:01
anylinux2014_x86_64.whl (23.7 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 66.8 MB/s eta 0:00:0000:0100:01
anylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.2/200.2 MB 12.2 MB/s eta 0:00:0000:0100:01
anylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 68.7 MB/s eta 0:00:0000:0100:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 49.8 MB/s eta 0:00:00:00:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.9/134.9 KB 9.0 MB/s eta 0:00:00
anylinux2014_x86_64.whl (156.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 156.8/156.8 MB 16.5 MB/s eta 0:00:0000:0100:01
anylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 35.5 MB/s eta 0:00:0000:0100:01
ent already satisfied: setuptools&gt;=40.8.0 in ./test_env/lib/python3.10/site-packages (from triton==3.3.0-&gt;torch&gt;=1.11.0-&gt;sentence_transformers) (59.6.0)
Collecting tokenizers&lt;0.22,&gt;=0.21
  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.0/3.0 MB 62.5 MB/s eta 0:00:00:00:01
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 471.6/471.6 KB 21.9 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.7/781.7 KB 54.7 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.7/307.7 KB 38.2 MB/s eta 0:00:00
pmath&lt;1.4,&gt;=1.1.0
  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 KB 45.4 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)
Collecting idna&lt;4,&gt;=2.5
  Downloading idna-3.10-py3-none-any.whl (70 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 70.4/70.4 KB 9.3 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 159.6/159.6 KB 20.5 MB/s eta 0:00:00
alizer&lt;4,&gt;=2
  Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.5/149.5 KB 8.8 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.7/128.7 KB 8.8 MB/s eta 0:00:00
pmath, urllib3, tzdata, triton, tqdm, threadpoolctl, sympy, safetensors, regex, pyyaml, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, idna, hf-xet, fsspec, filelock, charset-normalizer, certifi, scipy, requests, pandas, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, scikit-learn, nvidia-cusolver-cu12, huggingface-hub, torch, tokenizers, transformers, sentence_transformers
Successfully installed MarkupSafe-3.0.2 Pillow-11.2.1 certifi-2025.4.26 charset-normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.2 huggingface-hub-0.32.0 idna-3.10 jinja2-3.1.6 joblib-1.5.1 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pandas-2.2.3 pytz-2025.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.3 sentence_transformers-4.1.0 sympy-1.14.0 threadpoolctl-3.6.0 tokenizers-0.21.1 torch-2.7.0 tqdm-4.67.1 transformers-4.52.3 triton-3.3.0 tzdata-2025.2 urllib3-2.4.0
</code></pre>
</div>
</div>
<div id="3af87585" class="cell code">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the dataset</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(<span class="vs">r&#39;combined_all_chunks.json&#39;</span>, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> f:</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    raw_data <span class="op">=</span> json.load(f)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to DataFrame for easier handling</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">isinstance</span>(raw_data, <span class="bu">list</span>):</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> pd.DataFrame(raw_data)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If the JSON has a different structure, adjust accordingly</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> pd.DataFrame([raw_data])</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the first few rows to understand the structure</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Dataset shape:&quot;</span>, dataset.shape)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">First few rows:&quot;</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>dataset.head()</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract and structure metadata</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">isinstance</span>(raw_data,<span class="bu">list</span>):</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>pd.DataFrame(raw_data)</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    dataset<span class="op">=</span>pd.DataFrame([raw_data])</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;metadata&#39;</span>] <span class="op">=</span> dataset[<span class="st">&#39;metadata&#39;</span>].<span class="bu">apply</span>(json.loads)</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;code_snippet&#39;</span>] <span class="op">=</span> dataset[<span class="st">&#39;metadata&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.get(<span class="st">&#39;code_snippet&#39;</span>, <span class="st">&#39;&#39;</span>))</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;length&#39;</span>] <span class="op">=</span> dataset[<span class="st">&#39;metadata&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.get(<span class="st">&#39;length&#39;</span>, <span class="va">None</span>))</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;filename&#39;</span>] <span class="op">=</span> dataset[<span class="st">&#39;metadata&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.get(<span class="st">&#39;filename&#39;</span>, <span class="st">&#39;&#39;</span>))</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;previous_chunk_id&#39;</span>] <span class="op">=</span> dataset[<span class="st">&#39;metadata&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.get(<span class="st">&#39;previous_chunk_id&#39;</span>, <span class="va">None</span>))</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">&#39;next_chunk_id&#39;</span>] <span class="op">=</span> dataset[<span class="st">&#39;metadata&#39;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.get(<span class="st">&#39;next_chunk_id&#39;</span>, <span class="va">None</span>))</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>final_dataset <span class="op">=</span> dataset[[<span class="st">&#39;chunk_id&#39;</span>, <span class="st">&#39;doc&#39;</span>, <span class="st">&#39;title&#39;</span>, <span class="st">&#39;code_snippet&#39;</span>, <span class="st">&#39;length&#39;</span>, <span class="st">&#39;filename&#39;</span>]]</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>final_dataset.columns</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>final_dataset.head()</span></code></pre></div>
</div>
<div id="e108d616" class="cell code" data-execution_count="3">
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#final_dataset.to_csv(&#39;/home/user/Desktop/embedding_openai_bm25/output_chunk_file_reports.csv&#39;, index=False, encoding=&#39;utf-8&#39;)</span></span></code></pre></div>
</div>
<div id="26bf9f2e" class="cell code" data-execution_count="4">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> measure_embedding_time(embed_function, texts):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    embeddings <span class="op">=</span> embed_function(texts)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    end_time <span class="op">=</span> time.time()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embeddings, end_time <span class="op">-</span> start_time</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract text from the dataset</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>texts <span class="op">=</span> final_dataset[<span class="st">&quot;doc&quot;</span>].tolist()[:<span class="dv">100</span>]  <span class="co"># Limiting to 100 samples for demonstration</span></span></code></pre></div>
</div>
<div id="b9435f19" class="cell code" data-execution_count="5">
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">###</span><span class="co"> 2.1 E5-large-v2 (1024 dimensions)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loading E5-large-v2 model...&quot;</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>e5_model <span class="op">=</span> SentenceTransformer(<span class="st">&#39;intfloat/e5-large-v2&#39;</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate embeddings with CPU only</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating E5-large-v2 embeddings...&quot;</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>e5_embeddings, e5_time <span class="op">=</span> measure_embedding_time(</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: e5_model.encode(x, batch_size<span class="op">=</span><span class="dv">4</span>, normalize_embeddings<span class="op">=</span><span class="va">True</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>),</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    texts</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;E5-large-v2 embeddings generated in </span><span class="sc">{</span>e5_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Embedding dimension: </span><span class="sc">{</span>e5_embeddings<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of embeddings: </span><span class="sc">{</span><span class="bu">len</span>(e5_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Loading E5-large-v2 model...
Generating E5-large-v2 embeddings...
E5-large-v2 embeddings generated in 22.68 seconds
Embedding dimension: 1024
Number of embeddings: 100
</code></pre>
</div>
</div>
<div id="2a8160fc" class="cell code" data-execution_count="6">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Total number of parameters</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> e5_model.parameters())</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Total parameters: </span><span class="sc">{</span>total_params<span class="sc">:,}</span><span class="ss">&quot;</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Model size in memory</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>model_size_bytes <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="op">*</span> p.element_size() <span class="cf">for</span> p <span class="kw">in</span> e5_model.parameters())</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>model_size_mb <span class="op">=</span> model_size_bytes <span class="op">/</span> (<span class="dv">1024</span> <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Estimated model size: </span><span class="sc">{</span>model_size_mb<span class="sc">:.2f}</span><span class="ss"> MB&quot;</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total parameters: 335,141,888
Estimated model size: 1278.46 MB
</code></pre>
</div>
</div>
<div id="cfbce2ca" class="cell code" data-execution_count="7">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">###</span><span class="co"> 2.2 GTE-Large (1024 dimensions)</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the GTE-Large model which has 1024 dimensions</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loading GTE-Large model...&quot;</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>gte_model <span class="op">=</span> SentenceTransformer(<span class="st">&#39;thenlper/gte-large&#39;</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate embeddings with CPU only</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating GTE-Large embeddings...&quot;</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>gte_embeddings, gte_time <span class="op">=</span> measure_embedding_time(</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: gte_model.encode(x, batch_size<span class="op">=</span><span class="dv">4</span>, normalize_embeddings<span class="op">=</span><span class="va">True</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>),</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    texts</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;GTE-Large embeddings generated in </span><span class="sc">{</span>gte_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Embedding dimension: </span><span class="sc">{</span>gte_embeddings<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of embeddings: </span><span class="sc">{</span><span class="bu">len</span>(gte_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Loading GTE-Large model...
Generating GTE-Large embeddings...
GTE-Large embeddings generated in 22.41 seconds
Embedding dimension: 1024
Number of embeddings: 100
</code></pre>
</div>
</div>
<div id="a47162ea" class="cell code" data-execution_count="8">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Total number of parameters</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> gte_model.parameters())</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Total parameters: </span><span class="sc">{</span>total_params<span class="sc">:,}</span><span class="ss">&quot;</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Model size in memory</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>model_size_bytes <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="op">*</span> p.element_size() <span class="cf">for</span> p <span class="kw">in</span> gte_model.parameters())</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>model_size_mb <span class="op">=</span> model_size_bytes <span class="op">/</span> (<span class="dv">1024</span> <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Estimated model size: </span><span class="sc">{</span>model_size_mb<span class="sc">:.2f}</span><span class="ss"> MB&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total parameters: 335,141,888
Estimated model size: 1278.46 MB
</code></pre>
</div>
</div>
<div id="c8ea124c" class="cell code" data-execution_count="9">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">###</span><span class="co"> 2.3 BGE Large v1.5 (1024 dimensions)</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loading BGE Large v1.5 model...&quot;</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>bge_model <span class="op">=</span> SentenceTransformer(<span class="st">&#39;BAAI/bge-large-en-v1.5&#39;</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate embeddings with CPU only</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating BGE embeddings...&quot;</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>bge_embeddings, bge_time <span class="op">=</span> measure_embedding_time(</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: bge_model.encode(x, batch_size<span class="op">=</span><span class="dv">4</span>, normalize_embeddings<span class="op">=</span><span class="va">True</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>),</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    texts</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;BGE embeddings generated in </span><span class="sc">{</span>bge_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Embedding dimension: </span><span class="sc">{</span>bge_embeddings<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of embeddings: </span><span class="sc">{</span><span class="bu">len</span>(bge_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Loading BGE Large v1.5 model...
Generating BGE embeddings...
BGE embeddings generated in 22.24 seconds
Embedding dimension: 1024
Number of embeddings: 100
</code></pre>
</div>
</div>
<div id="752be111" class="cell code" data-execution_count="10">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Total number of parameters</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> bge_model.parameters())</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Total parameters: </span><span class="sc">{</span>total_params<span class="sc">:,}</span><span class="ss">&quot;</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Model size in memory</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>model_size_bytes <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="op">*</span> p.element_size() <span class="cf">for</span> p <span class="kw">in</span> bge_model.parameters())</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>model_size_mb <span class="op">=</span> model_size_bytes <span class="op">/</span> (<span class="dv">1024</span> <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Estimated model size: </span><span class="sc">{</span>model_size_mb<span class="sc">:.2f}</span><span class="ss"> MB&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total parameters: 335,141,888
Estimated model size: 1278.46 MB
</code></pre>
</div>
</div>
<div id="62d2f2cd" class="cell code" data-execution_count="11">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">###</span><span class="co"> 2.5 Instructor XL (1536 dimensions)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loading Iinfly model...&quot;</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>inf_model <span class="op">=</span> SentenceTransformer(<span class="st">&#39;infly/inf-retriever-v1&#39;</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate embeddings with CPU only - using code-specific instruction</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating infly embeddings...&quot;</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>inf_embeddings, inf_time <span class="op">=</span> measure_embedding_time(</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: inf_model.encode(</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        [[<span class="st">&quot;Represent code for retrieval: &quot;</span>, text] <span class="cf">for</span> text <span class="kw">in</span> x], </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">4</span>, </span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        normalize_embeddings<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span><span class="st">&#39;cpu&#39;</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    texts</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;inf_model embeddings generated in </span><span class="sc">{</span>inf_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Embedding dimension: </span><span class="sc">{</span>inf_embeddings<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of embeddings: </span><span class="sc">{</span><span class="bu">len</span>(inf_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Loading Iinfly model...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Fetching 3 files: 100%|██████████| 3/3 [02:03&lt;00:00, 41.07s/it] 
Loading checkpoint shards: 100%|██████████| 3/3 [00:02&lt;00:00,  1.10it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Generating infly embeddings...
inf_model embeddings generated in 360.13 seconds
Embedding dimension: 3584
Number of embeddings: 100
</code></pre>
</div>
</div>
<div id="b30bffa6" class="cell code" data-execution_count="12">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Total number of parameters</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> inf_model.parameters())</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Total parameters: </span><span class="sc">{</span>total_params<span class="sc">:,}</span><span class="ss">&quot;</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Model size in memory</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>model_size_bytes <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="op">*</span> p.element_size() <span class="cf">for</span> p <span class="kw">in</span> inf_model.parameters())</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>model_size_mb <span class="op">=</span> model_size_bytes <span class="op">/</span> (<span class="dv">1024</span> <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Estimated model size: </span><span class="sc">{</span>model_size_mb<span class="sc">:.2f}</span><span class="ss"> MB&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total parameters: 7,069,121,024
Estimated model size: 26966.56 MB
</code></pre>
</div>
</div>
<div id="8c379008" class="cell code" data-execution_count="13">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;BAAI/bge-m3 model...&quot;</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>bge_m3_model <span class="op">=</span> SentenceTransformer(<span class="st">&#39;BAAI/bge-m3&#39;</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate embeddings with CPU only - using code-specific instruction</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating BAAI/bge-m3 embeddings...&quot;</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>bge_m3_embeddings, bge_m3_time <span class="op">=</span> measure_embedding_time(</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: bge_m3_model.encode(</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        [[<span class="st">&quot;Represent code for retrieval: &quot;</span>, text] <span class="cf">for</span> text <span class="kw">in</span> x], </span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        batch_size<span class="op">=</span><span class="dv">4</span>, </span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        normalize_embeddings<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>        device<span class="op">=</span><span class="st">&#39;cpu&#39;</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>    texts</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;BAAI/bge-m3 embeddings generated in </span><span class="sc">{</span>bge_m3_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Embedding dimension: </span><span class="sc">{</span>bge_m3_embeddings<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of embeddings: </span><span class="sc">{</span><span class="bu">len</span>(bge_m3_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>BAAI/bge-m3 model...
Generating BAAI/bge-m3 embeddings...
BAAI/bge-m3 embeddings generated in 31.45 seconds
Embedding dimension: 1024
Number of embeddings: 100
</code></pre>
</div>
</div>
<div id="62e2e6a8" class="cell code" data-execution_count="14">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Total number of parameters</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> bge_m3_model.parameters())</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Total parameters: </span><span class="sc">{</span>total_params<span class="sc">:,}</span><span class="ss">&quot;</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Model size in memory</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>model_size_bytes <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="op">*</span> p.element_size() <span class="cf">for</span> p <span class="kw">in</span> bge_m3_model.parameters())</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>model_size_mb <span class="op">=</span> model_size_bytes <span class="op">/</span> (<span class="dv">1024</span> <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Estimated model size: </span><span class="sc">{</span>model_size_mb<span class="sc">:.2f}</span><span class="ss"> MB&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total parameters: 567,754,752
Estimated model size: 2165.81 MB
</code></pre>
</div>
</div>
<div id="c62f8043" class="cell code" data-execution_count="15">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install <span class="st">&quot;generative-ai-hub-sdk[all]&quot;</span></span></code></pre></div>
<div class="output stream stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Collecting generative-ai-hub-sdk[all]
  Downloading generative_ai_hub_sdk-4.12.4-py3-none-any.whl (613 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 613.6/613.6 KB 6.6 MB/s eta 0:00:00a 0:00:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.2/102.2 KB 11.3 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 720.4/720.4 KB 23.1 MB/s eta 0:00:00
ent already satisfied: packaging&gt;=23.2 in ./test_env/lib/python3.10/site-packages (from generative-ai-hub-sdk[all]) (25.0)
Collecting pydantic==2.10.6
  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 431.7/431.7 KB 9.7 MB/s eta 0:00:0000:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 153.7/153.7 KB 15.7 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 73.5/73.5 KB 8.8 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.4/95.4 KB 12.3 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.4/63.4 KB 3.5 MB/s eta 0:00:00
munity~=0.3.0
  Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 38.3 MB/s eta 0:00:00a 0:00:01
==1.83.0
  Downloading google_cloud_aiplatform-1.83.0-py2.py3-none-any.whl (7.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.3/7.3 MB 43.5 MB/s eta 0:00:0000:0100:01m
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 109.3/109.3 KB 14.3 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 39.5 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.3/139.3 KB 3.0 MB/s eta 0:00:00a 0:00:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 KB 4.2 MB/s eta 0:00:00
espath&lt;2.0.0,&gt;=0.7.1
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Collecting s3transfer&lt;0.12.0,&gt;=0.11.0
  Downloading s3transfer-0.11.5-py3-none-any.whl (84 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.8/84.8 KB 11.1 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 72.7 MB/s eta 0:00:0000:0100:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 KB 6.4 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 70.0 MB/s eta 0:00:00:00:01
anager&lt;3.0.0dev,&gt;=1.3.3
  Downloading google_cloud_resource_manager-1.14.2-py3-none-any.whl (394 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 394.3/394.3 KB 40.2 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 216.1/216.1 KB 10.2 MB/s eta 0:00:0000:01
ent already satisfied: typing-extensions in ./test_env/lib/python3.10/site-packages (from google-cloud-aiplatform==1.83.0-&gt;generative-ai-hub-sdk[all]) (4.13.2)
Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;6.0.0dev,&gt;=3.20.2
  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 319.7/319.7 KB 17.5 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 131.8/131.8 KB 7.7 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 253.5/253.5 KB 14.6 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 160.1/160.1 KB 9.6 MB/s eta 0:00:00
py&lt;2,&gt;=1
  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 61.8 MB/s eta 0:00:0000:0100:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 438.3/438.3 KB 22.5 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 53.7 MB/s eta 0:00:00:00:01
anylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.8/82.8 KB 4.9 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 59.2 MB/s eta 0:00:00
ent already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in ./test_env/lib/python3.10/site-packages (from aiobotocore[boto3]==2.21.1-&gt;aioboto3==14.1.0-&gt;generative-ai-hub-sdk[all]) (2.9.0.post0)
Collecting aioitertools&lt;1.0.0,&gt;=0.5.1
  Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)
Collecting botocore&lt;1.38.0,&gt;=1.37.0
  Downloading botocore-1.37.1-py3-none-any.whl (13.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.4/13.4 MB 68.9 MB/s eta 0:00:0000:0100:01
ultidict&lt;7.0.0,&gt;=6.0.0
  Downloading multidict-6.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 219.1/219.1 KB 11.2 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 265.5/265.5 KB 31.2 MB/s eta 0:00:00
ps~=3.0
  Downloading pyhumps-3.8.0-py3-none-any.whl (6.1 kB)
Requirement already satisfied: requests&lt;3.0 in ./test_env/lib/python3.10/site-packages (from ai-api-client-sdk==2.6.1-&gt;ai-core-sdk&gt;=2.6.2-&gt;generative-ai-hub-sdk[all]) (2.32.3)
Collecting aenum~=3.1
  Downloading aenum-3.1.16-py3-none-any.whl (165 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 165.6/165.6 KB 21.6 MB/s eta 0:00:00
ent already satisfied: idna in ./test_env/lib/python3.10/site-packages (from httpx&gt;=0.27.0-&gt;generative-ai-hub-sdk[all]) (3.10)
Collecting anyio
  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.9/100.9 KB 12.8 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.8/78.8 KB 12.3 MB/s eta 0:00:00
ent already satisfied: certifi in ./test_env/lib/python3.10/site-packages (from httpx&gt;=0.27.0-&gt;generative-ai-hub-sdk[all]) (2025.4.26)
Collecting h11&gt;=0.16
  Downloading h11-0.16.0-py3-none-any.whl (37 kB)
Collecting langchain-text-splitters&lt;1.0.0,&gt;=0.3.8
  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)
Collecting async-timeout&lt;5.0.0,&gt;=4.0.0
  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)
Collecting SQLAlchemy&lt;3,&gt;=1.4
  Downloading sqlalchemy-2.0.41-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 70.5 MB/s eta 0:00:00:00:01
ent already satisfied: PyYAML&gt;=5.3 in ./test_env/lib/python3.10/site-packages (from langchain~=0.3.0-&gt;generative-ai-hub-sdk[all]) (6.0.2)
Collecting langsmith&lt;0.4,&gt;=0.1.17
  Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 360.3/360.3 KB 19.5 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 44.4/44.4 KB 2.6 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 48.6 MB/s eta 0:00:00
ent already satisfied: tqdm&gt;4 in ./test_env/lib/python3.10/site-packages (from openai&gt;=1.58.1-&gt;generative-ai-hub-sdk[all]) (4.67.1)
Collecting distro&lt;2,&gt;=1.7.0
  Downloading distro-1.9.0-py3-none-any.whl (20 kB)
Collecting jiter&lt;1,&gt;=0.4.0
  Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 352.5/352.5 KB 7.9 MB/s eta 0:00:0000:01
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 333.9/333.9 KB 16.8 MB/s eta 0:00:00
anylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 287.3/287.3 KB 16.2 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.8/63.8 KB 8.1 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 206.6/206.6 KB 11.7 MB/s eta 0:00:00
ent already satisfied: exceptiongroup&gt;=1.0.2 in ./test_env/lib/python3.10/site-packages (from anyio-&gt;httpx&gt;=0.27.0-&gt;generative-ai-hub-sdk[all]) (1.3.0)
Requirement already satisfied: urllib3!=2.2.0,&lt;3,&gt;=1.25.4 in ./test_env/lib/python3.10/site-packages (from botocore&lt;1.38.0,&gt;=1.37.0-&gt;boto3==1.37.0-&gt;generative-ai-hub-sdk[all]) (2.4.0)
Collecting typing-inspect&lt;1,&gt;=0.4.0
  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)
Collecting marshmallow&lt;4.0.0,&gt;=3.18.0
  Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.9/50.9 KB 862.4 kB/s eta 0:00:00a 0:00:01
mon-protos&lt;2.0.0,&gt;=1.56.2
  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.5/294.5 KB 27.1 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 75.5 MB/s eta 0:00:00:00:0100:01
odules&gt;=0.2.1
  Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 KB 22.0 MB/s eta 0:00:00
able-media&lt;3.0.0,&gt;=2.0.0
  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.3/81.3 KB 10.7 MB/s eta 0:00:00
-v1&lt;1.0.0,&gt;=0.14.0
  Downloading grpc_google_iam_v1-0.14.2-py3-none-any.whl (19 kB)
Collecting google-crc32c&lt;2.0dev,&gt;=1.0
  Downloading google_crc32c-1.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38 kB)
Collecting packaging&gt;=23.2
  Downloading packaging-24.2-py3-none-any.whl (65 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 KB 3.0 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.5/54.5 KB 5.2 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 43.7 MB/s eta 0:00:0000:01:00:01
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.8/132.8 KB 8.2 MB/s eta 0:00:00
ent already satisfied: charset-normalizer&lt;4,&gt;=2 in ./test_env/lib/python3.10/site-packages (from requests&lt;3.0-&gt;ai-api-client-sdk==2.6.1-&gt;ai-core-sdk&gt;=2.6.2-&gt;generative-ai-hub-sdk[all]) (3.4.2)
Collecting s3transfer&lt;0.12.0,&gt;=0.11.0
  Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.4/84.4 KB 5.2 MB/s eta 0:00:00
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.2/84.2 KB 9.2 MB/s eta 0:00:00
anylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (580 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 580.6/580.6 KB 34.0 MB/s eta 0:00:00
ent already satisfied: regex&gt;=2022.1.18 in ./test_env/lib/python3.10/site-packages (from tiktoken&lt;1,&gt;=0.7-&gt;langchain-openai&gt;=0.3.7-&gt;generative-ai-hub-sdk[all]) (2024.11.6)
Collecting jsonpointer&gt;=1.9
  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)
Collecting pyasn1&lt;0.7.0,&gt;=0.6.1
  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.1/83.1 KB 12.0 MB/s eta 0:00:00
ent already satisfied: six&gt;=1.5 in ./test_env/lib/python3.10/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;aiobotocore[boto3]==2.21.1-&gt;aioboto3==14.1.0-&gt;generative-ai-hub-sdk[all]) (1.17.0)
Collecting mypy-extensions&gt;=0.3.0
  Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)
Installing collected packages: pyhumps, overloading, aenum, zstandard, wrapt, typing-inspection, tenacity, sniffio, python-dotenv, pydantic-core, pyasn1, protobuf, propcache, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, jmespath, jiter, httpx-sse, h11, grpcio, greenlet, google-crc32c, frozenlist, docstring-parser, distro, dacite, click, cachetools, attrs, async-timeout, annotated-types, aioitertools, aiohappyeyeballs, aiofiles, yarl, typing-inspect, tiktoken, SQLAlchemy, shapely, rsa, requests-toolbelt, pydantic, pyasn1-modules, proto-plus, marshmallow, jsonpatch, httpcore, googleapis-common-protos, google-resumable-media, botocore, anyio, aiosignal, ai-api-client-sdk, s3transfer, pydantic-settings, httpx, grpcio-status, google-auth, dataclasses-json, aiohttp, ai-core-sdk, openai, langsmith, grpc-google-iam-v1, google-api-core, boto3, aiobotocore, langchain-core, google-cloud-core, generative-ai-hub-sdk, langchain-text-splitters, langchain-openai, langchain-aws, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, aioboto3, langchain, google-cloud-aiplatform, langchain-google-vertexai, langchain-community
  Attempting uninstall: packaging
    Found existing installation: packaging 25.0
    Uninstalling packaging-25.0:
      Successfully uninstalled packaging-25.0
  Attempting uninstall: numpy
    Found existing installation: numpy 2.2.6
    Uninstalling numpy-2.2.6:
      Successfully uninstalled numpy-2.2.6
Successfully installed SQLAlchemy-2.0.41 aenum-3.1.16 ai-api-client-sdk-2.6.1 ai-core-sdk-2.6.2 aioboto3-14.1.0 aiobotocore-2.21.1 aiofiles-24.1.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.0 aioitertools-0.12.0 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 async-timeout-4.0.3 attrs-25.3.0 boto3-1.37.0 botocore-1.37.1 cachetools-5.5.2 click-8.2.1 dacite-1.9.2 dataclasses-json-0.6.7 distro-1.9.0 docstring-parser-0.16 frozenlist-1.6.0 generative-ai-hub-sdk-4.12.4 google-api-core-2.24.2 google-auth-2.40.2 google-cloud-aiplatform-1.83.0 google-cloud-bigquery-3.33.0 google-cloud-core-2.4.3 google-cloud-resource-manager-1.14.2 google-cloud-storage-2.19.0 google-crc32c-1.7.1 google-resumable-media-2.7.2 googleapis-common-protos-1.70.0 greenlet-3.2.2 grpc-google-iam-v1-0.14.2 grpcio-1.71.0 grpcio-status-1.71.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.0 jiter-0.10.0 jmespath-1.0.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.25 langchain-aws-0.2.15 langchain-community-0.3.24 langchain-core-0.3.61 langchain-google-vertexai-2.0.15 langchain-openai-0.3.18 langchain-text-splitters-0.3.8 langsmith-0.3.42 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 numpy-1.26.4 openai-1.82.0 orjson-3.10.18 overloading-0.5.0 packaging-24.2 propcache-0.3.1 proto-plus-1.26.1 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.9.1 pyhumps-3.8.0 python-dotenv-1.1.0 requests-toolbelt-1.0.0 rsa-4.9.1 s3transfer-0.11.3 shapely-2.1.1 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.9.0 typing-inspect-0.9.0 typing-inspection-0.4.1 wrapt-1.17.2 yarl-1.20.0 zstandard-0.23.0
</code></pre>
</div>
</div>
<div id="60548097" class="cell code" data-execution_count="16">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">###</span><span class="co"> 2.6 OpenAI Embeddings (1536 dimensions)</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> asyncio</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nest_asyncio</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> dotenv <span class="im">import</span> load_dotenv</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gen_ai_hub.proxy.native.openai <span class="im">import</span> AsyncOpenAI</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply nest_asyncio for notebook environments</span></span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>nest_asyncio.<span class="bu">apply</span>()</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Load environment variables</span></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>load_dotenv(<span class="st">&#39;chunk.env&#39;</span>)</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Define global variable for timing</span></span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>openai_time <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Get authentication token</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_auth_token():</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>    auth_url <span class="op">=</span> os.getenv(<span class="st">&#39;AICORE_AUTH_URL&#39;</span>)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    client_id <span class="op">=</span> os.getenv(<span class="st">&#39;AICORE_CLIENT_ID&#39;</span>)</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>    client_secret <span class="op">=</span> os.getenv(<span class="st">&#39;AICORE_CLIENT_SECRET&#39;</span>)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> requests.post(</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>        auth_url,</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>        data<span class="op">=</span>{</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;grant_type&#39;</span>: <span class="st">&#39;client_credentials&#39;</span>,</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;client_id&#39;</span>: client_id,</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>            <span class="st">&#39;client_secret&#39;</span>: client_secret</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>        headers<span class="op">=</span>{<span class="st">&#39;Content-Type&#39;</span>: <span class="st">&#39;application/x-www-form-urlencoded&#39;</span>}</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>        token_data <span class="op">=</span> response.json()</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> token_data.get(<span class="st">&#39;access_token&#39;</span>)</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">Exception</span>(<span class="ss">f&quot;Auth failed: </span><span class="sc">{</span>response<span class="sc">.</span>status_code<span class="sc">}</span><span class="ss"> - </span><span class="sc">{</span>response<span class="sc">.</span>text<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Client cache to avoid recreating clients</span></span>
<span id="cb32-44"><a href="#cb32-44" aria-hidden="true" tabindex="-1"></a>client_cache <span class="op">=</span> {}</span>
<span id="cb32-45"><a href="#cb32-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-46"><a href="#cb32-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to get or create client for a model instance</span></span>
<span id="cb32-47"><a href="#cb32-47" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_client(model_instance):</span>
<span id="cb32-48"><a href="#cb32-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> model_instance <span class="kw">in</span> client_cache:</span>
<span id="cb32-49"><a href="#cb32-49" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> client_cache[model_instance]</span>
<span id="cb32-50"><a href="#cb32-50" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-51"><a href="#cb32-51" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get deployment ID for this instance</span></span>
<span id="cb32-52"><a href="#cb32-52" aria-hidden="true" tabindex="-1"></a>    deployment_id <span class="op">=</span> os.getenv(<span class="ss">f&#39;AICORE_DEPLOYMENT_ID_</span><span class="sc">{</span>model_instance<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb32-53"><a href="#cb32-53" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> deployment_id:</span>
<span id="cb32-54"><a href="#cb32-54" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f&quot;No deployment ID found for </span><span class="sc">{</span>model_instance<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-55"><a href="#cb32-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-56"><a href="#cb32-56" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get auth token</span></span>
<span id="cb32-57"><a href="#cb32-57" aria-hidden="true" tabindex="-1"></a>    token <span class="op">=</span> get_auth_token()</span>
<span id="cb32-58"><a href="#cb32-58" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-59"><a href="#cb32-59" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create client</span></span>
<span id="cb32-60"><a href="#cb32-60" aria-hidden="true" tabindex="-1"></a>    client <span class="op">=</span> AsyncOpenAI(</span>
<span id="cb32-61"><a href="#cb32-61" aria-hidden="true" tabindex="-1"></a>        base_url<span class="op">=</span>os.getenv(<span class="st">&#39;AICORE_BASE_URL&#39;</span>),</span>
<span id="cb32-62"><a href="#cb32-62" aria-hidden="true" tabindex="-1"></a>        api_key<span class="op">=</span><span class="st">&quot;dummy&quot;</span>,  <span class="co"># Not used with SAP AI Core</span></span>
<span id="cb32-63"><a href="#cb32-63" aria-hidden="true" tabindex="-1"></a>        default_headers<span class="op">=</span>{</span>
<span id="cb32-64"><a href="#cb32-64" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;Authorization&quot;</span>: <span class="ss">f&quot;Bearer </span><span class="sc">{</span>token<span class="sc">}</span><span class="ss">&quot;</span>,</span>
<span id="cb32-65"><a href="#cb32-65" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;AI-Resource-Group&quot;</span>: os.getenv(<span class="st">&#39;AICORE_RESOURCE_GROUP&#39;</span>, <span class="st">&#39;default&#39;</span>),</span>
<span id="cb32-66"><a href="#cb32-66" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;AI-Deployment-ID&quot;</span>: deployment_id</span>
<span id="cb32-67"><a href="#cb32-67" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb32-68"><a href="#cb32-68" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb32-69"><a href="#cb32-69" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-70"><a href="#cb32-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Cache the client</span></span>
<span id="cb32-71"><a href="#cb32-71" aria-hidden="true" tabindex="-1"></a>    client_cache[model_instance] <span class="op">=</span> client</span>
<span id="cb32-72"><a href="#cb32-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> client</span>
<span id="cb32-73"><a href="#cb32-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-74"><a href="#cb32-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to generate embeddings with specific model instance</span></span>
<span id="cb32-75"><a href="#cb32-75" aria-hidden="true" tabindex="-1"></a><span class="cf">async</span> <span class="kw">def</span> get_embedding(text, model_instance<span class="op">=</span><span class="st">&quot;embed_1&quot;</span>, model<span class="op">=</span><span class="st">&quot;text-embedding-ada-002&quot;</span>):</span>
<span id="cb32-76"><a href="#cb32-76" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>):</span>
<span id="cb32-77"><a href="#cb32-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&quot;Expected text to be a string&quot;</span>)</span>
<span id="cb32-78"><a href="#cb32-78" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-79"><a href="#cb32-79" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> text.replace(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>, <span class="st">&quot; &quot;</span>)</span>
<span id="cb32-80"><a href="#cb32-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-81"><a href="#cb32-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get client for this model instance</span></span>
<span id="cb32-82"><a href="#cb32-82" aria-hidden="true" tabindex="-1"></a>    client <span class="op">=</span> get_client(model_instance)</span>
<span id="cb32-83"><a href="#cb32-83" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-84"><a href="#cb32-84" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> <span class="cf">await</span> client.embeddings.create(</span>
<span id="cb32-85"><a href="#cb32-85" aria-hidden="true" tabindex="-1"></a>        <span class="bu">input</span><span class="op">=</span>text,</span>
<span id="cb32-86"><a href="#cb32-86" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>model</span>
<span id="cb32-87"><a href="#cb32-87" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb32-88"><a href="#cb32-88" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response.data[<span class="dv">0</span>].embedding</span>
<span id="cb32-89"><a href="#cb32-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-90"><a href="#cb32-90" aria-hidden="true" tabindex="-1"></a><span class="co"># OpenAI Embedding Wrapper Class</span></span>
<span id="cb32-91"><a href="#cb32-91" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> OpenAIEmbeddingWrapper:</span>
<span id="cb32-92"><a href="#cb32-92" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model_instances<span class="op">=</span><span class="va">None</span>, model<span class="op">=</span><span class="st">&quot;text-embedding-ada-002&quot;</span>):</span>
<span id="cb32-93"><a href="#cb32-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_instances <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb32-94"><a href="#cb32-94" aria-hidden="true" tabindex="-1"></a>            model_instances <span class="op">=</span> [<span class="st">&quot;embed_1&quot;</span>, <span class="st">&quot;embed_2&quot;</span>, <span class="st">&quot;embed_3&quot;</span>]</span>
<span id="cb32-95"><a href="#cb32-95" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_instances <span class="op">=</span> model_instances</span>
<span id="cb32-96"><a href="#cb32-96" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb32-97"><a href="#cb32-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-98"><a href="#cb32-98" aria-hidden="true" tabindex="-1"></a>    <span class="cf">async</span> <span class="kw">def</span> _get_embedding_async(<span class="va">self</span>, text, model_instance):</span>
<span id="cb32-99"><a href="#cb32-99" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb32-100"><a href="#cb32-100" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Ensure text is a string and remove newlines</span></span>
<span id="cb32-101"><a href="#cb32-101" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(text, <span class="bu">str</span>):</span>
<span id="cb32-102"><a href="#cb32-102" aria-hidden="true" tabindex="-1"></a>                <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&quot;Expected text to be a string&quot;</span>)</span>
<span id="cb32-103"><a href="#cb32-103" aria-hidden="true" tabindex="-1"></a>            text <span class="op">=</span> text.replace(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>, <span class="st">&quot; &quot;</span>)</span>
<span id="cb32-104"><a href="#cb32-104" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb32-105"><a href="#cb32-105" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Get client for this model instance</span></span>
<span id="cb32-106"><a href="#cb32-106" aria-hidden="true" tabindex="-1"></a>            client <span class="op">=</span> get_client(model_instance)</span>
<span id="cb32-107"><a href="#cb32-107" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb32-108"><a href="#cb32-108" aria-hidden="true" tabindex="-1"></a>            response <span class="op">=</span> <span class="cf">await</span> client.embeddings.create(</span>
<span id="cb32-109"><a href="#cb32-109" aria-hidden="true" tabindex="-1"></a>                <span class="bu">input</span><span class="op">=</span>text,</span>
<span id="cb32-110"><a href="#cb32-110" aria-hidden="true" tabindex="-1"></a>                model<span class="op">=</span><span class="va">self</span>.model</span>
<span id="cb32-111"><a href="#cb32-111" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb32-112"><a href="#cb32-112" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> response.data[<span class="dv">0</span>].embedding</span>
<span id="cb32-113"><a href="#cb32-113" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb32-114"><a href="#cb32-114" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Error with </span><span class="sc">{</span>model_instance<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-115"><a href="#cb32-115" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> next_instance <span class="kw">in</span> <span class="va">self</span>.model_instances:</span>
<span id="cb32-116"><a href="#cb32-116" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> next_instance <span class="op">!=</span> model_instance:</span>
<span id="cb32-117"><a href="#cb32-117" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">try</span>:</span>
<span id="cb32-118"><a href="#cb32-118" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">print</span>(<span class="ss">f&quot;Retrying with </span><span class="sc">{</span>next_instance<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-119"><a href="#cb32-119" aria-hidden="true" tabindex="-1"></a>                        embedding <span class="op">=</span> <span class="cf">await</span> <span class="va">self</span>._get_embedding_async(text, next_instance)</span>
<span id="cb32-120"><a href="#cb32-120" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">return</span> embedding</span>
<span id="cb32-121"><a href="#cb32-121" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e2:</span>
<span id="cb32-122"><a href="#cb32-122" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">print</span>(<span class="ss">f&quot;Error on retry: </span><span class="sc">{</span>e2<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-123"><a href="#cb32-123" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb32-124"><a href="#cb32-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-125"><a href="#cb32-125" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> encode(<span class="va">self</span>, texts):</span>
<span id="cb32-126"><a href="#cb32-126" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb32-127"><a href="#cb32-127" aria-hidden="true" tabindex="-1"></a><span class="co">        Encode texts to embeddings.</span></span>
<span id="cb32-128"><a href="#cb32-128" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb32-129"><a href="#cb32-129" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span>
<span id="cb32-130"><a href="#cb32-130" aria-hidden="true" tabindex="-1"></a><span class="co">            texts: A string or list of strings to encode</span></span>
<span id="cb32-131"><a href="#cb32-131" aria-hidden="true" tabindex="-1"></a><span class="co">            </span></span>
<span id="cb32-132"><a href="#cb32-132" aria-hidden="true" tabindex="-1"></a><span class="co">        Returns:</span></span>
<span id="cb32-133"><a href="#cb32-133" aria-hidden="true" tabindex="-1"></a><span class="co">            A list of embeddings (one per text)</span></span>
<span id="cb32-134"><a href="#cb32-134" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span>
<span id="cb32-135"><a href="#cb32-135" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Ensure texts is always a list</span></span>
<span id="cb32-136"><a href="#cb32-136" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(texts, <span class="bu">str</span>):</span>
<span id="cb32-137"><a href="#cb32-137" aria-hidden="true" tabindex="-1"></a>            texts <span class="op">=</span> [texts]</span>
<span id="cb32-138"><a href="#cb32-138" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-139"><a href="#cb32-139" aria-hidden="true" tabindex="-1"></a>        embeddings <span class="op">=</span> []</span>
<span id="cb32-140"><a href="#cb32-140" aria-hidden="true" tabindex="-1"></a>        loop <span class="op">=</span> asyncio.get_event_loop()</span>
<span id="cb32-141"><a href="#cb32-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-142"><a href="#cb32-142" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Use tqdm for progress tracking</span></span>
<span id="cb32-143"><a href="#cb32-143" aria-hidden="true" tabindex="-1"></a>        <span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb32-144"><a href="#cb32-144" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-145"><a href="#cb32-145" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, text <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(texts, desc<span class="op">=</span><span class="st">&quot;Generating OpenAI embeddings&quot;</span>)):</span>
<span id="cb32-146"><a href="#cb32-146" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb32-147"><a href="#cb32-147" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Rotate through model instances for load balancing</span></span>
<span id="cb32-148"><a href="#cb32-148" aria-hidden="true" tabindex="-1"></a>                model_instance <span class="op">=</span> <span class="va">self</span>.model_instances[i <span class="op">%</span> <span class="bu">len</span>(<span class="va">self</span>.model_instances)]</span>
<span id="cb32-149"><a href="#cb32-149" aria-hidden="true" tabindex="-1"></a>                embedding <span class="op">=</span> loop.run_until_complete(<span class="va">self</span>._get_embedding_async(text, model_instance))</span>
<span id="cb32-150"><a href="#cb32-150" aria-hidden="true" tabindex="-1"></a>                embeddings.append(embedding)</span>
<span id="cb32-151"><a href="#cb32-151" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb32-152"><a href="#cb32-152" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;Error in encode for text </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-153"><a href="#cb32-153" aria-hidden="true" tabindex="-1"></a>                embeddings.append(<span class="va">None</span>)</span>
<span id="cb32-154"><a href="#cb32-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-155"><a href="#cb32-155" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> embeddings</span>
<span id="cb32-156"><a href="#cb32-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-157"><a href="#cb32-157" aria-hidden="true" tabindex="-1"></a><span class="co"># Process texts with rotating model instances for load balancing</span></span>
<span id="cb32-158"><a href="#cb32-158" aria-hidden="true" tabindex="-1"></a><span class="cf">async</span> <span class="kw">def</span> process_texts_with_rotation(texts):</span>
<span id="cb32-159"><a href="#cb32-159" aria-hidden="true" tabindex="-1"></a>    <span class="kw">global</span> openai_time</span>
<span id="cb32-160"><a href="#cb32-160" aria-hidden="true" tabindex="-1"></a>    openai_embeddings <span class="op">=</span> []</span>
<span id="cb32-161"><a href="#cb32-161" aria-hidden="true" tabindex="-1"></a>    start_time <span class="op">=</span> time.time()</span>
<span id="cb32-162"><a href="#cb32-162" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-163"><a href="#cb32-163" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Available model instances</span></span>
<span id="cb32-164"><a href="#cb32-164" aria-hidden="true" tabindex="-1"></a>    instances <span class="op">=</span> [<span class="st">&quot;embed_1&quot;</span>, <span class="st">&quot;embed_2&quot;</span>, <span class="st">&quot;embed_3&quot;</span>]</span>
<span id="cb32-165"><a href="#cb32-165" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-166"><a href="#cb32-166" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, text <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(texts)):</span>
<span id="cb32-167"><a href="#cb32-167" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Rotate through model instances</span></span>
<span id="cb32-168"><a href="#cb32-168" aria-hidden="true" tabindex="-1"></a>        model_instance <span class="op">=</span> instances[i <span class="op">%</span> <span class="bu">len</span>(instances)]</span>
<span id="cb32-169"><a href="#cb32-169" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb32-170"><a href="#cb32-170" aria-hidden="true" tabindex="-1"></a>            embedding <span class="op">=</span> <span class="cf">await</span> get_embedding(text, model_instance<span class="op">=</span>model_instance)</span>
<span id="cb32-171"><a href="#cb32-171" aria-hidden="true" tabindex="-1"></a>            openai_embeddings.append(embedding)</span>
<span id="cb32-172"><a href="#cb32-172" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb32-173"><a href="#cb32-173" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Error with </span><span class="sc">{</span>model_instance<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-174"><a href="#cb32-174" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Try next instance if one fails</span></span>
<span id="cb32-175"><a href="#cb32-175" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span>
<span id="cb32-176"><a href="#cb32-176" aria-hidden="true" tabindex="-1"></a>                next_instance <span class="op">=</span> instances[(i <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="bu">len</span>(instances)]</span>
<span id="cb32-177"><a href="#cb32-177" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;Retrying with </span><span class="sc">{</span>next_instance<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-178"><a href="#cb32-178" aria-hidden="true" tabindex="-1"></a>                embedding <span class="op">=</span> <span class="cf">await</span> get_embedding(text, model_instance<span class="op">=</span>next_instance)</span>
<span id="cb32-179"><a href="#cb32-179" aria-hidden="true" tabindex="-1"></a>                openai_embeddings.append(embedding)</span>
<span id="cb32-180"><a href="#cb32-180" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e2:</span>
<span id="cb32-181"><a href="#cb32-181" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;Error on retry: </span><span class="sc">{</span>e2<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-182"><a href="#cb32-182" aria-hidden="true" tabindex="-1"></a>                openai_embeddings.append(<span class="va">None</span>)</span>
<span id="cb32-183"><a href="#cb32-183" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-184"><a href="#cb32-184" aria-hidden="true" tabindex="-1"></a>    openai_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb32-185"><a href="#cb32-185" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Embeddings generated in </span><span class="sc">{</span>openai_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb32-186"><a href="#cb32-186" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-187"><a href="#cb32-187" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> openai_embeddings <span class="kw">and</span> openai_embeddings[<span class="dv">0</span>]:</span>
<span id="cb32-188"><a href="#cb32-188" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Embedding dimension: </span><span class="sc">{</span><span class="bu">len</span>(openai_embeddings[<span class="dv">0</span>])<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-189"><a href="#cb32-189" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Number of embeddings: </span><span class="sc">{</span><span class="bu">len</span>(openai_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb32-190"><a href="#cb32-190" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-191"><a href="#cb32-191" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> openai_embeddings</span>
<span id="cb32-192"><a href="#cb32-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-193"><a href="#cb32-193" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize OpenAI wrapper</span></span>
<span id="cb32-194"><a href="#cb32-194" aria-hidden="true" tabindex="-1"></a>openai_model <span class="op">=</span> OpenAIEmbeddingWrapper()</span>
<span id="cb32-195"><a href="#cb32-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-196"><a href="#cb32-196" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate OpenAI embeddings</span></span>
<span id="cb32-197"><a href="#cb32-197" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating embeddings via gen_ai_hub with rotation...&quot;</span>)</span>
<span id="cb32-198"><a href="#cb32-198" aria-hidden="true" tabindex="-1"></a>openai_embeddings <span class="op">=</span> asyncio.run(process_texts_with_rotation(texts))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Generating embeddings via gen_ai_hub with rotation...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 100/100 [00:36&lt;00:00,  2.73it/s]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Embeddings generated in 36.68 seconds
Embedding dimension: 1536
Number of embeddings: 100
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>
</code></pre>
</div>
</div>
<div id="6709fee5" class="cell code" data-execution_count="17">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install huggingface_hub</span></code></pre></div>
<div class="output stream stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Requirement already satisfied: huggingface_hub in ./test_env/lib/python3.10/site-packages (0.32.0)
Requirement already satisfied: pyyaml&gt;=5.1 in ./test_env/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)
Requirement already satisfied: tqdm&gt;=4.42.1 in ./test_env/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)
Requirement already satisfied: filelock in ./test_env/lib/python3.10/site-packages (from huggingface_hub) (3.18.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in ./test_env/lib/python3.10/site-packages (from huggingface_hub) (4.13.2)
Requirement already satisfied: requests in ./test_env/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)
Requirement already satisfied: hf-xet&lt;2.0.0,&gt;=1.1.2 in ./test_env/lib/python3.10/site-packages (from huggingface_hub) (1.1.2)
Requirement already satisfied: fsspec&gt;=2023.5.0 in ./test_env/lib/python3.10/site-packages (from huggingface_hub) (2025.5.1)
Requirement already satisfied: packaging&gt;=20.9 in ./test_env/lib/python3.10/site-packages (from huggingface_hub) (24.2)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in ./test_env/lib/python3.10/site-packages (from requests-&gt;huggingface_hub) (2.4.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in ./test_env/lib/python3.10/site-packages (from requests-&gt;huggingface_hub) (2025.4.26)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in ./test_env/lib/python3.10/site-packages (from requests-&gt;huggingface_hub) (3.4.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in ./test_env/lib/python3.10/site-packages (from requests-&gt;huggingface_hub) (3.10)
</code></pre>
</div>
</div>
<div id="5389c373" class="cell code">
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> huggingface_hub <span class="im">import</span> login</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> login_to_huggingface():</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Method 1: Using environment variable</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># You can set the HF_TOKEN environment variable</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    os.environ[<span class="st">&quot;HF_TOKEN&quot;</span>] <span class="op">=</span> <span class="st">&quot;&quot;</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Method 2: Interactive login (recommended for security)</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This will prompt you to enter your token</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#token = input(&quot;Enter your Hugging Face token: &quot;)</span></span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#login(token=token)</span></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#print(&quot;Successfully logged in to Hugging Face!&quot;)</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Method 3: Using the token directly (not recommended for shared code)</span></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># login(token=&quot;your_huggingface_token&quot;)</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="va">__name__</span> <span class="op">==</span> <span class="st">&quot;__main__&quot;</span>:</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>    login_to_huggingface()</span></code></pre></div>
</div>
<div id="21c009b4" class="cell code" data-execution_count="19">
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Code Llama embedding model</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loading Codellama embedding model...&quot;</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>codellama_model <span class="op">=</span> SentenceTransformer(<span class="st">&#39;meta-llama/CodeLlama-7b-hf&#39;</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the padding token to be the same as the EOS token</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> codellama_model.tokenizer.pad_token <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    codellama_model.tokenizer.pad_token <span class="op">=</span> codellama_model.tokenizer.eos_token</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate embeddings with CPU only</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating starcoder embeddings...&quot;</span>)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>codellama_embeddings, codellama_time <span class="op">=</span> measure_embedding_time(</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: codellama_model.encode(x, batch_size<span class="op">=</span><span class="dv">2</span>, normalize_embeddings<span class="op">=</span><span class="va">True</span>, device<span class="op">=</span><span class="st">&#39;cpu&#39;</span>),</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>    texts</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;starcoder embeddings generated in </span><span class="sc">{</span>codellama_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Embedding dimension: </span><span class="sc">{</span>codellama_embeddings<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of embeddings: </span><span class="sc">{</span><span class="bu">len</span>(codellama_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Loading Codellama embedding model...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>No sentence-transformers model found with name meta-llama/CodeLlama-7b-hf. Creating a new one with mean pooling.
Fetching 2 files: 100%|██████████| 2/2 [01:43&lt;00:00, 51.81s/it] 
Loading checkpoint shards: 100%|██████████| 2/2 [00:02&lt;00:00,  1.30s/it]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Generating starcoder embeddings...
starcoder embeddings generated in 413.89 seconds
Embedding dimension: 4096
Number of embeddings: 100
</code></pre>
</div>
</div>
<div id="581686a5" class="cell code" data-execution_count="20">
<div class="sourceCode" id="cb45"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Total number of parameters</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>total_params <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> codellama_model.parameters())</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Total parameters: </span><span class="sc">{</span>total_params<span class="sc">:,}</span><span class="ss">&quot;</span>)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Model size in memory</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a>model_size_bytes <span class="op">=</span> <span class="bu">sum</span>(p.numel() <span class="op">*</span> p.element_size() <span class="cf">for</span> p <span class="kw">in</span> codellama_model.parameters())</span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>model_size_mb <span class="op">=</span> model_size_bytes <span class="op">/</span> (<span class="dv">1024</span> <span class="op">**</span> <span class="dv">2</span>)</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Estimated model size: </span><span class="sc">{</span>model_size_mb<span class="sc">:.2f}</span><span class="ss"> MB&quot;</span>)</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total parameters: 6,607,409,152
Estimated model size: 25205.27 MB
</code></pre>
</div>
</div>
<div id="eef73073" class="cell code" data-execution_count="21">
<div class="sourceCode" id="cb47"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install fastembed</span></code></pre></div>
<div class="output stream stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Collecting fastembed
  Downloading fastembed-0.7.0-py3-none-any.whl (99 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.0/99.0 KB 461.9 kB/s eta 0:00:00 0:00:01m
mh3&lt;6.0.0,&gt;=4.1.0
  Downloading mmh3-5.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (99 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.2/99.2 KB 2.4 MB/s eta 0:00:00a 0:00:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.6/61.6 KB 8.2 MB/s eta 0:00:00
ent already satisfied: pillow&lt;12.0.0,&gt;=10.3.0 in ./test_env/lib/python3.10/site-packages (from fastembed) (11.2.1)
Collecting onnxruntime!=1.20.0,&gt;=1.17.0
  Downloading onnxruntime-1.22.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 66.5 MB/s eta 0:00:0000:0100:01
ent already satisfied: huggingface-hub&lt;1.0,&gt;=0.20 in ./test_env/lib/python3.10/site-packages (from fastembed) (0.32.0)
Requirement already satisfied: requests&lt;3.0,&gt;=2.31 in ./test_env/lib/python3.10/site-packages (from fastembed) (2.32.3)
Requirement already satisfied: tqdm&lt;5.0,&gt;=4.66 in ./test_env/lib/python3.10/site-packages (from fastembed) (4.67.1)
Requirement already satisfied: numpy&gt;=1.21 in ./test_env/lib/python3.10/site-packages (from fastembed) (1.26.4)
Collecting py-rust-stemmers&lt;0.2.0,&gt;=0.1.0
  Downloading py_rust_stemmers-0.1.5-cp310-cp310-manylinux_2_28_x86_64.whl (324 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 324.8/324.8 KB 37.2 MB/s eta 0:00:00
ent already satisfied: tokenizers&lt;1.0,&gt;=0.15 in ./test_env/lib/python3.10/site-packages (from fastembed) (0.21.1)
Requirement already satisfied: packaging&gt;=20.9 in ./test_env/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.20-&gt;fastembed) (24.2)
Requirement already satisfied: pyyaml&gt;=5.1 in ./test_env/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.20-&gt;fastembed) (6.0.2)
Requirement already satisfied: filelock in ./test_env/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.20-&gt;fastembed) (3.18.0)
Requirement already satisfied: fsspec&gt;=2023.5.0 in ./test_env/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.20-&gt;fastembed) (2025.5.1)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in ./test_env/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.20-&gt;fastembed) (4.13.2)
Requirement already satisfied: hf-xet&lt;2.0.0,&gt;=1.1.2 in ./test_env/lib/python3.10/site-packages (from huggingface-hub&lt;1.0,&gt;=0.20-&gt;fastembed) (1.1.2)
Collecting flatbuffers
  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)
Requirement already satisfied: protobuf in ./test_env/lib/python3.10/site-packages (from onnxruntime!=1.20.0,&gt;=1.17.0-&gt;fastembed) (5.29.4)
Collecting coloredlogs
  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 KB 7.1 MB/s eta 0:00:00
ent already satisfied: sympy in ./test_env/lib/python3.10/site-packages (from onnxruntime!=1.20.0,&gt;=1.17.0-&gt;fastembed) (1.14.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in ./test_env/lib/python3.10/site-packages (from requests&lt;3.0,&gt;=2.31-&gt;fastembed) (2025.4.26)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in ./test_env/lib/python3.10/site-packages (from requests&lt;3.0,&gt;=2.31-&gt;fastembed) (3.4.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in ./test_env/lib/python3.10/site-packages (from requests&lt;3.0,&gt;=2.31-&gt;fastembed) (3.10)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in ./test_env/lib/python3.10/site-packages (from requests&lt;3.0,&gt;=2.31-&gt;fastembed) (2.4.0)
Collecting humanfriendly&gt;=9.1
  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 KB 11.8 MB/s eta 0:00:00
ent already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in ./test_env/lib/python3.10/site-packages (from sympy-&gt;onnxruntime!=1.20.0,&gt;=1.17.0-&gt;fastembed) (1.3.0)
Installing collected packages: py-rust-stemmers, flatbuffers, mmh3, loguru, humanfriendly, coloredlogs, onnxruntime, fastembed
Successfully installed coloredlogs-15.0.1 fastembed-0.7.0 flatbuffers-25.2.10 humanfriendly-10.0 loguru-0.7.3 mmh3-5.1.0 onnxruntime-1.22.0 py-rust-stemmers-0.1.5
</code></pre>
</div>
</div>
<div id="6d3f883b" class="cell code" data-execution_count="22">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">###</span><span class="co"> 2.8 Sparse Embeddings with BM25 (complementary to dense embeddings)</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastembed <span class="im">import</span> SparseTextEmbedding</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loading BM25 model...&quot;</span>)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>bm25_embedding_model <span class="op">=</span> SparseTextEmbedding(<span class="st">&quot;Qdrant/bm25&quot;</span>)</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate sparse embeddings</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating BM25 sparse embeddings...&quot;</span>)</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>bm25_embeddings <span class="op">=</span> <span class="bu">list</span>(bm25_embedding_model.passage_embed(texts))</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>bm25_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;BM25 embeddings generated in </span><span class="sc">{</span>bm25_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of BM25 embeddings: </span><span class="sc">{</span><span class="bu">len</span>(bm25_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Example BM25 embedding: </span><span class="sc">{</span>bm25_embeddings[<span class="dv">0</span>]<span class="sc">.</span>as_dict()<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Loading BM25 model...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Fetching 18 files: 100%|██████████| 18/18 [00:00&lt;00:00, 45.16it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Generating BM25 sparse embeddings...
BM25 embeddings generated in 0.03 seconds
Number of BM25 embeddings: 100
Example BM25 embedding: {418310737: 1.5738437892971915, 144051554: 2.0378478127148387, 1458396614: 1.5738437892971915, 1167338989: 1.2251468348923211, 933802348: 1.8349759713285005, 1399361890: 2.0378478127148387, 641650763: 1.738808274158691, 2041386363: 1.8349759713285005, 358389376: 1.2251468348923211, 989116115: 1.2251468348923211, 1262366007: 1.2251468348923211, 546776626: 1.2251468348923211, 332135977: 1.5738437892971915, 1430125705: 1.2251468348923211, 1289414591: 1.2251468348923211, 1285987188: 1.2251468348923211, 609270800: 1.2251468348923211, 640494850: 1.2251468348923211, 889991415: 1.2251468348923211, 569047032: 1.5738437892971915, 1956269320: 1.2251468348923211, 46395304: 1.5738437892971915, 2045916435: 1.2251468348923211, 870749883: 1.2251468348923211, 563226112: 1.5738437892971915, 958659146: 1.2251468348923211, 1863550060: 1.2251468348923211, 1141099794: 1.2251468348923211, 1217469700: 1.5738437892971915, 733815364: 1.2251468348923211, 2019031726: 1.2251468348923211, 1563718956: 1.2251468348923211, 1853176582: 1.2251468348923211, 1889700339: 1.2251468348923211, 192389267: 1.2251468348923211, 640124220: 1.8349759713285005, 1060832955: 1.8349759713285005, 1856538418: 1.5738437892971915, 706006904: 1.738808274158691, 1839534477: 1.738808274158691, 1227694569: 1.897957808182247, 250027325: 1.2251468348923211, 161006309: 1.2251468348923211, 553793032: 1.5738437892971915, 995877641: 1.2251468348923211, 192104822: 1.2251468348923211, 1001046102: 1.2251468348923211, 983281070: 1.5738437892971915, 2095749492: 1.2251468348923211, 784500617: 1.2251468348923211, 989509788: 1.9424038627349545, 632657554: 1.738808274158691, 90483450: 1.2251468348923211, 608323106: 1.738808274158691, 2030342906: 1.738808274158691, 909849500: 1.738808274158691, 1498406768: 1.2251468348923211, 1319752834: 1.2251468348923211, 1559752128: 1.5738437892971915, 1423958341: 1.5738437892971915, 245221680: 1.5738437892971915, 644716969: 1.2251468348923211, 58671053: 1.5738437892971915, 1254596229: 1.2251468348923211, 142464249: 1.2251468348923211, 2022191088: 1.2251468348923211, 1290213554: 1.5738437892971915, 1364383302: 1.2251468348923211, 225924602: 1.2251468348923211, 653391441: 1.2251468348923211, 1968306389: 1.2251468348923211, 1792659531: 1.2251468348923211, 685017497: 1.2251468348923211}
</code></pre>
</div>
</div>
<div id="1854ba36" class="cell code" data-execution_count="23">
<div class="sourceCode" id="cb54"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span><span class="al">###</span><span class="co"> 2.9 Late Interaction Embeddings with ColBERT (complementary approach)</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastembed <span class="im">import</span> LateInteractionTextEmbedding</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Loading ColBERT model...&quot;</span>)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>late_interaction_embedding_model <span class="op">=</span> LateInteractionTextEmbedding(<span class="st">&quot;colbert-ir/colbertv2.0&quot;</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate late interaction embeddings</span></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Generating ColBERT late interaction embeddings...&quot;</span>)</span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>late_interaction_embeddings <span class="op">=</span> <span class="bu">list</span>(late_interaction_embedding_model.passage_embed(texts))</span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>late_interaction_time <span class="op">=</span> time.time() <span class="op">-</span> start_time</span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;ColBERT embeddings generated in </span><span class="sc">{</span>late_interaction_time<span class="sc">:.2f}</span><span class="ss"> seconds&quot;</span>)</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Number of ColBERT embeddings: </span><span class="sc">{</span><span class="bu">len</span>(late_interaction_embeddings)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Dimensions of first ColBERT embedding: </span><span class="sc">{</span><span class="bu">len</span>(late_interaction_embeddings[<span class="dv">0</span>])<span class="sc">}</span><span class="ss"> tokens with </span><span class="sc">{</span><span class="bu">len</span>(late_interaction_embeddings[<span class="dv">0</span>][<span class="dv">0</span>])<span class="sc">}</span><span class="ss"> dimensions each&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Loading ColBERT model...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Fetching 5 files: 100%|██████████| 5/5 [00:04&lt;00:00,  1.12it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Generating ColBERT late interaction embeddings...
ColBERT embeddings generated in 10.01 seconds
Number of ColBERT embeddings: 100
Dimensions of first ColBERT embedding: 512 tokens with 128 dimensions each
</code></pre>
</div>
</div>
<div id="3418b173" class="cell code" data-execution_count="24">
<div class="sourceCode" id="cb58"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install matplotlib</span></code></pre></div>
<div class="output stream stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Collecting matplotlib
  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.6/8.6 MB 35.4 MB/s eta 0:00:0000:0100:01
ent already satisfied: python-dateutil&gt;=2.7 in ./test_env/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)
Requirement already satisfied: pillow&gt;=8 in ./test_env/lib/python3.10/site-packages (from matplotlib) (11.2.1)
Collecting cycler&gt;=0.10
  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)
Collecting fonttools&gt;=4.22.0
  Downloading fonttools-4.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 70.5 MB/s eta 0:00:00ta 0:00:01
ent already satisfied: numpy&gt;=1.23 in ./test_env/lib/python3.10/site-packages (from matplotlib) (1.26.4)
Collecting kiwisolver&gt;=1.3.1
  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 13.7 MB/s eta 0:00:00:00:01
ent already satisfied: packaging&gt;=20.0 in ./test_env/lib/python3.10/site-packages (from matplotlib) (24.2)
Collecting pyparsing&gt;=2.3.1
  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 111.1/111.1 KB 6.4 MB/s eta 0:00:00
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 325.0/325.0 KB 17.7 MB/s eta 0:00:00
ent already satisfied: six&gt;=1.5 in ./test_env/lib/python3.10/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.17.0)
Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib
Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.0 kiwisolver-1.4.8 matplotlib-3.10.3 pyparsing-3.2.3
</code></pre>
</div>
</div>
<div id="09256fb7" class="cell code" data-execution_count="25">
<div class="sourceCode" id="cb61"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 3. Compare All High-Dimensional Embedding Models</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a comparison dataframe</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Model&#39;</span>: [</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;E5-large-v2&#39;</span>, </span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;GTE-Large&#39;</span>, </span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;BGE-Large-v1.5&#39;</span>,</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;inf-retriever-v1&#39;</span>,</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;BAAI/bge-m3&#39;</span>,</span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;OpenAI-text-embedding-ada-002&#39;</span>, </span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Codellama&#39;</span>,</span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;BM25 (Sparse)&#39;</span>, </span>
<span id="cb61-18"><a href="#cb61-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;ColBERT (Late Interaction)&#39;</span></span>
<span id="cb61-19"><a href="#cb61-19" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb61-20"><a href="#cb61-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Type&#39;</span>: [</span>
<span id="cb61-21"><a href="#cb61-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Sparse&#39;</span>, <span class="st">&#39;Late Interaction&#39;</span></span>
<span id="cb61-22"><a href="#cb61-22" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb61-23"><a href="#cb61-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Is Code-Specific&#39;</span>: [</span>
<span id="cb61-24"><a href="#cb61-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;No&#39;</span>, <span class="st">&#39;No&#39;</span>, <span class="st">&#39;No&#39;</span>, <span class="st">&#39;Instruction-tuned&#39;</span>, <span class="st">&#39;No&#39;</span>, <span class="st">&#39;No&#39;</span>, <span class="st">&#39;Yes&#39;</span>, <span class="st">&#39;No&#39;</span>, <span class="st">&#39;No&#39;</span></span>
<span id="cb61-25"><a href="#cb61-25" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb61-26"><a href="#cb61-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Generation Time (s)&#39;</span>: [</span>
<span id="cb61-27"><a href="#cb61-27" aria-hidden="true" tabindex="-1"></a>        e5_time, </span>
<span id="cb61-28"><a href="#cb61-28" aria-hidden="true" tabindex="-1"></a>        gte_time, </span>
<span id="cb61-29"><a href="#cb61-29" aria-hidden="true" tabindex="-1"></a>        bge_time,</span>
<span id="cb61-30"><a href="#cb61-30" aria-hidden="true" tabindex="-1"></a>        inf_time,</span>
<span id="cb61-31"><a href="#cb61-31" aria-hidden="true" tabindex="-1"></a>        bge_m3_time,</span>
<span id="cb61-32"><a href="#cb61-32" aria-hidden="true" tabindex="-1"></a>        openai_time,</span>
<span id="cb61-33"><a href="#cb61-33" aria-hidden="true" tabindex="-1"></a>        codellama_time,</span>
<span id="cb61-34"><a href="#cb61-34" aria-hidden="true" tabindex="-1"></a>        bm25_time,</span>
<span id="cb61-35"><a href="#cb61-35" aria-hidden="true" tabindex="-1"></a>        late_interaction_time</span>
<span id="cb61-36"><a href="#cb61-36" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb61-37"><a href="#cb61-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Samples&#39;</span>: [</span>
<span id="cb61-38"><a href="#cb61-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(e5_embeddings) <span class="cf">if</span> <span class="bu">isinstance</span>(e5_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb61-39"><a href="#cb61-39" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(gte_embeddings) <span class="cf">if</span> <span class="bu">isinstance</span>(gte_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb61-40"><a href="#cb61-40" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(bge_embeddings) <span class="cf">if</span> <span class="bu">isinstance</span>(bge_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb61-41"><a href="#cb61-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(inf_embeddings) <span class="cf">if</span> <span class="bu">isinstance</span>(inf_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb61-42"><a href="#cb61-42" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(bge_m3_embeddings) <span class="cf">if</span> <span class="bu">isinstance</span>(bge_m3_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb61-43"><a href="#cb61-43" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(openai_embeddings) <span class="cf">if</span> openai_embeddings <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb61-44"><a href="#cb61-44" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(codellama_embeddings) <span class="cf">if</span> <span class="bu">isinstance</span>(codellama_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb61-45"><a href="#cb61-45" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(bm25_embeddings) <span class="cf">if</span> <span class="bu">isinstance</span>(bm25_embeddings, <span class="bu">list</span>) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb61-46"><a href="#cb61-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">len</span>(late_interaction_embeddings) <span class="cf">if</span> <span class="bu">isinstance</span>(late_interaction_embeddings, <span class="bu">list</span>) <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb61-47"><a href="#cb61-47" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb61-48"><a href="#cb61-48" aria-hidden="true" tabindex="-1"></a>})</span></code></pre></div>
</div>
<div id="881afb2a" class="cell code" data-execution_count="26">
<div class="sourceCode" id="cb62"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add dimension information</span></span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>comparison[<span class="st">&#39;Dimension&#39;</span>] <span class="op">=</span> [</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a>    e5_embeddings.shape[<span class="dv">1</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(e5_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>    gte_embeddings.shape[<span class="dv">1</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(gte_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>    bge_embeddings.shape[<span class="dv">1</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(bge_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a>    inf_embeddings.shape[<span class="dv">1</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(inf_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a>    bge_m3_embeddings.shape[<span class="dv">1</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(bge_m3_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">len</span>(openai_embeddings[<span class="dv">0</span>]) <span class="cf">if</span> openai_embeddings <span class="kw">and</span> openai_embeddings[<span class="dv">0</span>] <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb62-9"><a href="#cb62-9" aria-hidden="true" tabindex="-1"></a>    codellama_embeddings.shape[<span class="dv">1</span>] <span class="cf">if</span> <span class="bu">isinstance</span>(codellama_embeddings, np.ndarray) <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb62-10"><a href="#cb62-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Variable (Sparse)&quot;</span>,</span>
<span id="cb62-11"><a href="#cb62-11" aria-hidden="true" tabindex="-1"></a>    <span class="ss">f&quot;</span><span class="sc">{</span><span class="bu">len</span>(late_interaction_embeddings[<span class="dv">0</span>])<span class="sc">}</span><span class="ss"> tokens × </span><span class="sc">{</span><span class="bu">len</span>(late_interaction_embeddings[<span class="dv">0</span>][<span class="dv">0</span>])<span class="sc">}</span><span class="ss"> dims&quot;</span> <span class="cf">if</span> <span class="bu">isinstance</span>(late_interaction_embeddings, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(late_interaction_embeddings) <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb62-12"><a href="#cb62-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb62-13"><a href="#cb62-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-14"><a href="#cb62-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Add normalized time metric for dense embeddings</span></span>
<span id="cb62-15"><a href="#cb62-15" aria-hidden="true" tabindex="-1"></a>comparison[<span class="st">&#39;Time per Dimension (ms)&#39;</span>] <span class="op">=</span> <span class="va">None</span>  <span class="co"># Initialize column with None instead of NaN</span></span>
<span id="cb62-16"><a href="#cb62-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">7</span>):  <span class="co"># Only calculate for dense embeddings</span></span>
<span id="cb62-17"><a href="#cb62-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(comparison.loc[i, <span class="st">&#39;Dimension&#39;</span>], (<span class="bu">int</span>, <span class="bu">float</span>)) <span class="kw">and</span> comparison.loc[i, <span class="st">&#39;Dimension&#39;</span>] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb62-18"><a href="#cb62-18" aria-hidden="true" tabindex="-1"></a>        comparison.loc[i, <span class="st">&#39;Time per Dimension (ms)&#39;</span>] <span class="op">=</span> (comparison.loc[i, <span class="st">&#39;Generation Time (s)&#39;</span>] <span class="op">*</span> <span class="dv">1000</span>) <span class="op">/</span> comparison.loc[i, <span class="st">&#39;Dimension&#39;</span>]</span>
<span id="cb62-19"><a href="#cb62-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-20"><a href="#cb62-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Add note for special embedding types</span></span>
<span id="cb62-21"><a href="#cb62-21" aria-hidden="true" tabindex="-1"></a>comparison.loc[<span class="dv">7</span>, <span class="st">&#39;Time per Dimension (ms)&#39;</span>] <span class="op">=</span> <span class="st">&quot;N/A for sparse embeddings&quot;</span></span>
<span id="cb62-22"><a href="#cb62-22" aria-hidden="true" tabindex="-1"></a>comparison.loc[<span class="dv">8</span>, <span class="st">&#39;Time per Dimension (ms)&#39;</span>] <span class="op">=</span> <span class="st">&quot;N/A for late interaction&quot;</span></span>
<span id="cb62-23"><a href="#cb62-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-24"><a href="#cb62-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the comparison</span></span>
<span id="cb62-25"><a href="#cb62-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Model Comparison:&quot;</span>)</span>
<span id="cb62-26"><a href="#cb62-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(comparison)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model Comparison:
                           Model              Type   Is Code-Specific  \
0                    E5-large-v2             Dense                 No   
1                      GTE-Large             Dense                 No   
2                 BGE-Large-v1.5             Dense                 No   
3               inf-retriever-v1             Dense  Instruction-tuned   
4                    BAAI/bge-m3             Dense                 No   
5  OpenAI-text-embedding-ada-002             Dense                 No   
6                      Codellama             Dense                Yes   
7                  BM25 (Sparse)            Sparse                 No   
8     ColBERT (Late Interaction)  Late Interaction                 No   

   Generation Time (s)  Samples              Dimension  \
0            22.682709      100                   1024   
1            22.405375      100                   1024   
2            22.244879      100                   1024   
3           360.134236      100                   3584   
4            31.449296      100                   1024   
5            36.676885      100                   1536   
6           413.888947      100                   4096   
7             0.027406      100      Variable (Sparse)   
8            10.012940      100  512 tokens × 128 dims   

     Time per Dimension (ms)  
0                  22.151083  
1                  21.880249  
2                  21.723515  
3                 100.483883  
4                  30.712203  
5                   23.87818  
6                 101.047106  
7  N/A for sparse embeddings  
8   N/A for late interaction  
</code></pre>
</div>
</div>
<div id="01c76e91" class="cell code" data-execution_count="27">
<div class="sourceCode" id="cb64"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot generation time comparison</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(comparison[<span class="st">&#39;Model&#39;</span>], comparison[<span class="st">&#39;Generation Time (s)&#39;</span>])</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define colors by type and code-specificity</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>colors_map <span class="op">=</span> {</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;No&#39;</span>): <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Yes&#39;</span>): <span class="st">&#39;green&#39;</span>,</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&#39;Dense&#39;</span>, <span class="st">&#39;Instruction-tuned&#39;</span>): <span class="st">&#39;purple&#39;</span>,</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&#39;Sparse&#39;</span>, <span class="st">&#39;No&#39;</span>): <span class="st">&#39;orange&#39;</span>,</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>    (<span class="st">&#39;Late Interaction&#39;</span>, <span class="st">&#39;No&#39;</span>): <span class="st">&#39;red&#39;</span></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Color bars by embedding type and code-specificity</span></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, bar <span class="kw">in</span> <span class="bu">enumerate</span>(bars):</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a>    model_type <span class="op">=</span> comparison.iloc[i][<span class="st">&#39;Type&#39;</span>]</span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>    is_code_specific <span class="op">=</span> comparison.iloc[i][<span class="st">&#39;Is Code-Specific&#39;</span>]</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>    bar.set_color(colors_map.get((model_type, is_code_specific), <span class="st">&#39;gray&#39;</span>))</span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Embedding Generation Time Comparison&#39;</span>)</span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Time (seconds)&#39;</span>)</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Model&#39;</span>)</span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;embedding_time_comparison.png&#39;</span>)  <span class="co"># Save the figure</span></span>
<span id="cb64-26"><a href="#cb64-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_7f8823aad92e4582b6ad79177749d011/9f2c9c2ec04f464661c80d7a429a3edf5aba5424.png" /></p>
</div>
</div>
<div id="e7687331" class="cell code" data-execution_count="28">
<div class="sourceCode" id="cb65"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a second visualization showing time per sample</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate time per sample</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>comparison[<span class="st">&#39;Time per Sample (ms)&#39;</span>] <span class="op">=</span> (comparison[<span class="st">&#39;Generation Time (s)&#39;</span>] <span class="op">*</span> <span class="dv">1000</span>) <span class="op">/</span> comparison[<span class="st">&#39;Samples&#39;</span>]</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(comparison[<span class="st">&#39;Model&#39;</span>], comparison[<span class="st">&#39;Time per Sample (ms)&#39;</span>])</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Color bars by embedding type and code-specificity</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, bar <span class="kw">in</span> <span class="bu">enumerate</span>(bars):</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>    model_type <span class="op">=</span> comparison.iloc[i][<span class="st">&#39;Type&#39;</span>]</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>    is_code_specific <span class="op">=</span> comparison.iloc[i][<span class="st">&#39;Is Code-Specific&#39;</span>]</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>    bar.set_color(colors_map.get((model_type, is_code_specific), <span class="st">&#39;gray&#39;</span>))</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Time per Sample by Embedding Model&#39;</span>)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Time per Sample (milliseconds)&#39;</span>)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Model&#39;</span>)</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend for embedding types</span></span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.patches <span class="im">import</span> Patch</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>legend_elements <span class="op">=</span> [</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">&#39;blue&#39;</span>, label<span class="op">=</span><span class="st">&#39;Dense (General)&#39;</span>),</span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Dense (Code-Specific)&#39;</span>),</span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">&#39;purple&#39;</span>, label<span class="op">=</span><span class="st">&#39;Dense (Instruction-tuned)&#39;</span>),</span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">&#39;orange&#39;</span>, label<span class="op">=</span><span class="st">&#39;Sparse&#39;</span>),</span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">&#39;red&#39;</span>, label<span class="op">=</span><span class="st">&#39;Late Interaction&#39;</span>)</span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>legend_elements)</span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;embedding_time_per_sample.png&#39;</span>)  <span class="co"># Save the figure</span></span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_7f8823aad92e4582b6ad79177749d011/45cb02893d2482aa6078888a035103e783eacc2a.png" /></p>
</div>
</div>
<div id="7fc489f6" class="cell code" data-execution_count="29">
<div class="sourceCode" id="cb66"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a third visualization for time per dimension (dense embeddings only)</span></span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Only show dense embeddings for this plot</span></span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>dense_models <span class="op">=</span> comparison[comparison[<span class="st">&#39;Type&#39;</span>] <span class="op">==</span> <span class="st">&#39;Dense&#39;</span>].copy()</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">&#39;Time per Dimension (ms)&#39;</span> <span class="kw">in</span> dense_models.columns:</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create a color map based on code-specificity</span></span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>    colors <span class="op">=</span> [<span class="st">&#39;blue&#39;</span> <span class="cf">if</span> x <span class="op">==</span> <span class="st">&#39;No&#39;</span> <span class="cf">else</span> <span class="st">&#39;green&#39;</span> <span class="cf">if</span> x <span class="op">==</span> <span class="st">&#39;Yes&#39;</span> <span class="cf">else</span> <span class="st">&#39;purple&#39;</span> <span class="cf">for</span> x <span class="kw">in</span> dense_models[<span class="st">&#39;Is Code-Specific&#39;</span>]]</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>    plt.bar(dense_models[<span class="st">&#39;Model&#39;</span>], dense_models[<span class="st">&#39;Time per Dimension (ms)&#39;</span>], color<span class="op">=</span>colors)</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">&#39;Time per Dimension for Dense Embedding Models&#39;</span>)</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">&#39;Time per Dimension (milliseconds)&#39;</span>)</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">&#39;Model&#39;</span>)</span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>    plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>    plt.savefig(<span class="st">&#39;dense_embedding_efficiency.png&#39;</span>)  <span class="co"># Save the figure</span></span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a fourth visualization specifically comparing dimensions</span></span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for only dense models and convert dimension to numeric</span></span>
<span id="cb66-22"><a href="#cb66-22" aria-hidden="true" tabindex="-1"></a>dimension_data <span class="op">=</span> comparison[comparison[<span class="st">&#39;Type&#39;</span>] <span class="op">==</span> <span class="st">&#39;Dense&#39;</span>].copy()</span>
<span id="cb66-23"><a href="#cb66-23" aria-hidden="true" tabindex="-1"></a>dimension_data[<span class="st">&#39;Dimension&#39;</span>] <span class="op">=</span> pd.to_numeric(dimension_data[<span class="st">&#39;Dimension&#39;</span>], errors<span class="op">=</span><span class="st">&#39;coerce&#39;</span>)</span>
<span id="cb66-24"><a href="#cb66-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-25"><a href="#cb66-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by dimension</span></span>
<span id="cb66-26"><a href="#cb66-26" aria-hidden="true" tabindex="-1"></a>dimension_data <span class="op">=</span> dimension_data.sort_values(<span class="st">&#39;Dimension&#39;</span>)</span>
<span id="cb66-27"><a href="#cb66-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-28"><a href="#cb66-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create colors based on code-specificity</span></span>
<span id="cb66-29"><a href="#cb66-29" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">&#39;blue&#39;</span> <span class="cf">if</span> x <span class="op">==</span> <span class="st">&#39;No&#39;</span> <span class="cf">else</span> <span class="st">&#39;green&#39;</span> <span class="cf">if</span> x <span class="op">==</span> <span class="st">&#39;Yes&#39;</span> <span class="cf">else</span> <span class="st">&#39;purple&#39;</span> <span class="cf">for</span> x <span class="kw">in</span> dimension_data[<span class="st">&#39;Is Code-Specific&#39;</span>]]</span>
<span id="cb66-30"><a href="#cb66-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-31"><a href="#cb66-31" aria-hidden="true" tabindex="-1"></a>plt.bar(dimension_data[<span class="st">&#39;Model&#39;</span>], dimension_data[<span class="st">&#39;Dimension&#39;</span>], color<span class="op">=</span>colors)</span>
<span id="cb66-32"><a href="#cb66-32" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Embedding Dimensions Comparison (Dense Models)&#39;</span>)</span>
<span id="cb66-33"><a href="#cb66-33" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Dimensions&#39;</span>)</span>
<span id="cb66-34"><a href="#cb66-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Model&#39;</span>)</span>
<span id="cb66-35"><a href="#cb66-35" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb66-36"><a href="#cb66-36" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb66-37"><a href="#cb66-37" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;embedding_dimensions.png&#39;</span>)  <span class="co"># Save the figure</span></span>
<span id="cb66-38"><a href="#cb66-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_7f8823aad92e4582b6ad79177749d011/8eeb2d408e99ea4f49a9ce1911bf7be36879b007.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_7f8823aad92e4582b6ad79177749d011/d8abb04b841703d7e5efb95e8954d05d71d076cd.png" /></p>
</div>
</div>
<div id="4ea978f7" class="cell code" data-execution_count="30">
<div class="sourceCode" id="cb67"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 4. Evaluate Similarity Between Random Samples</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics.pairwise <span class="im">import</span> cosine_similarity</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_similarity(embeddings, n_samples<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For numpy arrays</span></span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(embeddings, np.ndarray):</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> embeddings.shape[<span class="dv">0</span>] <span class="op">&lt;</span> n_samples:</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select random samples</span></span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> random.sample(<span class="bu">range</span>(embeddings.shape[<span class="dv">0</span>]), n_samples)</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>        selected_embeddings <span class="op">=</span> embeddings[indices]</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># For lists (like OpenAI embeddings)</span></span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="bu">isinstance</span>(embeddings, <span class="bu">list</span>):</span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(embeddings) <span class="op">&lt;</span> n_samples:</span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb67-22"><a href="#cb67-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Select random samples</span></span>
<span id="cb67-23"><a href="#cb67-23" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> random.sample(<span class="bu">range</span>(<span class="bu">len</span>(embeddings)), n_samples)</span>
<span id="cb67-24"><a href="#cb67-24" aria-hidden="true" tabindex="-1"></a>        selected_embeddings <span class="op">=</span> [embeddings[i] <span class="cf">for</span> i <span class="kw">in</span> indices]</span>
<span id="cb67-25"><a href="#cb67-25" aria-hidden="true" tabindex="-1"></a>        selected_embeddings <span class="op">=</span> np.array(selected_embeddings)  <span class="co"># Convert to numpy for cosine_similarity</span></span>
<span id="cb67-26"><a href="#cb67-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb67-27"><a href="#cb67-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb67-28"><a href="#cb67-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb67-29"><a href="#cb67-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb67-30"><a href="#cb67-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate similarity matrix</span></span>
<span id="cb67-31"><a href="#cb67-31" aria-hidden="true" tabindex="-1"></a>    similarity_matrix <span class="op">=</span> cosine_similarity(selected_embeddings)</span>
<span id="cb67-32"><a href="#cb67-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb67-33"><a href="#cb67-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return average similarity (excluding self-similarity)</span></span>
<span id="cb67-34"><a href="#cb67-34" aria-hidden="true" tabindex="-1"></a>    total_sim <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb67-35"><a href="#cb67-35" aria-hidden="true" tabindex="-1"></a>    count <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb67-36"><a href="#cb67-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_samples):</span>
<span id="cb67-37"><a href="#cb67-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(i<span class="op">+</span><span class="dv">1</span>, n_samples):</span>
<span id="cb67-38"><a href="#cb67-38" aria-hidden="true" tabindex="-1"></a>            total_sim <span class="op">+=</span> similarity_matrix[i, j]</span>
<span id="cb67-39"><a href="#cb67-39" aria-hidden="true" tabindex="-1"></a>            count <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb67-40"><a href="#cb67-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb67-41"><a href="#cb67-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_sim <span class="op">/</span> count <span class="cf">if</span> count <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb67-42"><a href="#cb67-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-43"><a href="#cb67-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate average similarity for each model</span></span>
<span id="cb67-44"><a href="#cb67-44" aria-hidden="true" tabindex="-1"></a>e5_similarity <span class="op">=</span> evaluate_similarity(e5_embeddings)</span>
<span id="cb67-45"><a href="#cb67-45" aria-hidden="true" tabindex="-1"></a>gte_similarity <span class="op">=</span> evaluate_similarity(gte_embeddings)</span>
<span id="cb67-46"><a href="#cb67-46" aria-hidden="true" tabindex="-1"></a>bge_similarity <span class="op">=</span> evaluate_similarity(bge_embeddings)</span>
<span id="cb67-47"><a href="#cb67-47" aria-hidden="true" tabindex="-1"></a>inf_similarity <span class="op">=</span> evaluate_similarity(inf_embeddings)</span>
<span id="cb67-48"><a href="#cb67-48" aria-hidden="true" tabindex="-1"></a>bge_m3_similarity <span class="op">=</span> evaluate_similarity(bge_m3_embeddings)</span>
<span id="cb67-49"><a href="#cb67-49" aria-hidden="true" tabindex="-1"></a>openai_similarity <span class="op">=</span> evaluate_similarity(openai_embeddings)</span>
<span id="cb67-50"><a href="#cb67-50" aria-hidden="true" tabindex="-1"></a>codellama_similarity <span class="op">=</span> evaluate_similarity(codellama_embeddings)</span>
<span id="cb67-51"><a href="#cb67-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-52"><a href="#cb67-52" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Average similarity between random samples:&quot;</span>)</span>
<span id="cb67-53"><a href="#cb67-53" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;E5: </span><span class="sc">{</span>e5_similarity<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb67-54"><a href="#cb67-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;GTE: </span><span class="sc">{</span>gte_similarity<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb67-55"><a href="#cb67-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;BGE: </span><span class="sc">{</span>bge_similarity<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb67-56"><a href="#cb67-56" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;inf_retrival: </span><span class="sc">{</span>inf_similarity<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb67-57"><a href="#cb67-57" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;BGE_m3: </span><span class="sc">{</span>bge_m3_similarity<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb67-58"><a href="#cb67-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;OpenAI: </span><span class="sc">{</span>openai_similarity<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span>
<span id="cb67-59"><a href="#cb67-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;codellama: </span><span class="sc">{</span>codellama_similarity<span class="sc">:.4f}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Average similarity between random samples:
E5: 0.8458
GTE: 0.8418
BGE: 0.6701
inf_retrival: 0.7993
BGE_m3: 0.6190
OpenAI: 0.7354
codellama: 0.8056
</code></pre>
</div>
</div>
<div id="beca2699" class="cell code" data-execution_count="31">
<div class="sourceCode" id="cb69"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize similarity comparison</span></span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [<span class="st">&#39;E5-large-v2&#39;</span>, <span class="st">&#39;GTE-Large&#39;</span>, <span class="st">&#39;BGE-Large&#39;</span>, <span class="st">&#39;Inf_retrival&#39;</span>, <span class="st">&#39;BGE-M3&#39;</span>, <span class="st">&#39;OpenAI&#39;</span>, <span class="st">&#39;codellama&#39;</span>]</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>similarities <span class="op">=</span> [e5_similarity, gte_similarity, bge_similarity, inf_similarity, </span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>                bge_m3_similarity, openai_similarity, codellama_similarity]</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Define colors based on code-specificity</span></span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>color_map <span class="op">=</span> {</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;E5-large-v2&#39;</span>: <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;GTE-Large&#39;</span>: <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;BGE-Large&#39;</span>: <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb69-13"><a href="#cb69-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Inf_retrival&#39;</span>: <span class="st">&#39;purple&#39;</span>,</span>
<span id="cb69-14"><a href="#cb69-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;BGE-M3&#39;</span>: <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb69-15"><a href="#cb69-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;OpenAI&#39;</span>: <span class="st">&#39;blue&#39;</span>,</span>
<span id="cb69-16"><a href="#cb69-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;codellama&#39;</span>: <span class="st">&#39;green&#39;</span></span>
<span id="cb69-17"><a href="#cb69-17" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb69-18"><a href="#cb69-18" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [color_map[model] <span class="cf">for</span> model <span class="kw">in</span> models]</span>
<span id="cb69-19"><a href="#cb69-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-20"><a href="#cb69-20" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb69-21"><a href="#cb69-21" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(models, similarities, color<span class="op">=</span>colors)</span>
<span id="cb69-22"><a href="#cb69-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Average Similarity Between Random Samples&#39;</span>)</span>
<span id="cb69-23"><a href="#cb69-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Cosine Similarity&#39;</span>)</span>
<span id="cb69-24"><a href="#cb69-24" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="dv">0</span>, <span class="dv">1</span>)  <span class="co"># Cosine similarity ranges from -1 to 1, but typically positive for embeddings</span></span>
<span id="cb69-25"><a href="#cb69-25" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">&#39;y&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb69-26"><a href="#cb69-26" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb69-27"><a href="#cb69-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-28"><a href="#cb69-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a legend for embedding types</span></span>
<span id="cb69-29"><a href="#cb69-29" aria-hidden="true" tabindex="-1"></a>legend_elements <span class="op">=</span> [</span>
<span id="cb69-30"><a href="#cb69-30" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">&#39;blue&#39;</span>, label<span class="op">=</span><span class="st">&#39;General Purpose&#39;</span>),</span>
<span id="cb69-31"><a href="#cb69-31" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">&#39;green&#39;</span>, label<span class="op">=</span><span class="st">&#39;Code-Specific&#39;</span>),</span>
<span id="cb69-32"><a href="#cb69-32" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">&#39;purple&#39;</span>, label<span class="op">=</span><span class="st">&#39;Instruction-tuned&#39;</span>)</span>
<span id="cb69-33"><a href="#cb69-33" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb69-34"><a href="#cb69-34" aria-hidden="true" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>legend_elements)</span>
<span id="cb69-35"><a href="#cb69-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-36"><a href="#cb69-36" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb69-37"><a href="#cb69-37" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;embedding_similarity.png&#39;</span>)</span>
<span id="cb69-38"><a href="#cb69-38" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_7f8823aad92e4582b6ad79177749d011/30403d471dc6201313a1dde08e323ef12cac98e3.png" /></p>
</div>
</div>
<div id="6e111759" class="cell code" data-execution_count="32">
<div class="sourceCode" id="cb70"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install qdrant_client</span></code></pre></div>
<div class="output stream stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Collecting qdrant_client
  Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 327.7/327.7 KB 1.7 MB/s eta 0:00:0000:0100:01
ent already satisfied: urllib3&lt;3,&gt;=1.26.14 in ./test_env/lib/python3.10/site-packages (from qdrant_client) (2.4.0)
Requirement already satisfied: httpx[http2]&gt;=0.20.0 in ./test_env/lib/python3.10/site-packages (from qdrant_client) (0.28.1)
Collecting portalocker&lt;3.0.0,&gt;=2.7.0
  Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)
Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,&gt;=1.10.8 in ./test_env/lib/python3.10/site-packages (from qdrant_client) (2.10.6)
Requirement already satisfied: grpcio&gt;=1.41.0 in ./test_env/lib/python3.10/site-packages (from qdrant_client) (1.71.0)
Requirement already satisfied: numpy&gt;=1.21 in ./test_env/lib/python3.10/site-packages (from qdrant_client) (1.26.4)
Requirement already satisfied: protobuf&gt;=3.20.0 in ./test_env/lib/python3.10/site-packages (from qdrant_client) (5.29.4)
Requirement already satisfied: idna in ./test_env/lib/python3.10/site-packages (from httpx[http2]&gt;=0.20.0-&gt;qdrant_client) (3.10)
Requirement already satisfied: httpcore==1.* in ./test_env/lib/python3.10/site-packages (from httpx[http2]&gt;=0.20.0-&gt;qdrant_client) (1.0.9)
Requirement already satisfied: certifi in ./test_env/lib/python3.10/site-packages (from httpx[http2]&gt;=0.20.0-&gt;qdrant_client) (2025.4.26)
Requirement already satisfied: anyio in ./test_env/lib/python3.10/site-packages (from httpx[http2]&gt;=0.20.0-&gt;qdrant_client) (4.9.0)
Collecting h2&lt;5,&gt;=3
  Downloading h2-4.2.0-py3-none-any.whl (60 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.0/61.0 KB 7.8 MB/s eta 0:00:00
ent already satisfied: h11&gt;=0.16 in ./test_env/lib/python3.10/site-packages (from httpcore==1.*-&gt;httpx[http2]&gt;=0.20.0-&gt;qdrant_client) (0.16.0)
Requirement already satisfied: annotated-types&gt;=0.6.0 in ./test_env/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,&gt;=1.10.8-&gt;qdrant_client) (0.7.0)
Requirement already satisfied: typing-extensions&gt;=4.12.2 in ./test_env/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,&gt;=1.10.8-&gt;qdrant_client) (4.13.2)
Requirement already satisfied: pydantic-core==2.27.2 in ./test_env/lib/python3.10/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,&gt;=1.10.8-&gt;qdrant_client) (2.27.2)
Collecting hpack&lt;5,&gt;=4.1
  Downloading hpack-4.1.0-py3-none-any.whl (34 kB)
Collecting hyperframe&lt;7,&gt;=6.1
  Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)
Requirement already satisfied: exceptiongroup&gt;=1.0.2 in ./test_env/lib/python3.10/site-packages (from anyio-&gt;httpx[http2]&gt;=0.20.0-&gt;qdrant_client) (1.3.0)
Requirement already satisfied: sniffio&gt;=1.1 in ./test_env/lib/python3.10/site-packages (from anyio-&gt;httpx[http2]&gt;=0.20.0-&gt;qdrant_client) (1.3.1)
Installing collected packages: portalocker, hyperframe, hpack, h2, qdrant_client
Successfully installed h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 portalocker-2.10.1 qdrant_client-1.14.2
</code></pre>
</div>
</div>
<div id="1cf6d0f5" class="cell code" data-execution_count="33">
<div class="sourceCode" id="cb73"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 5. Qdrant Setup for Embedding Comparison</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> qdrant_client <span class="im">import</span> QdrantClient</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> qdrant_client.http <span class="im">import</span> models</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>QDRANT_HOST <span class="op">=</span> <span class="st">&quot;localhost&quot;</span>  <span class="co"># If running Docker on the same machine</span></span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>QDRANT_PORT <span class="op">=</span> <span class="dv">6333</span>  <span class="co"># Default HTTP API port</span></span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>COLLECTION_NAME <span class="op">=</span> <span class="st">&quot;HIGH_DIM_EMBEDDING_COMPARISON&quot;</span></span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;1. Connecting to Qdrant server in Docker...&quot;</span>)</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>client <span class="op">=</span> QdrantClient(host<span class="op">=</span>QDRANT_HOST, port<span class="op">=</span>QDRANT_PORT, timeout<span class="op">=</span><span class="fl">10.0</span>)</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Delete existing collection if it exists</span></span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>    client.delete_collection(collection_name<span class="op">=</span>COLLECTION_NAME)</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Existing collection deleted.&quot;</span>)</span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">1</span>)  <span class="co"># Give the server time to process</span></span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span>:</span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;No existing collection to delete.&quot;</span>)</span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;2. Creating collection with multiple vector configurations...&quot;</span>)</span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create with named vectors configuration for all models</span></span>
<span id="cb73-27"><a href="#cb73-27" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if collection exists first</span></span>
<span id="cb73-28"><a href="#cb73-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> client.collection_exists(COLLECTION_NAME):</span>
<span id="cb73-29"><a href="#cb73-29" aria-hidden="true" tabindex="-1"></a>        client.delete_collection(COLLECTION_NAME)</span>
<span id="cb73-30"><a href="#cb73-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Deleted existing collection </span><span class="sc">{</span>COLLECTION_NAME<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb73-31"><a href="#cb73-31" aria-hidden="true" tabindex="-1"></a>        time.sleep(<span class="dv">1</span>)  <span class="co"># Give server time to process</span></span>
<span id="cb73-32"><a href="#cb73-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb73-33"><a href="#cb73-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create new collection with named vectors - following sample implementation</span></span>
<span id="cb73-34"><a href="#cb73-34" aria-hidden="true" tabindex="-1"></a>    client.create_collection(</span>
<span id="cb73-35"><a href="#cb73-35" aria-hidden="true" tabindex="-1"></a>        collection_name<span class="op">=</span>COLLECTION_NAME,</span>
<span id="cb73-36"><a href="#cb73-36" aria-hidden="true" tabindex="-1"></a>        vectors_config<span class="op">=</span>{</span>
<span id="cb73-37"><a href="#cb73-37" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;E5&quot;</span>: models.VectorParams(</span>
<span id="cb73-38"><a href="#cb73-38" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">1024</span>,  <span class="co"># Dimension for E5</span></span>
<span id="cb73-39"><a href="#cb73-39" aria-hidden="true" tabindex="-1"></a>                distance<span class="op">=</span>models.Distance.COSINE,</span>
<span id="cb73-40"><a href="#cb73-40" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb73-41"><a href="#cb73-41" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;GTE&quot;</span>: models.VectorParams(</span>
<span id="cb73-42"><a href="#cb73-42" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">1024</span>,  <span class="co"># Dimension for GTE</span></span>
<span id="cb73-43"><a href="#cb73-43" aria-hidden="true" tabindex="-1"></a>                distance<span class="op">=</span>models.Distance.COSINE,</span>
<span id="cb73-44"><a href="#cb73-44" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb73-45"><a href="#cb73-45" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;BGE&quot;</span>: models.VectorParams(</span>
<span id="cb73-46"><a href="#cb73-46" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">1024</span>,  <span class="co"># Dimension for BGE</span></span>
<span id="cb73-47"><a href="#cb73-47" aria-hidden="true" tabindex="-1"></a>                distance<span class="op">=</span>models.Distance.COSINE,</span>
<span id="cb73-48"><a href="#cb73-48" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb73-49"><a href="#cb73-49" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;INF_RETRIEVER_V1&quot;</span>: models.VectorParams(</span>
<span id="cb73-50"><a href="#cb73-50" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">3584</span>,  <span class="co"># Dimension for Cohere</span></span>
<span id="cb73-51"><a href="#cb73-51" aria-hidden="true" tabindex="-1"></a>                distance<span class="op">=</span>models.Distance.COSINE,</span>
<span id="cb73-52"><a href="#cb73-52" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb73-53"><a href="#cb73-53" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;BGE_M3&quot;</span>: models.VectorParams(</span>
<span id="cb73-54"><a href="#cb73-54" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">1024</span>,  <span class="co"># Dimension for Instructor</span></span>
<span id="cb73-55"><a href="#cb73-55" aria-hidden="true" tabindex="-1"></a>                distance<span class="op">=</span>models.Distance.COSINE,</span>
<span id="cb73-56"><a href="#cb73-56" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb73-57"><a href="#cb73-57" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;OpenAI&quot;</span>: models.VectorParams(</span>
<span id="cb73-58"><a href="#cb73-58" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">1536</span>,  <span class="co"># Dimension for OpenAI</span></span>
<span id="cb73-59"><a href="#cb73-59" aria-hidden="true" tabindex="-1"></a>                distance<span class="op">=</span>models.Distance.COSINE,</span>
<span id="cb73-60"><a href="#cb73-60" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb73-61"><a href="#cb73-61" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;codellama&quot;</span>: models.VectorParams(</span>
<span id="cb73-62"><a href="#cb73-62" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">4096</span>,  <span class="co"># Dimension for CodeLlama</span></span>
<span id="cb73-63"><a href="#cb73-63" aria-hidden="true" tabindex="-1"></a>                distance<span class="op">=</span>models.Distance.COSINE,</span>
<span id="cb73-64"><a href="#cb73-64" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb73-65"><a href="#cb73-65" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;ColBERT&quot;</span>: models.VectorParams(</span>
<span id="cb73-66"><a href="#cb73-66" aria-hidden="true" tabindex="-1"></a>                size<span class="op">=</span><span class="dv">128</span>,  <span class="co"># Dimension for single ColBERT vector</span></span>
<span id="cb73-67"><a href="#cb73-67" aria-hidden="true" tabindex="-1"></a>                distance<span class="op">=</span>models.Distance.COSINE,</span>
<span id="cb73-68"><a href="#cb73-68" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Configure for late interaction (multiple vectors per document)</span></span>
<span id="cb73-69"><a href="#cb73-69" aria-hidden="true" tabindex="-1"></a>                multivector_config<span class="op">=</span>models.MultiVectorConfig(</span>
<span id="cb73-70"><a href="#cb73-70" aria-hidden="true" tabindex="-1"></a>                    comparator<span class="op">=</span>models.MultiVectorComparator.MAX_SIM,</span>
<span id="cb73-71"><a href="#cb73-71" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb73-72"><a href="#cb73-72" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb73-73"><a href="#cb73-73" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb73-74"><a href="#cb73-74" aria-hidden="true" tabindex="-1"></a>        sparse_vectors_config<span class="op">=</span>{</span>
<span id="cb73-75"><a href="#cb73-75" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;BM25&quot;</span>: models.SparseVectorParams(</span>
<span id="cb73-76"><a href="#cb73-76" aria-hidden="true" tabindex="-1"></a>                modifier<span class="op">=</span>models.Modifier.IDF,</span>
<span id="cb73-77"><a href="#cb73-77" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb73-78"><a href="#cb73-78" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb73-79"><a href="#cb73-79" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb73-80"><a href="#cb73-80" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Collection created successfully!&quot;</span>)</span>
<span id="cb73-81"><a href="#cb73-81" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-82"><a href="#cb73-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verify collection was created</span></span>
<span id="cb73-83"><a href="#cb73-83" aria-hidden="true" tabindex="-1"></a>    collection_info <span class="op">=</span> client.get_collection(COLLECTION_NAME)</span>
<span id="cb73-84"><a href="#cb73-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Collection status: </span><span class="sc">{</span>collection_info<span class="sc">.</span>status<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb73-85"><a href="#cb73-85" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-86"><a href="#cb73-86" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The collection config structure may vary by Qdrant version</span></span>
<span id="cb73-87"><a href="#cb73-87" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the entire structure to inspect</span></span>
<span id="cb73-88"><a href="#cb73-88" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Collection configuration:&quot;</span>)</span>
<span id="cb73-89"><a href="#cb73-89" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(collection_info)</span>
<span id="cb73-90"><a href="#cb73-90" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb73-91"><a href="#cb73-91" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb73-92"><a href="#cb73-92" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Failed to create collection: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb73-93"><a href="#cb73-93" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Please check Qdrant server connectivity and client version.&quot;</span>)</span>
<span id="cb73-94"><a href="#cb73-94" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> sys</span>
<span id="cb73-95"><a href="#cb73-95" aria-hidden="true" tabindex="-1"></a>    sys.exit(<span class="dv">1</span>)  <span class="co"># Exit if we can&#39;t create the collection</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>1. Connecting to Qdrant server in Docker...
Existing collection deleted.
2. Creating collection with multiple vector configurations...
Collection created successfully!
Collection status: green
Collection configuration:
status=&lt;CollectionStatus.GREEN: &#39;green&#39;&gt; optimizer_status=&lt;OptimizersStatusOneOf.OK: &#39;ok&#39;&gt; vectors_count=None indexed_vectors_count=0 points_count=0 segments_count=8 config=CollectionConfig(params=CollectionParams(vectors={&#39;BGE&#39;: VectorParams(size=1024, distance=&lt;Distance.COSINE: &#39;Cosine&#39;&gt;, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), &#39;BGE_M3&#39;: VectorParams(size=1024, distance=&lt;Distance.COSINE: &#39;Cosine&#39;&gt;, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), &#39;ColBERT&#39;: VectorParams(size=128, distance=&lt;Distance.COSINE: &#39;Cosine&#39;&gt;, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=MultiVectorConfig(comparator=&lt;MultiVectorComparator.MAX_SIM: &#39;max_sim&#39;&gt;)), &#39;E5&#39;: VectorParams(size=1024, distance=&lt;Distance.COSINE: &#39;Cosine&#39;&gt;, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), &#39;GTE&#39;: VectorParams(size=1024, distance=&lt;Distance.COSINE: &#39;Cosine&#39;&gt;, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), &#39;INF_RETRIEVER_V1&#39;: VectorParams(size=3584, distance=&lt;Distance.COSINE: &#39;Cosine&#39;&gt;, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), &#39;OpenAI&#39;: VectorParams(size=1536, distance=&lt;Distance.COSINE: &#39;Cosine&#39;&gt;, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), &#39;codellama&#39;: VectorParams(size=4096, distance=&lt;Distance.COSINE: &#39;Cosine&#39;&gt;, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None)}, shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors={&#39;BM25&#39;: SparseVectorParams(index=None, modifier=&lt;Modifier.IDF: &#39;idf&#39;&gt;)}), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=StrictModeConfigOutput(enabled=False, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=None, unindexed_filtering_update=None, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None)) payload_schema={}
</code></pre>
</div>
</div>
<div id="52f00888" class="cell code" data-execution_count="34">
<div class="sourceCode" id="cb75"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define upload_all_embeddings function</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> upload_all_embeddings(data, embeddings_dict, batch_size<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Upload embeddings to Qdrant server using named vectors.</span></span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb75-6"><a href="#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb75-7"><a href="#cb75-7" aria-hidden="true" tabindex="-1"></a><span class="co">    - data: List of dictionaries or DataFrame containing document data</span></span>
<span id="cb75-8"><a href="#cb75-8" aria-hidden="true" tabindex="-1"></a><span class="co">    - embeddings_dict: Dictionary with model names as keys and embedding arrays as values</span></span>
<span id="cb75-9"><a href="#cb75-9" aria-hidden="true" tabindex="-1"></a><span class="co">    - batch_size: Number of points to upload in a single batch</span></span>
<span id="cb75-10"><a href="#cb75-10" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb75-11"><a href="#cb75-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb75-12"><a href="#cb75-12" aria-hidden="true" tabindex="-1"></a><span class="co">    - Boolean indicating success</span></span>
<span id="cb75-13"><a href="#cb75-13" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb75-14"><a href="#cb75-14" aria-hidden="true" tabindex="-1"></a>    total_points <span class="op">=</span> <span class="bu">len</span>(data)</span>
<span id="cb75-15"><a href="#cb75-15" aria-hidden="true" tabindex="-1"></a>    points <span class="op">=</span> []</span>
<span id="cb75-16"><a href="#cb75-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-17"><a href="#cb75-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Determine the maximum number of points we can process</span></span>
<span id="cb75-18"><a href="#cb75-18" aria-hidden="true" tabindex="-1"></a>    max_points <span class="op">=</span> total_points</span>
<span id="cb75-19"><a href="#cb75-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name, embeddings <span class="kw">in</span> embeddings_dict.items():</span>
<span id="cb75-20"><a href="#cb75-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> embeddings <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb75-21"><a href="#cb75-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(embeddings, <span class="bu">list</span>) <span class="kw">or</span> <span class="bu">isinstance</span>(embeddings, np.ndarray):</span>
<span id="cb75-22"><a href="#cb75-22" aria-hidden="true" tabindex="-1"></a>                max_points <span class="op">=</span> <span class="bu">min</span>(max_points, <span class="bu">len</span>(embeddings))</span>
<span id="cb75-23"><a href="#cb75-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-24"><a href="#cb75-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Processing </span><span class="sc">{</span>max_points<span class="sc">}</span><span class="ss"> points (limited by smallest array)&quot;</span>)</span>
<span id="cb75-25"><a href="#cb75-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-26"><a href="#cb75-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if data is a DataFrame or a list</span></span>
<span id="cb75-27"><a href="#cb75-27" aria-hidden="true" tabindex="-1"></a>    is_dataframe <span class="op">=</span> <span class="bu">hasattr</span>(data, <span class="st">&#39;iloc&#39;</span>)</span>
<span id="cb75-28"><a href="#cb75-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-29"><a href="#cb75-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(max_points):</span>
<span id="cb75-30"><a href="#cb75-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create named vector dict for all model embeddings</span></span>
<span id="cb75-31"><a href="#cb75-31" aria-hidden="true" tabindex="-1"></a>        vector_dict <span class="op">=</span> {}</span>
<span id="cb75-32"><a href="#cb75-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-33"><a href="#cb75-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add dense embeddings (named vectors)</span></span>
<span id="cb75-34"><a href="#cb75-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> model_name, embeddings <span class="kw">in</span> embeddings_dict.items():</span>
<span id="cb75-35"><a href="#cb75-35" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;BM25&#39;</span> <span class="kw">or</span> model_name <span class="op">==</span> <span class="st">&#39;ColBERT&#39;</span>:</span>
<span id="cb75-36"><a href="#cb75-36" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span>  <span class="co"># Skip special types, handle separately</span></span>
<span id="cb75-37"><a href="#cb75-37" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb75-38"><a href="#cb75-38" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> embeddings <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> i <span class="op">&lt;</span> <span class="bu">len</span>(embeddings) <span class="kw">and</span> embeddings[i] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb75-39"><a href="#cb75-39" aria-hidden="true" tabindex="-1"></a>                vector_value <span class="op">=</span> embeddings[i].tolist() <span class="cf">if</span> <span class="bu">hasattr</span>(embeddings[i], <span class="st">&#39;tolist&#39;</span>) <span class="cf">else</span> embeddings[i]</span>
<span id="cb75-40"><a href="#cb75-40" aria-hidden="true" tabindex="-1"></a>                vector_dict[model_name] <span class="op">=</span> vector_value</span>
<span id="cb75-41"><a href="#cb75-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-42"><a href="#cb75-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add BM25 sparse embeddings</span></span>
<span id="cb75-43"><a href="#cb75-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">&#39;BM25&#39;</span> <span class="kw">in</span> embeddings_dict <span class="kw">and</span> embeddings_dict[<span class="st">&#39;BM25&#39;</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb75-44"><a href="#cb75-44" aria-hidden="true" tabindex="-1"></a>            bm25_embeddings <span class="op">=</span> embeddings_dict[<span class="st">&#39;BM25&#39;</span>]</span>
<span id="cb75-45"><a href="#cb75-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&lt;</span> <span class="bu">len</span>(bm25_embeddings) <span class="kw">and</span> bm25_embeddings[i] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb75-46"><a href="#cb75-46" aria-hidden="true" tabindex="-1"></a>                <span class="co"># For BM25, try to use as_object() method as shown in the sample</span></span>
<span id="cb75-47"><a href="#cb75-47" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">hasattr</span>(bm25_embeddings[i], <span class="st">&#39;as_object&#39;</span>):</span>
<span id="cb75-48"><a href="#cb75-48" aria-hidden="true" tabindex="-1"></a>                    vector_dict[<span class="st">&quot;BM25&quot;</span>] <span class="op">=</span> bm25_embeddings[i].as_object()</span>
<span id="cb75-49"><a href="#cb75-49" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If no as_object method, but has proper structure</span></span>
<span id="cb75-50"><a href="#cb75-50" aria-hidden="true" tabindex="-1"></a>                <span class="cf">elif</span> <span class="bu">hasattr</span>(bm25_embeddings[i], <span class="st">&#39;indices&#39;</span>) <span class="kw">and</span> <span class="bu">hasattr</span>(bm25_embeddings[i], <span class="st">&#39;values&#39;</span>):</span>
<span id="cb75-51"><a href="#cb75-51" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Create a compatible format</span></span>
<span id="cb75-52"><a href="#cb75-52" aria-hidden="true" tabindex="-1"></a>                    vector_dict[<span class="st">&quot;BM25&quot;</span>] <span class="op">=</span> {</span>
<span id="cb75-53"><a href="#cb75-53" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;indices&#39;</span>: bm25_embeddings[i].indices.tolist() <span class="cf">if</span> <span class="bu">hasattr</span>(bm25_embeddings[i].indices, <span class="st">&#39;tolist&#39;</span>) <span class="cf">else</span> bm25_embeddings[i].indices,</span>
<span id="cb75-54"><a href="#cb75-54" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;values&#39;</span>: bm25_embeddings[i].values.tolist() <span class="cf">if</span> <span class="bu">hasattr</span>(bm25_embeddings[i].values, <span class="st">&#39;tolist&#39;</span>) <span class="cf">else</span> bm25_embeddings[i].values</span>
<span id="cb75-55"><a href="#cb75-55" aria-hidden="true" tabindex="-1"></a>                    }</span>
<span id="cb75-56"><a href="#cb75-56" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If it&#39;s already a dict with indices and values</span></span>
<span id="cb75-57"><a href="#cb75-57" aria-hidden="true" tabindex="-1"></a>                <span class="cf">elif</span> <span class="bu">isinstance</span>(bm25_embeddings[i], <span class="bu">dict</span>) <span class="kw">and</span> <span class="st">&#39;indices&#39;</span> <span class="kw">in</span> bm25_embeddings[i] <span class="kw">and</span> <span class="st">&#39;values&#39;</span> <span class="kw">in</span> bm25_embeddings[i]:</span>
<span id="cb75-58"><a href="#cb75-58" aria-hidden="true" tabindex="-1"></a>                    vector_dict[<span class="st">&quot;BM25&quot;</span>] <span class="op">=</span> bm25_embeddings[i]</span>
<span id="cb75-59"><a href="#cb75-59" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb75-60"><a href="#cb75-60" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;Skipping BM25 for point </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: format not compatible&quot;</span>)</span>
<span id="cb75-61"><a href="#cb75-61" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-62"><a href="#cb75-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add ColBERT late interaction embeddings (multi-vector)</span></span>
<span id="cb75-63"><a href="#cb75-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">&#39;ColBERT&#39;</span> <span class="kw">in</span> embeddings_dict <span class="kw">and</span> embeddings_dict[<span class="st">&#39;ColBERT&#39;</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb75-64"><a href="#cb75-64" aria-hidden="true" tabindex="-1"></a>            late_interaction_embeddings <span class="op">=</span> embeddings_dict[<span class="st">&#39;ColBERT&#39;</span>]</span>
<span id="cb75-65"><a href="#cb75-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&lt;</span> <span class="bu">len</span>(late_interaction_embeddings) <span class="kw">and</span> late_interaction_embeddings[i] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb75-66"><a href="#cb75-66" aria-hidden="true" tabindex="-1"></a>                <span class="co"># For late interaction, we expect a list of vectors (one per token)</span></span>
<span id="cb75-67"><a href="#cb75-67" aria-hidden="true" tabindex="-1"></a>                colbert_vectors <span class="op">=</span> late_interaction_embeddings[i]</span>
<span id="cb75-68"><a href="#cb75-68" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Make sure we have a list of lists</span></span>
<span id="cb75-69"><a href="#cb75-69" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(colbert_vectors, np.ndarray):</span>
<span id="cb75-70"><a href="#cb75-70" aria-hidden="true" tabindex="-1"></a>                    colbert_vectors <span class="op">=</span> colbert_vectors.tolist()</span>
<span id="cb75-71"><a href="#cb75-71" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Ensure each vector is a list</span></span>
<span id="cb75-72"><a href="#cb75-72" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> colbert_vectors <span class="kw">and</span> <span class="bu">hasattr</span>(colbert_vectors[<span class="dv">0</span>], <span class="st">&#39;tolist&#39;</span>):</span>
<span id="cb75-73"><a href="#cb75-73" aria-hidden="true" tabindex="-1"></a>                    colbert_vectors <span class="op">=</span> [v.tolist() <span class="cf">for</span> v <span class="kw">in</span> colbert_vectors]</span>
<span id="cb75-74"><a href="#cb75-74" aria-hidden="true" tabindex="-1"></a>                vector_dict[<span class="st">&quot;ColBERT&quot;</span>] <span class="op">=</span> colbert_vectors</span>
<span id="cb75-75"><a href="#cb75-75" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-76"><a href="#cb75-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># If we have no vectors, skip this point</span></span>
<span id="cb75-77"><a href="#cb75-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> vector_dict:</span>
<span id="cb75-78"><a href="#cb75-78" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Skipping point </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> because no vectors are available&quot;</span>)</span>
<span id="cb75-79"><a href="#cb75-79" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb75-80"><a href="#cb75-80" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb75-81"><a href="#cb75-81" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create payload based on data type</span></span>
<span id="cb75-82"><a href="#cb75-82" aria-hidden="true" tabindex="-1"></a>        payload <span class="op">=</span> {}</span>
<span id="cb75-83"><a href="#cb75-83" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-84"><a href="#cb75-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> is_dataframe <span class="kw">and</span> i <span class="op">&lt;</span> <span class="bu">len</span>(data):</span>
<span id="cb75-85"><a href="#cb75-85" aria-hidden="true" tabindex="-1"></a>            row <span class="op">=</span> data.iloc[i]</span>
<span id="cb75-86"><a href="#cb75-86" aria-hidden="true" tabindex="-1"></a>            text_content <span class="op">=</span> row.get(<span class="st">&#39;doc&#39;</span>, <span class="st">&#39;&#39;</span>) <span class="cf">if</span> <span class="bu">hasattr</span>(row, <span class="st">&#39;get&#39;</span>) <span class="cf">else</span> row[<span class="st">&#39;doc&#39;</span>] <span class="cf">if</span> <span class="st">&#39;doc&#39;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="st">&quot;&quot;</span></span>
<span id="cb75-87"><a href="#cb75-87" aria-hidden="true" tabindex="-1"></a>            payload.update({</span>
<span id="cb75-88"><a href="#cb75-88" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;text&quot;</span>: text_content,</span>
<span id="cb75-89"><a href="#cb75-89" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;title&quot;</span>: row.get(<span class="st">&#39;title&#39;</span>, <span class="st">&#39;&#39;</span>) <span class="cf">if</span> <span class="bu">hasattr</span>(row, <span class="st">&#39;get&#39;</span>) <span class="cf">else</span> row[<span class="st">&#39;title&#39;</span>] <span class="cf">if</span> <span class="st">&#39;title&#39;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb75-90"><a href="#cb75-90" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;code_snippet&quot;</span>: row.get(<span class="st">&#39;code_snippet&#39;</span>, <span class="st">&#39;&#39;</span>) <span class="cf">if</span> <span class="bu">hasattr</span>(row, <span class="st">&#39;get&#39;</span>) <span class="cf">else</span> row[<span class="st">&#39;code_snippet&#39;</span>] <span class="cf">if</span> <span class="st">&#39;code_snippet&#39;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb75-91"><a href="#cb75-91" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;length&quot;</span>: row.get(<span class="st">&#39;length&#39;</span>, <span class="dv">0</span>) <span class="cf">if</span> <span class="bu">hasattr</span>(row, <span class="st">&#39;get&#39;</span>) <span class="cf">else</span> row[<span class="st">&#39;length&#39;</span>] <span class="cf">if</span> <span class="st">&#39;length&#39;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="dv">0</span>,</span>
<span id="cb75-92"><a href="#cb75-92" aria-hidden="true" tabindex="-1"></a>                <span class="st">&quot;filename&quot;</span>: row.get(<span class="st">&#39;filename&#39;</span>, <span class="st">&#39;&#39;</span>) <span class="cf">if</span> <span class="bu">hasattr</span>(row, <span class="st">&#39;get&#39;</span>) <span class="cf">else</span> row[<span class="st">&#39;filename&#39;</span>] <span class="cf">if</span> <span class="st">&#39;filename&#39;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="st">&quot;&quot;</span></span>
<span id="cb75-93"><a href="#cb75-93" aria-hidden="true" tabindex="-1"></a>            })</span>
<span id="cb75-94"><a href="#cb75-94" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> <span class="kw">not</span> is_dataframe <span class="kw">and</span> i <span class="op">&lt;</span> <span class="bu">len</span>(data):</span>
<span id="cb75-95"><a href="#cb75-95" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(data[i], <span class="bu">dict</span>):</span>
<span id="cb75-96"><a href="#cb75-96" aria-hidden="true" tabindex="-1"></a>                text_content <span class="op">=</span> data[i].get(<span class="st">&quot;text&quot;</span>, data[i].get(<span class="st">&quot;doc&quot;</span>, <span class="st">&quot;&quot;</span>))</span>
<span id="cb75-97"><a href="#cb75-97" aria-hidden="true" tabindex="-1"></a>                payload[<span class="st">&quot;text&quot;</span>] <span class="op">=</span> text_content</span>
<span id="cb75-98"><a href="#cb75-98" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb75-99"><a href="#cb75-99" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Extract metadata directly</span></span>
<span id="cb75-100"><a href="#cb75-100" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> field <span class="kw">in</span> [<span class="st">&quot;title&quot;</span>, <span class="st">&quot;code_snippet&quot;</span>, <span class="st">&quot;length&quot;</span>, <span class="st">&quot;filename&quot;</span>]:</span>
<span id="cb75-101"><a href="#cb75-101" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> field <span class="kw">in</span> data[i]:</span>
<span id="cb75-102"><a href="#cb75-102" aria-hidden="true" tabindex="-1"></a>                        <span class="co"># Convert numpy types to Python native types</span></span>
<span id="cb75-103"><a href="#cb75-103" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">if</span> <span class="bu">hasattr</span>(data[i][field], <span class="st">&#39;item&#39;</span>):</span>
<span id="cb75-104"><a href="#cb75-104" aria-hidden="true" tabindex="-1"></a>                            payload[field] <span class="op">=</span> data[i][field].item()</span>
<span id="cb75-105"><a href="#cb75-105" aria-hidden="true" tabindex="-1"></a>                        <span class="cf">else</span>:</span>
<span id="cb75-106"><a href="#cb75-106" aria-hidden="true" tabindex="-1"></a>                            payload[field] <span class="op">=</span> data[i][field]</span>
<span id="cb75-107"><a href="#cb75-107" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb75-108"><a href="#cb75-108" aria-hidden="true" tabindex="-1"></a>                payload[<span class="st">&quot;text&quot;</span>] <span class="op">=</span> data[i]</span>
<span id="cb75-109"><a href="#cb75-109" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-110"><a href="#cb75-110" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert any numpy types to native Python types for JSON serialization</span></span>
<span id="cb75-111"><a href="#cb75-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> key, value <span class="kw">in</span> payload.items():</span>
<span id="cb75-112"><a href="#cb75-112" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">hasattr</span>(value, <span class="st">&#39;item&#39;</span>):</span>
<span id="cb75-113"><a href="#cb75-113" aria-hidden="true" tabindex="-1"></a>                payload[key] <span class="op">=</span> value.item()</span>
<span id="cb75-114"><a href="#cb75-114" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Handle string-like numpy objects</span></span>
<span id="cb75-115"><a href="#cb75-115" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">hasattr</span>(value, <span class="st">&#39;decode&#39;</span>) <span class="kw">and</span> <span class="bu">callable</span>(<span class="bu">getattr</span>(value, <span class="st">&#39;decode&#39;</span>)):</span>
<span id="cb75-116"><a href="#cb75-116" aria-hidden="true" tabindex="-1"></a>                <span class="cf">try</span>:</span>
<span id="cb75-117"><a href="#cb75-117" aria-hidden="true" tabindex="-1"></a>                    payload[key] <span class="op">=</span> value.decode(<span class="st">&#39;utf-8&#39;</span>)</span>
<span id="cb75-118"><a href="#cb75-118" aria-hidden="true" tabindex="-1"></a>                <span class="cf">except</span>:</span>
<span id="cb75-119"><a href="#cb75-119" aria-hidden="true" tabindex="-1"></a>                    payload[key] <span class="op">=</span> <span class="bu">str</span>(value)</span>
<span id="cb75-120"><a href="#cb75-120" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-121"><a href="#cb75-121" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Truncate very long text fields to avoid potential issues with server</span></span>
<span id="cb75-122"><a href="#cb75-122" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> field <span class="kw">in</span> [<span class="st">&quot;text&quot;</span>, <span class="st">&quot;title&quot;</span>, <span class="st">&quot;code_snippet&quot;</span>, <span class="st">&quot;filename&quot;</span>]:</span>
<span id="cb75-123"><a href="#cb75-123" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> field <span class="kw">in</span> payload <span class="kw">and</span> <span class="bu">isinstance</span>(payload[field], <span class="bu">str</span>) <span class="kw">and</span> <span class="bu">len</span>(payload[field]) <span class="op">&gt;</span> <span class="dv">65535</span>:</span>
<span id="cb75-124"><a href="#cb75-124" aria-hidden="true" tabindex="-1"></a>                payload[field] <span class="op">=</span> payload[field][:<span class="dv">65535</span>]</span>
<span id="cb75-125"><a href="#cb75-125" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;Truncated </span><span class="sc">{</span>field<span class="sc">}</span><span class="ss"> field for point </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss"> (too long)&quot;</span>)</span>
<span id="cb75-126"><a href="#cb75-126" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-127"><a href="#cb75-127" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create point</span></span>
<span id="cb75-128"><a href="#cb75-128" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb75-129"><a href="#cb75-129" aria-hidden="true" tabindex="-1"></a>            points.append(models.PointStruct(</span>
<span id="cb75-130"><a href="#cb75-130" aria-hidden="true" tabindex="-1"></a>                <span class="bu">id</span><span class="op">=</span>i,</span>
<span id="cb75-131"><a href="#cb75-131" aria-hidden="true" tabindex="-1"></a>                vector<span class="op">=</span>vector_dict,</span>
<span id="cb75-132"><a href="#cb75-132" aria-hidden="true" tabindex="-1"></a>                payload<span class="op">=</span>payload</span>
<span id="cb75-133"><a href="#cb75-133" aria-hidden="true" tabindex="-1"></a>            ))</span>
<span id="cb75-134"><a href="#cb75-134" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb75-135"><a href="#cb75-135" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Error creating point </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb75-136"><a href="#cb75-136" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="st">&#39;BM25&#39;</span> <span class="kw">in</span> vector_dict:</span>
<span id="cb75-137"><a href="#cb75-137" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;BM25 type: </span><span class="sc">{</span><span class="bu">type</span>(vector_dict[<span class="st">&#39;BM25&#39;</span>])<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb75-138"><a href="#cb75-138" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(vector_dict[<span class="st">&#39;BM25&#39;</span>], <span class="bu">dict</span>):</span>
<span id="cb75-139"><a href="#cb75-139" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;BM25 keys: </span><span class="sc">{</span><span class="bu">list</span>(vector_dict[<span class="st">&#39;BM25&#39;</span>].keys())<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb75-140"><a href="#cb75-140" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb75-141"><a href="#cb75-141" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb75-142"><a href="#cb75-142" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Upload in batches</span></span>
<span id="cb75-143"><a href="#cb75-143" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(points) <span class="op">&gt;=</span> batch_size <span class="kw">or</span> i <span class="op">==</span> max_points <span class="op">-</span> <span class="dv">1</span>:</span>
<span id="cb75-144"><a href="#cb75-144" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> points:  <span class="co"># Only upload if we have points</span></span>
<span id="cb75-145"><a href="#cb75-145" aria-hidden="true" tabindex="-1"></a>                <span class="cf">try</span>:</span>
<span id="cb75-146"><a href="#cb75-146" aria-hidden="true" tabindex="-1"></a>                    client.upsert(</span>
<span id="cb75-147"><a href="#cb75-147" aria-hidden="true" tabindex="-1"></a>                        collection_name<span class="op">=</span>COLLECTION_NAME,</span>
<span id="cb75-148"><a href="#cb75-148" aria-hidden="true" tabindex="-1"></a>                        points<span class="op">=</span>points,</span>
<span id="cb75-149"><a href="#cb75-149" aria-hidden="true" tabindex="-1"></a>                        wait<span class="op">=</span><span class="va">True</span>  <span class="co"># Wait for the server to process the points</span></span>
<span id="cb75-150"><a href="#cb75-150" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb75-151"><a href="#cb75-151" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;Successfully uploaded batch of </span><span class="sc">{</span><span class="bu">len</span>(points)<span class="sc">}</span><span class="ss"> points to server&quot;</span>)</span>
<span id="cb75-152"><a href="#cb75-152" aria-hidden="true" tabindex="-1"></a>                    points <span class="op">=</span> []</span>
<span id="cb75-153"><a href="#cb75-153" aria-hidden="true" tabindex="-1"></a>                <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb75-154"><a href="#cb75-154" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;Error uploading batch to server: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb75-155"><a href="#cb75-155" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> points:</span>
<span id="cb75-156"><a href="#cb75-156" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">print</span>(<span class="ss">f&quot;First point in failed batch id: </span><span class="sc">{</span>points[<span class="dv">0</span>]<span class="sc">.</span><span class="bu">id</span> <span class="cf">if</span> <span class="bu">hasattr</span>(points[<span class="dv">0</span>], <span class="st">&#39;id&#39;</span>) <span class="cf">else</span> <span class="st">&#39;Unknown&#39;</span><span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb75-157"><a href="#cb75-157" aria-hidden="true" tabindex="-1"></a>                    <span class="im">import</span> traceback</span>
<span id="cb75-158"><a href="#cb75-158" aria-hidden="true" tabindex="-1"></a>                    traceback.print_exc()</span>
<span id="cb75-159"><a href="#cb75-159" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Don&#39;t immediately return, try to continue with the next batch</span></span>
<span id="cb75-160"><a href="#cb75-160" aria-hidden="true" tabindex="-1"></a>                    points <span class="op">=</span> []</span>
<span id="cb75-161"><a href="#cb75-161" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb75-162"><a href="#cb75-162" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="va">True</span></span></code></pre></div>
</div>
<div id="7206bea7" class="cell code" data-execution_count="35">
<div class="sourceCode" id="cb76"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare embeddings dictionary</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;3. Preparing data for upload...&quot;</span>)</span>
<span id="cb76-3"><a href="#cb76-3" aria-hidden="true" tabindex="-1"></a>embeddings_dict <span class="op">=</span> {</span>
<span id="cb76-4"><a href="#cb76-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;E5&quot;</span>: e5_embeddings,</span>
<span id="cb76-5"><a href="#cb76-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;GTE&quot;</span>: gte_embeddings,</span>
<span id="cb76-6"><a href="#cb76-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;BGE&quot;</span>: bge_embeddings,</span>
<span id="cb76-7"><a href="#cb76-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;INF_RETRIEVER_V1&quot;</span>: inf_embeddings,</span>
<span id="cb76-8"><a href="#cb76-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;BGE_M3&quot;</span>: bge_m3_embeddings,</span>
<span id="cb76-9"><a href="#cb76-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;OpenAI&quot;</span>: openai_embeddings,</span>
<span id="cb76-10"><a href="#cb76-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;codellama&quot;</span>: codellama_embeddings,</span>
<span id="cb76-11"><a href="#cb76-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;BM25&quot;</span>: bm25_embeddings,</span>
<span id="cb76-12"><a href="#cb76-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;ColBERT&quot;</span>: late_interaction_embeddings</span>
<span id="cb76-13"><a href="#cb76-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="output stream stdout">
<pre><code>3. Preparing data for upload...
</code></pre>
</div>
</div>
<div id="caec34d5" class="cell code" data-execution_count="36">
<div class="sourceCode" id="cb78"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create structured_texts from DataFrame</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>structured_texts <span class="op">=</span> []</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(final_dataset)):</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> final_dataset.iloc[i]</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert any numpy types to native Python types</span></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>    length_value <span class="op">=</span> row[<span class="st">&quot;length&quot;</span>] <span class="cf">if</span> <span class="st">&quot;length&quot;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="dv">0</span></span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(length_value, <span class="st">&#39;item&#39;</span>):</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>        length_value <span class="op">=</span> length_value.item()</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>    structured_texts.append({</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;text&quot;</span>: row[<span class="st">&quot;doc&quot;</span>] <span class="cf">if</span> <span class="st">&quot;doc&quot;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;title&quot;</span>: row[<span class="st">&quot;title&quot;</span>] <span class="cf">if</span> <span class="st">&quot;title&quot;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;code_snippet&quot;</span>: row[<span class="st">&quot;code_snippet&quot;</span>] <span class="cf">if</span> <span class="st">&quot;code_snippet&quot;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;length&quot;</span>: length_value,</span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;filename&quot;</span>: row[<span class="st">&quot;filename&quot;</span>] <span class="cf">if</span> <span class="st">&quot;filename&quot;</span> <span class="kw">in</span> row <span class="cf">else</span> <span class="st">&quot;&quot;</span></span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Define how many samples to use (limited to 100 for demonstration)</span></span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a>max_samples <span class="op">=</span> <span class="bu">min</span>(<span class="dv">100</span>, <span class="bu">len</span>(structured_texts))</span>
<span id="cb78-21"><a href="#cb78-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-22"><a href="#cb78-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subset of data</span></span>
<span id="cb78-23"><a href="#cb78-23" aria-hidden="true" tabindex="-1"></a>subset_texts <span class="op">=</span> structured_texts[:max_samples]</span>
<span id="cb78-24"><a href="#cb78-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-25"><a href="#cb78-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Using </span><span class="sc">{</span>max_samples<span class="sc">}</span><span class="ss"> samples for upload&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Using 100 samples for upload
</code></pre>
</div>
</div>
<div id="7d70f2e7" class="cell code" data-execution_count="37">
<div class="sourceCode" id="cb80"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Upload the embeddings</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;4. Uploading embeddings to Qdrant...&quot;</span>)</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a>upload_success <span class="op">=</span> upload_all_embeddings(</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a>    subset_texts,</span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>    embeddings_dict,</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span><span class="dv">4</span>  <span class="co"># Reduced batch size for complex vectors</span></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> upload_success:</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;All embeddings uploaded successfully to Qdrant server&quot;</span>)</span>
<span id="cb80-11"><a href="#cb80-11" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb80-12"><a href="#cb80-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;There were issues during the upload process&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>4. Uploading embeddings to Qdrant...
Processing 100 points (limited by smallest array)
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
Successfully uploaded batch of 4 points to server
All embeddings uploaded successfully to Qdrant server
</code></pre>
</div>
</div>
<div id="14909695" class="cell code" data-execution_count="38">
<div class="sourceCode" id="cb82"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify upload and optimize collection</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;5. Verifying upload and optimizing collection...&quot;</span>)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Verify collection status</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a>    collection_info <span class="op">=</span> client.get_collection(COLLECTION_NAME)</span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Collection points count: </span><span class="sc">{</span>collection_info<span class="sc">.</span>points_count<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Force collection optimization</span></span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Forcing collection optimization...&quot;</span>)</span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>    client.update_collection(</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a>        collection_name<span class="op">=</span>COLLECTION_NAME,</span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>        optimizers_config<span class="op">=</span>models.OptimizersConfigDiff(</span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>            indexing_threshold<span class="op">=</span><span class="dv">0</span>  <span class="co"># Force immediate indexing</span></span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Optimization requested&quot;</span>)</span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Wait for indexing</span></span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Waiting for indexing to complete...&quot;</span>)</span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a>    time.sleep(<span class="dv">5</span>)</span>
<span id="cb82-21"><a href="#cb82-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-22"><a href="#cb82-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check updated collection status</span></span>
<span id="cb82-23"><a href="#cb82-23" aria-hidden="true" tabindex="-1"></a>    collection_info <span class="op">=</span> client.get_collection(COLLECTION_NAME)</span>
<span id="cb82-24"><a href="#cb82-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Updated points count: </span><span class="sc">{</span>collection_info<span class="sc">.</span>points_count<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb82-25"><a href="#cb82-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-26"><a href="#cb82-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Count points directly</span></span>
<span id="cb82-27"><a href="#cb82-27" aria-hidden="true" tabindex="-1"></a>    count_response <span class="op">=</span> client.count(collection_name<span class="op">=</span>COLLECTION_NAME)</span>
<span id="cb82-28"><a href="#cb82-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Actual points count: </span><span class="sc">{</span>count_response<span class="sc">.</span>count<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb82-29"><a href="#cb82-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-30"><a href="#cb82-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print a sample search to verify everything works</span></span>
<span id="cb82-31"><a href="#cb82-31" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Testing search with E5 vector...&quot;</span>)</span>
<span id="cb82-32"><a href="#cb82-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(e5_embeddings, np.ndarray) <span class="kw">and</span> e5_embeddings.shape[<span class="dv">0</span>] <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb82-33"><a href="#cb82-33" aria-hidden="true" tabindex="-1"></a>        search_result <span class="op">=</span> client.search(</span>
<span id="cb82-34"><a href="#cb82-34" aria-hidden="true" tabindex="-1"></a>            collection_name<span class="op">=</span>COLLECTION_NAME,</span>
<span id="cb82-35"><a href="#cb82-35" aria-hidden="true" tabindex="-1"></a>            query_vector<span class="op">=</span>(<span class="st">&quot;E5&quot;</span>, e5_embeddings[<span class="dv">0</span>].tolist()),</span>
<span id="cb82-36"><a href="#cb82-36" aria-hidden="true" tabindex="-1"></a>            limit<span class="op">=</span><span class="dv">3</span></span>
<span id="cb82-37"><a href="#cb82-37" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb82-38"><a href="#cb82-38" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Search returned </span><span class="sc">{</span><span class="bu">len</span>(search_result)<span class="sc">}</span><span class="ss"> results&quot;</span>)</span>
<span id="cb82-39"><a href="#cb82-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb82-40"><a href="#cb82-40" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Process completed successfully!&quot;</span>)</span>
<span id="cb82-41"><a href="#cb82-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb82-42"><a href="#cb82-42" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb82-43"><a href="#cb82-43" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Error during verification or optimization: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>5. Verifying upload and optimizing collection...
Collection points count: 100
Forcing collection optimization...
Optimization requested
Waiting for indexing to complete...
Updated points count: 100
Actual points count: 100

Testing search with E5 vector...
Search returned 3 results

Process completed successfully!
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>/tmp/ipykernel_23188/4059328617.py:33: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.
  search_result = client.search(
</code></pre>
</div>
</div>
<div id="0f77a333" class="cell code" data-execution_count="39">
<div class="sourceCode" id="cb85"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install ranx</span></code></pre></div>
<div class="output stream stderr">
<pre><code>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Collecting ranx
  Downloading ranx-0.3.20-py3-none-any.whl (99 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.3/99.3 KB 1.3 MB/s eta 0:00:00a 0:00:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 859.0/859.0 KB 9.2 MB/s eta 0:00:00a 0:00:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 243.2/243.2 KB 29.0 MB/s eta 0:00:00
ent already satisfied: numpy in ./test_env/lib/python3.10/site-packages (from ranx) (1.26.4)
Requirement already satisfied: orjson in ./test_env/lib/python3.10/site-packages (from ranx) (3.10.18)
Collecting lz4
  Downloading lz4-4.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 30.9 MB/s eta 0:00:0000:01
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 46.7 MB/s eta 0:00:00:00:01
ent already satisfied: pandas in ./test_env/lib/python3.10/site-packages (from ranx) (2.2.3)
Collecting cbor2
  Downloading cbor2-5.6.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.1/242.1 KB 2.5 MB/s eta 0:00:00a 0:00:01
ba&gt;=0.54.1
  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 66.9 MB/s eta 0:00:00:00:01
ent already satisfied: scipy&gt;=1.8.0 in ./test_env/lib/python3.10/site-packages (from ranx) (1.15.3)
Collecting seaborn
  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 294.9/294.9 KB 31.3 MB/s eta 0:00:00
ent already satisfied: tqdm in ./test_env/lib/python3.10/site-packages (from ranx) (4.67.1)
Collecting llvmlite&lt;0.45,&gt;=0.44.0dev0
  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.4/42.4 MB 39.0 MB/s eta 0:00:0000:0100:01
jam&gt;=2.3
  Downloading cramjam-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 49.8 MB/s eta 0:00:00:00:01
ent already satisfied: fsspec in ./test_env/lib/python3.10/site-packages (from fastparquet-&gt;ranx) (2025.5.1)
Requirement already satisfied: packaging in ./test_env/lib/python3.10/site-packages (from fastparquet-&gt;ranx) (24.2)
Requirement already satisfied: python-dateutil&gt;=2.8.2 in ./test_env/lib/python3.10/site-packages (from pandas-&gt;ranx) (2.9.0.post0)
Requirement already satisfied: pytz&gt;=2020.1 in ./test_env/lib/python3.10/site-packages (from pandas-&gt;ranx) (2025.2)
Requirement already satisfied: tzdata&gt;=2022.7 in ./test_env/lib/python3.10/site-packages (from pandas-&gt;ranx) (2025.2)
Collecting zlib-state&gt;=0.1.3
  Downloading zlib_state-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)
Collecting trec-car-tools&gt;=2.5.4
  Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)
Collecting warc3-wet&gt;=0.2.3
  Downloading warc3_wet-0.2.5-py3-none-any.whl (18 kB)
Collecting warc3-wet-clueweb09&gt;=0.2.5
  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)
  Preparing metadata (setup.py) ... ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45.1/45.1 KB 4.5 MB/s eta 0:00:00
anylinux_2_28_x86_64.whl (42.3 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.3/42.3 MB 43.0 MB/s eta 0:00:0000:0100:01
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 187.3/187.3 KB 25.1 MB/s eta 0:00:00
l&gt;=4.5.2
  Downloading lxml-5.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.1 MB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 70.7 MB/s eta 0:00:00:00:0100:01
anylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.2/130.2 KB 7.6 MB/s eta 0:00:00
ent already satisfied: pyyaml&gt;=5.3.1 in ./test_env/lib/python3.10/site-packages (from ir-datasets-&gt;ranx) (6.0.2)
Requirement already satisfied: requests&gt;=2.22.0 in ./test_env/lib/python3.10/site-packages (from ir-datasets-&gt;ranx) (2.32.3)
Requirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in ./test_env/lib/python3.10/site-packages (from rich-&gt;ranx) (2.19.1)
Collecting markdown-it-py&gt;=2.2.0
  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.5/87.5 KB 11.8 MB/s eta 0:00:00
ent already satisfied: typing-extensions&lt;5.0,&gt;=4.0.0 in ./test_env/lib/python3.10/site-packages (from rich-&gt;ranx) (4.13.2)
Requirement already satisfied: matplotlib!=3.6.1,&gt;=3.4 in ./test_env/lib/python3.10/site-packages (from seaborn-&gt;ranx) (3.10.3)
Collecting soupsieve&gt;1.2
  Downloading soupsieve-2.7-py3-none-any.whl (36 kB)
Collecting mdurl~=0.1
  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)
Requirement already satisfied: pillow&gt;=8 in ./test_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn-&gt;ranx) (11.2.1)
Requirement already satisfied: pyparsing&gt;=2.3.1 in ./test_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn-&gt;ranx) (3.2.3)
Requirement already satisfied: cycler&gt;=0.10 in ./test_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn-&gt;ranx) (0.12.1)
Requirement already satisfied: kiwisolver&gt;=1.3.1 in ./test_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn-&gt;ranx) (1.4.8)
Requirement already satisfied: contourpy&gt;=1.0.1 in ./test_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn-&gt;ranx) (1.3.2)
Requirement already satisfied: fonttools&gt;=4.22.0 in ./test_env/lib/python3.10/site-packages (from matplotlib!=3.6.1,&gt;=3.4-&gt;seaborn-&gt;ranx) (4.58.0)
Requirement already satisfied: six&gt;=1.5 in ./test_env/lib/python3.10/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas-&gt;ranx) (1.17.0)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in ./test_env/lib/python3.10/site-packages (from requests&gt;=2.22.0-&gt;ir-datasets-&gt;ranx) (3.10)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in ./test_env/lib/python3.10/site-packages (from requests&gt;=2.22.0-&gt;ir-datasets-&gt;ranx) (3.4.2)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in ./test_env/lib/python3.10/site-packages (from requests&gt;=2.22.0-&gt;ir-datasets-&gt;ranx) (2.4.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in ./test_env/lib/python3.10/site-packages (from requests&gt;=2.22.0-&gt;ir-datasets-&gt;ranx) (2025.4.26)
Collecting cbor&gt;=1.0.0
  Downloading cbor-1.0.0.tar.gz (20 kB)
  Preparing metadata (setup.py) ... durl, lz4, lxml, llvmlite, ijson, cramjam, cbor2, numba, markdown-it-py, inscriptis, beautifulsoup4, seaborn, rich, ir-datasets, fastparquet, ranx
  Running setup.py install for warc3-wet-clueweb09 ... jam-2.10.0 fastparquet-2024.11.0 ijson-3.4.0 inscriptis-2.6.0 ir-datasets-0.5.10 llvmlite-0.44.0 lxml-5.4.0 lz4-4.4.4 markdown-it-py-3.0.0 mdurl-0.1.2 numba-0.61.2 pyarrow-20.0.0 ranx-0.3.20 rich-14.0.0 seaborn-0.13.2 soupsieve-2.7 tabulate-0.9.0 trec-car-tools-2.6 unlzw3-0.2.3 warc3-wet-0.2.5 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.9
</code></pre>
</div>
</div>
<div id="210bdddb" class="cell code" data-execution_count="40">
<div class="sourceCode" id="cb88"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 6. Retrieval Evaluation Framework</span></span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load queries and ground truth data</span></span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> json</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ranx <span class="im">import</span> Qrels</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Path to your generated ground truth data</span></span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a>qrels_path <span class="op">=</span> <span class="st">&quot;qrels_beir.json&quot;</span></span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the BeIR format qrels</span></span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(qrels_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> f:</span>
<span id="cb88-13"><a href="#cb88-13" aria-hidden="true" tabindex="-1"></a>    query_qrels <span class="op">=</span> json.load(f)</span>
<span id="cb88-14"><a href="#cb88-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-15"><a href="#cb88-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Print a sample entry</span></span>
<span id="cb88-16"><a href="#cb88-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Sample qrels entry:&quot;</span>)</span>
<span id="cb88-17"><a href="#cb88-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(query_qrels[<span class="dv">7</span>])</span>
<span id="cb88-18"><a href="#cb88-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-19"><a href="#cb88-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to ranx format</span></span>
<span id="cb88-20"><a href="#cb88-20" aria-hidden="true" tabindex="-1"></a>qrels_dict <span class="op">=</span> defaultdict(<span class="bu">dict</span>)</span>
<span id="cb88-21"><a href="#cb88-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> entry <span class="kw">in</span> query_qrels:</span>
<span id="cb88-22"><a href="#cb88-22" aria-hidden="true" tabindex="-1"></a>    query_id <span class="op">=</span> <span class="bu">str</span>(entry[<span class="st">&quot;query-id&quot;</span>])</span>
<span id="cb88-23"><a href="#cb88-23" aria-hidden="true" tabindex="-1"></a>    doc_id <span class="op">=</span> <span class="bu">str</span>(entry[<span class="st">&quot;corpus-id&quot;</span>])</span>
<span id="cb88-24"><a href="#cb88-24" aria-hidden="true" tabindex="-1"></a>    qrels_dict[query_id][doc_id] <span class="op">=</span> entry[<span class="st">&quot;score&quot;</span>]</span>
<span id="cb88-25"><a href="#cb88-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-26"><a href="#cb88-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create ranx Qrels object</span></span>
<span id="cb88-27"><a href="#cb88-27" aria-hidden="true" tabindex="-1"></a>qrels <span class="op">=</span> Qrels(qrels_dict, name<span class="op">=</span><span class="st">&quot;sap_abap&quot;</span>)</span>
<span id="cb88-28"><a href="#cb88-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Qrels object created:&quot;</span>)</span>
<span id="cb88-29"><a href="#cb88-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(qrels)</span>
<span id="cb88-30"><a href="#cb88-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-31"><a href="#cb88-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Load queries from JSON</span></span>
<span id="cb88-32"><a href="#cb88-32" aria-hidden="true" tabindex="-1"></a>queries_path <span class="op">=</span> <span class="st">&quot;queries.json&quot;</span></span>
<span id="cb88-33"><a href="#cb88-33" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(queries_path, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> f:</span>
<span id="cb88-34"><a href="#cb88-34" aria-hidden="true" tabindex="-1"></a>    queries_dict <span class="op">=</span> json.load(f)</span>
<span id="cb88-35"><a href="#cb88-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-36"><a href="#cb88-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to list format with _id field</span></span>
<span id="cb88-37"><a href="#cb88-37" aria-hidden="true" tabindex="-1"></a>queries <span class="op">=</span> []</span>
<span id="cb88-38"><a href="#cb88-38" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> query_id, query_data <span class="kw">in</span> queries_dict.items():</span>
<span id="cb88-39"><a href="#cb88-39" aria-hidden="true" tabindex="-1"></a>    queries.append({</span>
<span id="cb88-40"><a href="#cb88-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;_id&quot;</span>: query_id,</span>
<span id="cb88-41"><a href="#cb88-41" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;text&quot;</span>: query_data[<span class="st">&quot;text&quot;</span>]</span>
<span id="cb88-42"><a href="#cb88-42" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb88-43"><a href="#cb88-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb88-44"><a href="#cb88-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Loaded </span><span class="sc">{</span><span class="bu">len</span>(queries)<span class="sc">}</span><span class="ss"> queries&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Sample qrels entry:
{&#39;query-id&#39;: 7, &#39;corpus-id&#39;: 3, &#39;score&#39;: 1}

Qrels object created:
{0: {0: 1}, 1: {0: 1}, 10: {5: 1}, 100: {50: 1}, 101: {50: 1}, 102: {51: 1}, 103: {51: 1}, 104: {52: 1}, 105: {52: 1}, 106: {53: 1}, 107: {53: 1}, 108: {54: 1}, 109: {54: 1}, 11: {5: 1}, 110: {55: 1}, 111: {55: 1}, 112: {56: 1}, 113: {56: 1}, 114: {57: 1}, 115: {57: 1}, 116: {58: 1}, 117: {58: 1}, 118: {59: 1}, 119: {59: 1}, 12: {6: 1}, 120: {60: 1}, 121: {60: 1}, 122: {61: 1}, 123: {61: 1}, 124: {62: 1}, 125: {62: 1}, 126: {63: 1}, 127: {63: 1}, 128: {64: 1}, 129: {64: 1}, 13: {6: 1}, 130: {65: 1}, 131: {65: 1}, 132: {66: 1}, 133: {66: 1}, 134: {67: 1}, 135: {67: 1}, 136: {68: 1}, 137: {68: 1}, 138: {69: 1}, 139: {69: 1}, 14: {7: 1}, 140: {70: 1}, 141: {70: 1}, 142: {71: 1}, 143: {71: 1}, 144: {72: 1}, 145: {72: 1}, 146: {73: 1}, 147: {73: 1}, 148: {74: 1}, 149: {74: 1}, 15: {7: 1}, 150: {75: 1}, 151: {75: 1}, 152: {76: 1}, 153: {76: 1}, 154: {77: 1}, 155: {77: 1}, 156: {78: 1}, 157: {78: 1}, 158: {79: 1}, 159: {79: 1}, 16: {8: 1}, 160: {80: 1}, 161: {80: 1}, 162: {81: 1}, 163: {81: 1}, 164: {82: 1}, 165: {82: 1}, 166: {83: 1}, 167: {83: 1}, 168: {84: 1}, 169: {84: 1}, 17: {8: 1}, 170: {85: 1}, 171: {85: 1}, 172: {86: 1}, 173: {86: 1}, 174: {87: 1}, 175: {87: 1}, 176: {88: 1}, 177: {88: 1}, 178: {89: 1}, 179: {89: 1}, 18: {9: 1}, 180: {90: 1}, 181: {90: 1}, 182: {91: 1}, 183: {91: 1}, 184: {92: 1}, 185: {92: 1}, 186: {93: 1}, 187: {93: 1}, 188: {94: 1}, 189: {94: 1}, 19: {9: 1}, 190: {95: 1}, 191: {95: 1}, 192: {96: 1}, 193: {96: 1}, 194: {97: 1}, 195: {97: 1}, 196: {98: 1}, 197: {98: 1}, 198: {99: 1}, 199: {99: 1}, 2: {1: 1}, 20: {10: 1}, 21: {10: 1}, 22: {11: 1}, 23: {11: 1}, 24: {12: 1}, 25: {12: 1}, 26: {13: 1}, 27: {13: 1}, 28: {14: 1}, 29: {14: 1}, 3: {1: 1}, 30: {15: 1}, 31: {15: 1}, 32: {16: 1}, 33: {16: 1}, 34: {17: 1}, 35: {17: 1}, 36: {18: 1}, 37: {18: 1}, 38: {19: 1}, 39: {19: 1}, 4: {2: 1}, 40: {20: 1}, 41: {20: 1}, 42: {21: 1}, 43: {21: 1}, 44: {22: 1}, 45: {22: 1}, 46: {23: 1}, 47: {23: 1}, 48: {24: 1}, 49: {24: 1}, 5: {2: 1}, 50: {25: 1}, 51: {25: 1}, 52: {26: 1}, 53: {26: 1}, 54: {27: 1}, 55: {27: 1}, 56: {28: 1}, 57: {28: 1}, 58: {29: 1}, 59: {29: 1}, 6: {3: 1}, 60: {30: 1}, 61: {30: 1}, 62: {31: 1}, 63: {31: 1}, 64: {32: 1}, 65: {32: 1}, 66: {33: 1}, 67: {33: 1}, 68: {34: 1}, 69: {34: 1}, 7: {3: 1}, 70: {35: 1}, 71: {35: 1}, 72: {36: 1}, 73: {36: 1}, 74: {37: 1}, 75: {37: 1}, 76: {38: 1}, 77: {38: 1}, 78: {39: 1}, 79: {39: 1}, 8: {4: 1}, 80: {40: 1}, 81: {40: 1}, 82: {41: 1}, 83: {41: 1}, 84: {42: 1}, 85: {42: 1}, 86: {43: 1}, 87: {43: 1}, 88: {44: 1}, 89: {44: 1}, 9: {4: 1}, 90: {45: 1}, 91: {45: 1}, 92: {46: 1}, 93: {46: 1}, 94: {47: 1}, 95: {47: 1}, 96: {48: 1}, 97: {48: 1}, 98: {49: 1}, 99: {49: 1}}
Loaded 200 queries
</code></pre>
</div>
</div>
<div id="541e73b6" class="cell code" data-execution_count="41">
<div class="sourceCode" id="cb90"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 7. Precompute Query Embeddings for All Models</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to precompute embeddings for all queries and models</span></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> precompute_query_embeddings(queries, models):</span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="co">    Precompute embeddings for all queries across multiple models.</span></span>
<span id="cb90-7"><a href="#cb90-7" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb90-8"><a href="#cb90-8" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb90-9"><a href="#cb90-9" aria-hidden="true" tabindex="-1"></a><span class="co">        queries: List of query objects with &#39;text&#39; field</span></span>
<span id="cb90-10"><a href="#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="co">        models: Dictionary of embedding models keyed by model name</span></span>
<span id="cb90-11"><a href="#cb90-11" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb90-12"><a href="#cb90-12" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb90-13"><a href="#cb90-13" aria-hidden="true" tabindex="-1"></a><span class="co">        Dictionary of embeddings organized by model type and name</span></span>
<span id="cb90-14"><a href="#cb90-14" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb90-15"><a href="#cb90-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensure queries is a list of dictionaries</span></span>
<span id="cb90-16"><a href="#cb90-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(queries[<span class="dv">0</span>], <span class="bu">str</span>):</span>
<span id="cb90-17"><a href="#cb90-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Converting queries from strings to dictionaries...&quot;</span>)</span>
<span id="cb90-18"><a href="#cb90-18" aria-hidden="true" tabindex="-1"></a>        queries <span class="op">=</span> [{<span class="st">&quot;_id&quot;</span>: <span class="bu">str</span>(i), <span class="st">&quot;text&quot;</span>: query} <span class="cf">for</span> i, query <span class="kw">in</span> <span class="bu">enumerate</span>(queries)]</span>
<span id="cb90-19"><a href="#cb90-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-20"><a href="#cb90-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initialize dictionary to store embeddings by type</span></span>
<span id="cb90-21"><a href="#cb90-21" aria-hidden="true" tabindex="-1"></a>    embeddings <span class="op">=</span> {</span>
<span id="cb90-22"><a href="#cb90-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;dense_embeddings&#39;</span>: {},</span>
<span id="cb90-23"><a href="#cb90-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;sparse_embeddings&#39;</span>: {},</span>
<span id="cb90-24"><a href="#cb90-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;late_interaction_embeddings&#39;</span>: {}</span>
<span id="cb90-25"><a href="#cb90-25" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb90-26"><a href="#cb90-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-27"><a href="#cb90-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Precomputing query embeddings...&quot;</span>)</span>
<span id="cb90-28"><a href="#cb90-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-29"><a href="#cb90-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Import tqdm correctly</span></span>
<span id="cb90-30"><a href="#cb90-30" aria-hidden="true" tabindex="-1"></a>    <span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb90-31"><a href="#cb90-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-32"><a href="#cb90-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process dense models</span></span>
<span id="cb90-33"><a href="#cb90-33" aria-hidden="true" tabindex="-1"></a>    dense_models <span class="op">=</span> [<span class="st">&#39;E5&#39;</span>, <span class="st">&#39;GTE&#39;</span>, <span class="st">&#39;BGE&#39;</span>, <span class="st">&#39;INF_RETRIEVER_V1&#39;</span>, <span class="st">&#39;BGE_M3&#39;</span>, <span class="st">&#39;OpenAI&#39;</span>, <span class="st">&#39;codellama&#39;</span>]</span>
<span id="cb90-34"><a href="#cb90-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name <span class="kw">in</span> dense_models:</span>
<span id="cb90-35"><a href="#cb90-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_name <span class="kw">in</span> models:</span>
<span id="cb90-36"><a href="#cb90-36" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Processing </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> embeddings...&quot;</span>)</span>
<span id="cb90-37"><a href="#cb90-37" aria-hidden="true" tabindex="-1"></a>            model_vectors <span class="op">=</span> []</span>
<span id="cb90-38"><a href="#cb90-38" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb90-39"><a href="#cb90-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> query <span class="kw">in</span> tqdm(queries):</span>
<span id="cb90-40"><a href="#cb90-40" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Special handling for Instructor model (requires prompt)</span></span>
<span id="cb90-41"><a href="#cb90-41" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;INF_RETRIEVER_V1&#39;</span>:</span>
<span id="cb90-42"><a href="#cb90-42" aria-hidden="true" tabindex="-1"></a>                    query_vector <span class="op">=</span> models[model_name].encode([[<span class="st">&quot;Represent code for retrieval: &quot;</span>, query[<span class="st">&quot;text&quot;</span>]]])</span>
<span id="cb90-43"><a href="#cb90-43" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb90-44"><a href="#cb90-44" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Use encode for SentenceTransformer models</span></span>
<span id="cb90-45"><a href="#cb90-45" aria-hidden="true" tabindex="-1"></a>                    query_vector <span class="op">=</span> models[model_name].encode(query[<span class="st">&quot;text&quot;</span>])</span>
<span id="cb90-46"><a href="#cb90-46" aria-hidden="true" tabindex="-1"></a>                model_vectors.append(query_vector)</span>
<span id="cb90-47"><a href="#cb90-47" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb90-48"><a href="#cb90-48" aria-hidden="true" tabindex="-1"></a>            embeddings[<span class="st">&#39;dense_embeddings&#39;</span>][model_name] <span class="op">=</span> model_vectors</span>
<span id="cb90-49"><a href="#cb90-49" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-50"><a href="#cb90-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process sparse model (BM25)</span></span>
<span id="cb90-51"><a href="#cb90-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&#39;BM25&#39;</span> <span class="kw">in</span> models:</span>
<span id="cb90-52"><a href="#cb90-52" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Processing BM25 sparse embeddings...&quot;</span>)</span>
<span id="cb90-53"><a href="#cb90-53" aria-hidden="true" tabindex="-1"></a>        sparse_vectors <span class="op">=</span> []</span>
<span id="cb90-54"><a href="#cb90-54" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb90-55"><a href="#cb90-55" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> query <span class="kw">in</span> tqdm(queries):</span>
<span id="cb90-56"><a href="#cb90-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use query_embed for fastembed models</span></span>
<span id="cb90-57"><a href="#cb90-57" aria-hidden="true" tabindex="-1"></a>            sparse_vector <span class="op">=</span> <span class="bu">next</span>(models[<span class="st">&#39;BM25&#39;</span>].query_embed(query[<span class="st">&quot;text&quot;</span>]))</span>
<span id="cb90-58"><a href="#cb90-58" aria-hidden="true" tabindex="-1"></a>            sparse_vectors.append(sparse_vector)</span>
<span id="cb90-59"><a href="#cb90-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb90-60"><a href="#cb90-60" aria-hidden="true" tabindex="-1"></a>        embeddings[<span class="st">&#39;sparse_embeddings&#39;</span>][<span class="st">&#39;BM25&#39;</span>] <span class="op">=</span> sparse_vectors</span>
<span id="cb90-61"><a href="#cb90-61" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-62"><a href="#cb90-62" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Process late interaction model (ColBERT)</span></span>
<span id="cb90-63"><a href="#cb90-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&#39;ColBERT&#39;</span> <span class="kw">in</span> models:</span>
<span id="cb90-64"><a href="#cb90-64" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Processing ColBERT late interaction embeddings...&quot;</span>)</span>
<span id="cb90-65"><a href="#cb90-65" aria-hidden="true" tabindex="-1"></a>        late_vectors <span class="op">=</span> []</span>
<span id="cb90-66"><a href="#cb90-66" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb90-67"><a href="#cb90-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> query <span class="kw">in</span> tqdm(queries):</span>
<span id="cb90-68"><a href="#cb90-68" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use query_embed for fastembed models</span></span>
<span id="cb90-69"><a href="#cb90-69" aria-hidden="true" tabindex="-1"></a>            late_vector <span class="op">=</span> <span class="bu">next</span>(models[<span class="st">&#39;ColBERT&#39;</span>].query_embed(query[<span class="st">&quot;text&quot;</span>]))</span>
<span id="cb90-70"><a href="#cb90-70" aria-hidden="true" tabindex="-1"></a>            late_vectors.append(late_vector)</span>
<span id="cb90-71"><a href="#cb90-71" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb90-72"><a href="#cb90-72" aria-hidden="true" tabindex="-1"></a>        embeddings[<span class="st">&#39;late_interaction_embeddings&#39;</span>][<span class="st">&#39;ColBERT&#39;</span>] <span class="op">=</span> late_vectors</span>
<span id="cb90-73"><a href="#cb90-73" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb90-74"><a href="#cb90-74" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Embeddings precomputation complete!&quot;</span>)</span>
<span id="cb90-75"><a href="#cb90-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> embeddings</span></code></pre></div>
</div>
<div id="14a0dee4" class="cell code" data-execution_count="42">
<div class="sourceCode" id="cb91"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize models dictionary</span></span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> {</span>
<span id="cb91-3"><a href="#cb91-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;E5&#39;</span>: e5_model,</span>
<span id="cb91-4"><a href="#cb91-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;GTE&#39;</span>: gte_model,</span>
<span id="cb91-5"><a href="#cb91-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;BGE&#39;</span>: bge_model,</span>
<span id="cb91-6"><a href="#cb91-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;INF_RETRIEVER_V1&#39;</span>: inf_model,  <span class="co"># Simulated, would require API client</span></span>
<span id="cb91-7"><a href="#cb91-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;BGE_M3&#39;</span>: bge_m3_model,</span>
<span id="cb91-8"><a href="#cb91-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;OpenAI&#39;</span>: openai_model,</span>
<span id="cb91-9"><a href="#cb91-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;codellama&#39;</span>:codellama_model,</span>
<span id="cb91-10"><a href="#cb91-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;BM25&#39;</span>: bm25_embedding_model,</span>
<span id="cb91-11"><a href="#cb91-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;ColBERT&#39;</span>: late_interaction_embedding_model</span>
<span id="cb91-12"><a href="#cb91-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
</div>
<div id="07b21bd8" class="cell code" data-execution_count="43">
<div class="sourceCode" id="cb92"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Precompute embeddings</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>embeddings <span class="op">=</span> precompute_query_embeddings(queries, models)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Precomputing query embeddings...
Processing E5 embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:31&lt;00:00,  6.30it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Processing GTE embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:29&lt;00:00,  6.80it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Processing BGE embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:30&lt;00:00,  6.52it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Processing INF_RETRIEVER_V1 embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [07:03&lt;00:00,  2.12s/it]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Processing BGE_M3 embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:28&lt;00:00,  6.95it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Processing OpenAI embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>Generating OpenAI embeddings: 100%|██████████| 1/1 [00:01&lt;00:00,  1.01s/it]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.56it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.09it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.74it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.25it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.50it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.30it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  2.25it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.47it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.89it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.84it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.07it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.79it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.60it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.85it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:01&lt;00:00,  1.85s/it]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.56it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.71it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.91it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.89it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:01&lt;00:00,  1.08s/it]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  2.67it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.85it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.57it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.05it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.63it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.62it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.01it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.85it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.37it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.89it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.76it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.79it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.96it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.74it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.74it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.71it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.00it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.86it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.00it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.75it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.79it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.80it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.79it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.67it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.84it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.62it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.69it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.62it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.45it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.48it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.82it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.40it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.92it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.82it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.57it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.73it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.52it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.96it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.32it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.97it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.80it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.41it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.81it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.91it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.93it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.88it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.90it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.83it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.48it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.64it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.00it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.76it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.83it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.84it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.90it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.63it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.73it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.69it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.70it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.95it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.95it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.11it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.70it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.80it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.51it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.90it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.80it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.69it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.86it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.91it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.96it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.84it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.88it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.94it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.85it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.44it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.27it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.79it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.99it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.54it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.43it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.32it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.72it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.53it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.71it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.88it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.76it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.94it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.69it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.94it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.12it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.88it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.84it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.04it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.43it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.00it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.92it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.65it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.94it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.95it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.32it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.95it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.73it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.83it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.63it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.50it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.73it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.61it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.79it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.61it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.77it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.50it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.18it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.67it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.69it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.91it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.51it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.91it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.92it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.82it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.71it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.79it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.00it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.60it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.84it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.99it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.07it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.83it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.69it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.79it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.59it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.97it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.96it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.93it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.55it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.76it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.04it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.98it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.71it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.02it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.91it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  2.83it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.14it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.78it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.93it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.27it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.69it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.92it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.94it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.72it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.83it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.27it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.73it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.66it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.95it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.85it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.55it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.84it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.88it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.77it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.30it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.82it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  4.01it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.89it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.52it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.88it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.57it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.20it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.87it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.48it/s]
Generating OpenAI embeddings: 100%|██████████| 1/1 [00:00&lt;00:00,  3.22it/s]
100%|██████████| 200/200 [00:58&lt;00:00,  3.43it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Processing codellama embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [06:54&lt;00:00,  2.07s/it]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Processing BM25 sparse embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:00&lt;00:00, 28816.93it/s]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Processing ColBERT late interaction embeddings...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:04&lt;00:00, 46.61it/s]</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Embeddings precomputation complete!
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>
</code></pre>
</div>
</div>
<div id="80172d66" class="cell code" data-execution_count="44">
<div class="sourceCode" id="cb113"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Before your evaluation code, check your embeddings dictionary structure</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Embeddings dictionary keys:&quot;</span>, embeddings.keys())</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">&#39;dense_embeddings&#39;</span> <span class="kw">in</span> embeddings:</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Dense embeddings keys:&quot;</span>, embeddings[<span class="st">&#39;dense_embeddings&#39;</span>].keys())</span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;No &#39;dense_embeddings&#39; key found. Creating it now...&quot;</span>)</span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If embeddings is a flat dictionary, create the nested structure</span></span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>    dense_embeddings <span class="op">=</span> {}</span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> key <span class="kw">in</span> embeddings.keys():</span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> key <span class="kw">not</span> <span class="kw">in</span> [<span class="st">&#39;sparse_embeddings&#39;</span>, <span class="st">&#39;late_interaction_embeddings&#39;</span>]:</span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>            dense_embeddings[key] <span class="op">=</span> embeddings[key]</span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create the nested structure</span></span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>    embeddings <span class="op">=</span> {</span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;dense_embeddings&#39;</span>: dense_embeddings,</span>
<span id="cb113-16"><a href="#cb113-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;sparse_embeddings&#39;</span>: {},</span>
<span id="cb113-17"><a href="#cb113-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">&#39;late_interaction_embeddings&#39;</span>: {}</span>
<span id="cb113-18"><a href="#cb113-18" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb113-19"><a href="#cb113-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb113-20"><a href="#cb113-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make sure starcoder is in the dense embeddings</span></span>
<span id="cb113-21"><a href="#cb113-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&#39;codellama&#39;</span> <span class="kw">not</span> <span class="kw">in</span> embeddings[<span class="st">&#39;dense_embeddings&#39;</span>] <span class="kw">and</span> <span class="st">&#39;codellama_embeddings&#39;</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb113-22"><a href="#cb113-22" aria-hidden="true" tabindex="-1"></a>        embeddings[<span class="st">&#39;dense_embeddings&#39;</span>][<span class="st">&#39;codellama&#39;</span>] <span class="op">=</span> codellama_embeddings</span>
<span id="cb113-23"><a href="#cb113-23" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">&quot;Added codellama embeddings to the dictionary&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Embeddings dictionary keys: dict_keys([&#39;dense_embeddings&#39;, &#39;sparse_embeddings&#39;, &#39;late_interaction_embeddings&#39;])
Dense embeddings keys: dict_keys([&#39;E5&#39;, &#39;GTE&#39;, &#39;BGE&#39;, &#39;INF_RETRIEVER_V1&#39;, &#39;BGE_M3&#39;, &#39;OpenAI&#39;, &#39;codellama&#39;])
</code></pre>
</div>
</div>
<div id="3a53f270" class="cell code" data-execution_count="45">
<div class="sourceCode" id="cb115"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 8. Retrieval Evaluation for All Models</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ranx <span class="im">import</span> Run, evaluate, compare</span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> qdrant_client.models <span class="im">import</span> SparseVector, FusionQuery, Fusion, Prefetch</span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate individual models</span></span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-9"><a href="#cb115-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define models that have real embeddings (not simulated)</span></span>
<span id="cb115-10"><a href="#cb115-10" aria-hidden="true" tabindex="-1"></a>real_models <span class="op">=</span> [<span class="st">&#39;E5&#39;</span>, <span class="st">&#39;GTE&#39;</span>, <span class="st">&#39;BGE&#39;</span>, <span class="st">&#39;INF_RETRIEVER_V1&#39;</span>, <span class="st">&#39;BGE_M3&#39;</span>,<span class="st">&#39;OpenAI&#39;</span>,<span class="st">&#39;codellama&#39;</span>]</span>
<span id="cb115-11"><a href="#cb115-11" aria-hidden="true" tabindex="-1"></a>dense_runs <span class="op">=</span> {}</span>
<span id="cb115-12"><a href="#cb115-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate individual models</span></span>
<span id="cb115-13"><a href="#cb115-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluating individual dense models...&quot;</span>)</span>
<span id="cb115-14"><a href="#cb115-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model_name <span class="kw">in</span> tqdm(real_models):</span>
<span id="cb115-15"><a href="#cb115-15" aria-hidden="true" tabindex="-1"></a>    dense_run_dict <span class="op">=</span> {}</span>
<span id="cb115-16"><a href="#cb115-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> query_idx, query <span class="kw">in</span> <span class="bu">enumerate</span>(queries):</span>
<span id="cb115-17"><a href="#cb115-17" aria-hidden="true" tabindex="-1"></a>        query_id <span class="op">=</span> <span class="bu">str</span>(query[<span class="st">&quot;_id&quot;</span>])</span>
<span id="cb115-18"><a href="#cb115-18" aria-hidden="true" tabindex="-1"></a>        query_vector <span class="op">=</span> embeddings[<span class="st">&#39;dense_embeddings&#39;</span>][model_name][query_idx]</span>
<span id="cb115-19"><a href="#cb115-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb115-20"><a href="#cb115-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fix INF_RETRIEVER_V1 dimensionality (remove the extra dimension)</span></span>
<span id="cb115-21"><a href="#cb115-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;INF_RETRIEVER_V1&#39;</span> <span class="kw">and</span> <span class="bu">isinstance</span>(query_vector, np.ndarray) <span class="kw">and</span> <span class="bu">len</span>(query_vector.shape) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb115-22"><a href="#cb115-22" aria-hidden="true" tabindex="-1"></a>            query_vector <span class="op">=</span> query_vector.reshape(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># Flatten to 1D array</span></span>
<span id="cb115-23"><a href="#cb115-23" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb115-24"><a href="#cb115-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fix for OpenAI embeddings which seem to be a list containing the actual embedding</span></span>
<span id="cb115-25"><a href="#cb115-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;OpenAI&#39;</span>:</span>
<span id="cb115-26"><a href="#cb115-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(query_vector, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(query_vector) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb115-27"><a href="#cb115-27" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If it&#39;s a list with one item, extract that item</span></span>
<span id="cb115-28"><a href="#cb115-28" aria-hidden="true" tabindex="-1"></a>                query_vector <span class="op">=</span> query_vector[<span class="dv">0</span>]</span>
<span id="cb115-29"><a href="#cb115-29" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">isinstance</span>(query_vector, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(query_vector) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb115-30"><a href="#cb115-30" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If it&#39;s already a flattened vector in list form, keep as is</span></span>
<span id="cb115-31"><a href="#cb115-31" aria-hidden="true" tabindex="-1"></a>                <span class="cf">pass</span></span>
<span id="cb115-32"><a href="#cb115-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Ensure it&#39;s a list for JSON serialization</span></span>
<span id="cb115-33"><a href="#cb115-33" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(query_vector, np.ndarray):</span>
<span id="cb115-34"><a href="#cb115-34" aria-hidden="true" tabindex="-1"></a>                query_vector <span class="op">=</span> query_vector.tolist()</span>
<span id="cb115-35"><a href="#cb115-35" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb115-36"><a href="#cb115-36" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert numpy arrays to lists for JSON serialization</span></span>
<span id="cb115-37"><a href="#cb115-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(query_vector, np.ndarray):</span>
<span id="cb115-38"><a href="#cb115-38" aria-hidden="true" tabindex="-1"></a>            query_vector <span class="op">=</span> query_vector.tolist()</span>
<span id="cb115-39"><a href="#cb115-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb115-40"><a href="#cb115-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb115-41"><a href="#cb115-41" aria-hidden="true" tabindex="-1"></a>            results <span class="op">=</span> client.query_points(</span>
<span id="cb115-42"><a href="#cb115-42" aria-hidden="true" tabindex="-1"></a>                COLLECTION_NAME,</span>
<span id="cb115-43"><a href="#cb115-43" aria-hidden="true" tabindex="-1"></a>                query<span class="op">=</span>query_vector,</span>
<span id="cb115-44"><a href="#cb115-44" aria-hidden="true" tabindex="-1"></a>                using<span class="op">=</span>model_name,</span>
<span id="cb115-45"><a href="#cb115-45" aria-hidden="true" tabindex="-1"></a>                with_payload<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb115-46"><a href="#cb115-46" aria-hidden="true" tabindex="-1"></a>                limit<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb115-47"><a href="#cb115-47" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb115-48"><a href="#cb115-48" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb115-49"><a href="#cb115-49" aria-hidden="true" tabindex="-1"></a>            dense_run_dict[query_id] <span class="op">=</span> {</span>
<span id="cb115-50"><a href="#cb115-50" aria-hidden="true" tabindex="-1"></a>                <span class="bu">str</span>(point.<span class="bu">id</span>): point.score</span>
<span id="cb115-51"><a href="#cb115-51" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> point <span class="kw">in</span> results.points</span>
<span id="cb115-52"><a href="#cb115-52" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb115-53"><a href="#cb115-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb115-54"><a href="#cb115-54" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Error querying with </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> for query </span><span class="sc">{</span>query_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb115-55"><a href="#cb115-55" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add more debugging info</span></span>
<span id="cb115-56"><a href="#cb115-56" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;OpenAI&#39;</span>:</span>
<span id="cb115-57"><a href="#cb115-57" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;OpenAI vector type: </span><span class="sc">{</span><span class="bu">type</span>(query_vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb115-58"><a href="#cb115-58" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(query_vector, <span class="bu">list</span>):</span>
<span id="cb115-59"><a href="#cb115-59" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;OpenAI vector length: </span><span class="sc">{</span><span class="bu">len</span>(query_vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb115-60"><a href="#cb115-60" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> <span class="bu">len</span>(query_vector) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb115-61"><a href="#cb115-61" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">print</span>(<span class="ss">f&quot;First element type: </span><span class="sc">{</span><span class="bu">type</span>(query_vector[<span class="dv">0</span>])<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb115-62"><a href="#cb115-62" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb115-63"><a href="#cb115-63" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb115-64"><a href="#cb115-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Only create Run objects for models with results</span></span>
<span id="cb115-65"><a href="#cb115-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> dense_run_dict:</span>
<span id="cb115-66"><a href="#cb115-66" aria-hidden="true" tabindex="-1"></a>        dense_runs[model_name] <span class="op">=</span> Run(dense_run_dict, name<span class="op">=</span><span class="ss">f&quot;</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">_dense&quot;</span>)</span>
<span id="cb115-67"><a href="#cb115-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb115-68"><a href="#cb115-68" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;No successful queries for </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">, skipping Run creation&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Evaluating individual dense models...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 7/7 [00:28&lt;00:00,  4.13s/it]
</code></pre>
</div>
</div>
<div id="d6c2a127" class="cell code" data-execution_count="46">
<div class="sourceCode" id="cb118"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out any models not present in the dense embeddings</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>real_models <span class="op">=</span> [m <span class="cf">for</span> m <span class="kw">in</span> real_models <span class="cf">if</span> m <span class="kw">in</span> embeddings[<span class="st">&#39;dense_embeddings&#39;</span>]]</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>real_models</span></code></pre></div>
<div class="output execute_result" data-execution_count="46">
<pre><code>[&#39;E5&#39;, &#39;GTE&#39;, &#39;BGE&#39;, &#39;INF_RETRIEVER_V1&#39;, &#39;BGE_M3&#39;, &#39;OpenAI&#39;, &#39;codellama&#39;]</code></pre>
</div>
</div>
<div id="fdd8432b" class="cell code" data-execution_count="47">
<div class="sourceCode" id="cb120"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate BM25 sparse model</span></span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluating BM25 sparse model...&quot;</span>)</span>
<span id="cb120-3"><a href="#cb120-3" aria-hidden="true" tabindex="-1"></a>bm25_run_dict <span class="op">=</span> {}</span>
<span id="cb120-4"><a href="#cb120-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> query_idx, query <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(queries)):</span>
<span id="cb120-5"><a href="#cb120-5" aria-hidden="true" tabindex="-1"></a>    query_id <span class="op">=</span> <span class="bu">str</span>(query[<span class="st">&quot;_id&quot;</span>])</span>
<span id="cb120-6"><a href="#cb120-6" aria-hidden="true" tabindex="-1"></a>    sparse_query_vector <span class="op">=</span> embeddings[<span class="st">&#39;sparse_embeddings&#39;</span>][<span class="st">&#39;BM25&#39;</span>][query_idx]</span>
<span id="cb120-7"><a href="#cb120-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb120-8"><a href="#cb120-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(sparse_query_vector, <span class="st">&#39;indices&#39;</span>) <span class="kw">and</span> <span class="bu">hasattr</span>(sparse_query_vector, <span class="st">&#39;values&#39;</span>):</span>
<span id="cb120-9"><a href="#cb120-9" aria-hidden="true" tabindex="-1"></a>        sparse_query_vector <span class="op">=</span> SparseVector(</span>
<span id="cb120-10"><a href="#cb120-10" aria-hidden="true" tabindex="-1"></a>            indices<span class="op">=</span>sparse_query_vector.indices.tolist(),</span>
<span id="cb120-11"><a href="#cb120-11" aria-hidden="true" tabindex="-1"></a>            values<span class="op">=</span>sparse_query_vector.values.tolist()</span>
<span id="cb120-12"><a href="#cb120-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb120-13"><a href="#cb120-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb120-14"><a href="#cb120-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Skipping query </span><span class="sc">{</span>query_idx<span class="sc">}</span><span class="ss">: Invalid BM25 vector format&quot;</span>)</span>
<span id="cb120-15"><a href="#cb120-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb120-16"><a href="#cb120-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb120-17"><a href="#cb120-17" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> client.query_points(</span>
<span id="cb120-18"><a href="#cb120-18" aria-hidden="true" tabindex="-1"></a>        COLLECTION_NAME,</span>
<span id="cb120-19"><a href="#cb120-19" aria-hidden="true" tabindex="-1"></a>        query<span class="op">=</span>sparse_query_vector,</span>
<span id="cb120-20"><a href="#cb120-20" aria-hidden="true" tabindex="-1"></a>        using<span class="op">=</span><span class="st">&quot;BM25&quot;</span>,</span>
<span id="cb120-21"><a href="#cb120-21" aria-hidden="true" tabindex="-1"></a>        with_payload<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb120-22"><a href="#cb120-22" aria-hidden="true" tabindex="-1"></a>        limit<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb120-23"><a href="#cb120-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb120-24"><a href="#cb120-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb120-25"><a href="#cb120-25" aria-hidden="true" tabindex="-1"></a>    bm25_run_dict[query_id] <span class="op">=</span> {</span>
<span id="cb120-26"><a href="#cb120-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">str</span>(point.<span class="bu">id</span>): point.score</span>
<span id="cb120-27"><a href="#cb120-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> point <span class="kw">in</span> results.points</span>
<span id="cb120-28"><a href="#cb120-28" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb120-29"><a href="#cb120-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-30"><a href="#cb120-30" aria-hidden="true" tabindex="-1"></a>bm25_run <span class="op">=</span> Run(bm25_run_dict, name<span class="op">=</span><span class="st">&quot;BM25_sparse&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Evaluating BM25 sparse model...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:00&lt;00:00, 250.79it/s]
</code></pre>
</div>
</div>
<div id="b78428ac" class="cell code" data-execution_count="48">
<div class="sourceCode" id="cb123"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate ColBERT late interaction model</span></span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluating ColBERT late interaction model...&quot;</span>)</span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a>colbert_run_dict <span class="op">=</span> {}</span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> query_idx, query <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(queries)):</span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a>    query_id <span class="op">=</span> <span class="bu">str</span>(query[<span class="st">&quot;_id&quot;</span>])</span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a>    late_query_vector <span class="op">=</span> embeddings[<span class="st">&#39;late_interaction_embeddings&#39;</span>][<span class="st">&#39;ColBERT&#39;</span>][query_idx]</span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a>    results <span class="op">=</span> client.query_points(</span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a>        COLLECTION_NAME,</span>
<span id="cb123-10"><a href="#cb123-10" aria-hidden="true" tabindex="-1"></a>        query<span class="op">=</span>late_query_vector,</span>
<span id="cb123-11"><a href="#cb123-11" aria-hidden="true" tabindex="-1"></a>        using<span class="op">=</span><span class="st">&quot;ColBERT&quot;</span>,</span>
<span id="cb123-12"><a href="#cb123-12" aria-hidden="true" tabindex="-1"></a>        with_payload<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb123-13"><a href="#cb123-13" aria-hidden="true" tabindex="-1"></a>        limit<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb123-14"><a href="#cb123-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb123-15"><a href="#cb123-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb123-16"><a href="#cb123-16" aria-hidden="true" tabindex="-1"></a>    colbert_run_dict[query_id] <span class="op">=</span> {</span>
<span id="cb123-17"><a href="#cb123-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">str</span>(point.<span class="bu">id</span>): point.score</span>
<span id="cb123-18"><a href="#cb123-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> point <span class="kw">in</span> results.points</span>
<span id="cb123-19"><a href="#cb123-19" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb123-20"><a href="#cb123-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-21"><a href="#cb123-21" aria-hidden="true" tabindex="-1"></a>colbert_run <span class="op">=</span> Run(colbert_run_dict, name<span class="op">=</span><span class="st">&quot;ColBERT_late&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Evaluating ColBERT late interaction model...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:08&lt;00:00, 22.41it/s]
</code></pre>
</div>
</div>
<div id="17d94ec2" class="cell code" data-execution_count="49">
<div class="sourceCode" id="cb126"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate hybrid models with BM25</span></span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluating hybrid models (dense + BM25)...&quot;</span>)</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>rrf_runs <span class="op">=</span> {}</span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create combinations of each dense model with BM25</span></span>
<span id="cb126-6"><a href="#cb126-6" aria-hidden="true" tabindex="-1"></a>hybrid_combinations <span class="op">=</span> [<span class="ss">f&quot;</span><span class="sc">{</span>model<span class="sc">}</span><span class="ss">+BM25&quot;</span> <span class="cf">for</span> model <span class="kw">in</span> real_models]</span>
<span id="cb126-7"><a href="#cb126-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb126-8"><a href="#cb126-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> combination <span class="kw">in</span> tqdm(hybrid_combinations):</span>
<span id="cb126-9"><a href="#cb126-9" aria-hidden="true" tabindex="-1"></a>    dense_model_name <span class="op">=</span> combination.split(<span class="st">&#39;+&#39;</span>)[<span class="dv">0</span>]</span>
<span id="cb126-10"><a href="#cb126-10" aria-hidden="true" tabindex="-1"></a>    rrf_run_dict <span class="op">=</span> {}</span>
<span id="cb126-11"><a href="#cb126-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb126-12"><a href="#cb126-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> query_idx, query <span class="kw">in</span> <span class="bu">enumerate</span>(queries):</span>
<span id="cb126-13"><a href="#cb126-13" aria-hidden="true" tabindex="-1"></a>        query_id <span class="op">=</span> <span class="bu">str</span>(query[<span class="st">&quot;_id&quot;</span>])</span>
<span id="cb126-14"><a href="#cb126-14" aria-hidden="true" tabindex="-1"></a>        dense_query_vector <span class="op">=</span> embeddings[<span class="st">&#39;dense_embeddings&#39;</span>][dense_model_name][query_idx]</span>
<span id="cb126-15"><a href="#cb126-15" aria-hidden="true" tabindex="-1"></a>        sparse_query_vector <span class="op">=</span> embeddings[<span class="st">&#39;sparse_embeddings&#39;</span>][<span class="st">&#39;BM25&#39;</span>][query_idx]</span>
<span id="cb126-16"><a href="#cb126-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb126-17"><a href="#cb126-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fix INF_RETRIEVER_V1 dimensionality (remove the extra dimension)</span></span>
<span id="cb126-18"><a href="#cb126-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> dense_model_name <span class="op">==</span> <span class="st">&#39;INF_RETRIEVER_V1&#39;</span> <span class="kw">and</span> <span class="bu">isinstance</span>(dense_query_vector, np.ndarray) <span class="kw">and</span> <span class="bu">len</span>(dense_query_vector.shape) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb126-19"><a href="#cb126-19" aria-hidden="true" tabindex="-1"></a>            dense_query_vector <span class="op">=</span> dense_query_vector.reshape(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># Flatten to 1D array</span></span>
<span id="cb126-20"><a href="#cb126-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb126-21"><a href="#cb126-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fix for OpenAI embeddings </span></span>
<span id="cb126-22"><a href="#cb126-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> dense_model_name <span class="op">==</span> <span class="st">&#39;OpenAI&#39;</span>:</span>
<span id="cb126-23"><a href="#cb126-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(dense_query_vector, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(dense_query_vector) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb126-24"><a href="#cb126-24" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If it&#39;s a list with one item, extract that item</span></span>
<span id="cb126-25"><a href="#cb126-25" aria-hidden="true" tabindex="-1"></a>                dense_query_vector <span class="op">=</span> dense_query_vector[<span class="dv">0</span>]</span>
<span id="cb126-26"><a href="#cb126-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">isinstance</span>(dense_query_vector, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(dense_query_vector) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb126-27"><a href="#cb126-27" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If it&#39;s already a flattened vector in list form, keep as is</span></span>
<span id="cb126-28"><a href="#cb126-28" aria-hidden="true" tabindex="-1"></a>                <span class="cf">pass</span></span>
<span id="cb126-29"><a href="#cb126-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb126-30"><a href="#cb126-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert numpy arrays to lists for JSON serialization</span></span>
<span id="cb126-31"><a href="#cb126-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(dense_query_vector, np.ndarray):</span>
<span id="cb126-32"><a href="#cb126-32" aria-hidden="true" tabindex="-1"></a>            dense_query_vector <span class="op">=</span> dense_query_vector.tolist()</span>
<span id="cb126-33"><a href="#cb126-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb126-34"><a href="#cb126-34" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Prepare sparse vector</span></span>
<span id="cb126-35"><a href="#cb126-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(sparse_query_vector, <span class="st">&#39;indices&#39;</span>) <span class="kw">and</span> <span class="bu">hasattr</span>(sparse_query_vector, <span class="st">&#39;values&#39;</span>):</span>
<span id="cb126-36"><a href="#cb126-36" aria-hidden="true" tabindex="-1"></a>            sparse_query_vector <span class="op">=</span> SparseVector(</span>
<span id="cb126-37"><a href="#cb126-37" aria-hidden="true" tabindex="-1"></a>                indices<span class="op">=</span>sparse_query_vector.indices.tolist(),</span>
<span id="cb126-38"><a href="#cb126-38" aria-hidden="true" tabindex="-1"></a>                values<span class="op">=</span>sparse_query_vector.values.tolist()</span>
<span id="cb126-39"><a href="#cb126-39" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb126-40"><a href="#cb126-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb126-41"><a href="#cb126-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Skipping query </span><span class="sc">{</span>query_idx<span class="sc">}</span><span class="ss">: Invalid BM25 vector format&quot;</span>)</span>
<span id="cb126-42"><a href="#cb126-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb126-43"><a href="#cb126-43" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb126-44"><a href="#cb126-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb126-45"><a href="#cb126-45" aria-hidden="true" tabindex="-1"></a>            prefetch_queries <span class="op">=</span> [</span>
<span id="cb126-46"><a href="#cb126-46" aria-hidden="true" tabindex="-1"></a>                Prefetch(</span>
<span id="cb126-47"><a href="#cb126-47" aria-hidden="true" tabindex="-1"></a>                    query<span class="op">=</span>dense_query_vector,</span>
<span id="cb126-48"><a href="#cb126-48" aria-hidden="true" tabindex="-1"></a>                    using<span class="op">=</span>dense_model_name,</span>
<span id="cb126-49"><a href="#cb126-49" aria-hidden="true" tabindex="-1"></a>                    limit<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb126-50"><a href="#cb126-50" aria-hidden="true" tabindex="-1"></a>                ),</span>
<span id="cb126-51"><a href="#cb126-51" aria-hidden="true" tabindex="-1"></a>                Prefetch(</span>
<span id="cb126-52"><a href="#cb126-52" aria-hidden="true" tabindex="-1"></a>                    query<span class="op">=</span>sparse_query_vector,</span>
<span id="cb126-53"><a href="#cb126-53" aria-hidden="true" tabindex="-1"></a>                    using<span class="op">=</span><span class="st">&quot;BM25&quot;</span>,</span>
<span id="cb126-54"><a href="#cb126-54" aria-hidden="true" tabindex="-1"></a>                    limit<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb126-55"><a href="#cb126-55" aria-hidden="true" tabindex="-1"></a>                ),</span>
<span id="cb126-56"><a href="#cb126-56" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb126-57"><a href="#cb126-57" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb126-58"><a href="#cb126-58" aria-hidden="true" tabindex="-1"></a>            results <span class="op">=</span> client.query_points(</span>
<span id="cb126-59"><a href="#cb126-59" aria-hidden="true" tabindex="-1"></a>                COLLECTION_NAME,</span>
<span id="cb126-60"><a href="#cb126-60" aria-hidden="true" tabindex="-1"></a>                prefetch<span class="op">=</span>prefetch_queries,</span>
<span id="cb126-61"><a href="#cb126-61" aria-hidden="true" tabindex="-1"></a>                query<span class="op">=</span>FusionQuery(</span>
<span id="cb126-62"><a href="#cb126-62" aria-hidden="true" tabindex="-1"></a>                    fusion<span class="op">=</span>Fusion.RRF,</span>
<span id="cb126-63"><a href="#cb126-63" aria-hidden="true" tabindex="-1"></a>                ),</span>
<span id="cb126-64"><a href="#cb126-64" aria-hidden="true" tabindex="-1"></a>                with_payload<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb126-65"><a href="#cb126-65" aria-hidden="true" tabindex="-1"></a>                limit<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb126-66"><a href="#cb126-66" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb126-67"><a href="#cb126-67" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb126-68"><a href="#cb126-68" aria-hidden="true" tabindex="-1"></a>            rrf_run_dict[query_id] <span class="op">=</span> {</span>
<span id="cb126-69"><a href="#cb126-69" aria-hidden="true" tabindex="-1"></a>                <span class="bu">str</span>(point.<span class="bu">id</span>): point.score</span>
<span id="cb126-70"><a href="#cb126-70" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> point <span class="kw">in</span> results.points</span>
<span id="cb126-71"><a href="#cb126-71" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb126-72"><a href="#cb126-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb126-73"><a href="#cb126-73" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Error with hybrid fusion </span><span class="sc">{</span>combination<span class="sc">}</span><span class="ss"> for query </span><span class="sc">{</span>query_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb126-74"><a href="#cb126-74" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Add more debugging info</span></span>
<span id="cb126-75"><a href="#cb126-75" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> dense_model_name <span class="op">==</span> <span class="st">&#39;OpenAI&#39;</span>:</span>
<span id="cb126-76"><a href="#cb126-76" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;OpenAI vector type: </span><span class="sc">{</span><span class="bu">type</span>(dense_query_vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb126-77"><a href="#cb126-77" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(dense_query_vector, <span class="bu">list</span>):</span>
<span id="cb126-78"><a href="#cb126-78" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;OpenAI vector length: </span><span class="sc">{</span><span class="bu">len</span>(dense_query_vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb126-79"><a href="#cb126-79" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb126-80"><a href="#cb126-80" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb126-81"><a href="#cb126-81" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Only create Run objects for combinations with results</span></span>
<span id="cb126-82"><a href="#cb126-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> rrf_run_dict:</span>
<span id="cb126-83"><a href="#cb126-83" aria-hidden="true" tabindex="-1"></a>        rrf_runs[combination] <span class="op">=</span> Run(rrf_run_dict, name<span class="op">=</span>combination)</span>
<span id="cb126-84"><a href="#cb126-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb126-85"><a href="#cb126-85" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;No successful queries for </span><span class="sc">{</span>combination<span class="sc">}</span><span class="ss">, skipping Run creation&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Evaluating hybrid models (dense + BM25)...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 7/7 [00:15&lt;00:00,  2.16s/it]
</code></pre>
</div>
</div>
<div id="84a82c9b" class="cell code" data-execution_count="50">
<div class="sourceCode" id="cb129"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluating fusion of all models...&quot;</span>)</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>full_rrf_run_dict <span class="op">=</span> {}</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> query_idx, query <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(queries)):</span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>    query_id <span class="op">=</span> <span class="bu">str</span>(query[<span class="st">&quot;_id&quot;</span>])</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get all dense embeddings for this query and preprocess them</span></span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a>        dense_query_vectors <span class="op">=</span> {}</span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> model_name <span class="kw">in</span> real_models:</span>
<span id="cb129-11"><a href="#cb129-11" aria-hidden="true" tabindex="-1"></a>            vector <span class="op">=</span> embeddings[<span class="st">&#39;dense_embeddings&#39;</span>][model_name][query_idx]</span>
<span id="cb129-12"><a href="#cb129-12" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb129-13"><a href="#cb129-13" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fix INF_RETRIEVER_V1 dimensionality (remove the extra dimension)</span></span>
<span id="cb129-14"><a href="#cb129-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;INF_RETRIEVER_V1&#39;</span> <span class="kw">and</span> <span class="bu">isinstance</span>(vector, np.ndarray) <span class="kw">and</span> <span class="bu">len</span>(vector.shape) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb129-15"><a href="#cb129-15" aria-hidden="true" tabindex="-1"></a>                vector <span class="op">=</span> vector.reshape(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># Flatten to 1D array</span></span>
<span id="cb129-16"><a href="#cb129-16" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb129-17"><a href="#cb129-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fix for OpenAI embeddings</span></span>
<span id="cb129-18"><a href="#cb129-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;OpenAI&#39;</span>:</span>
<span id="cb129-19"><a href="#cb129-19" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(vector, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(vector) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb129-20"><a href="#cb129-20" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># If it&#39;s a list with one item, extract that item</span></span>
<span id="cb129-21"><a href="#cb129-21" aria-hidden="true" tabindex="-1"></a>                    vector <span class="op">=</span> vector[<span class="dv">0</span>]</span>
<span id="cb129-22"><a href="#cb129-22" aria-hidden="true" tabindex="-1"></a>                <span class="cf">elif</span> <span class="bu">isinstance</span>(vector, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(vector) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb129-23"><a href="#cb129-23" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># If it&#39;s already a flattened vector in list form, keep as is</span></span>
<span id="cb129-24"><a href="#cb129-24" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">pass</span></span>
<span id="cb129-25"><a href="#cb129-25" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb129-26"><a href="#cb129-26" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Convert numpy arrays to lists for JSON serialization</span></span>
<span id="cb129-27"><a href="#cb129-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(vector, np.ndarray):</span>
<span id="cb129-28"><a href="#cb129-28" aria-hidden="true" tabindex="-1"></a>                vector <span class="op">=</span> vector.tolist()</span>
<span id="cb129-29"><a href="#cb129-29" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb129-30"><a href="#cb129-30" aria-hidden="true" tabindex="-1"></a>            dense_query_vectors[model_name] <span class="op">=</span> vector</span>
<span id="cb129-31"><a href="#cb129-31" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb129-32"><a href="#cb129-32" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get and prepare sparse vector</span></span>
<span id="cb129-33"><a href="#cb129-33" aria-hidden="true" tabindex="-1"></a>        sparse_query_vector <span class="op">=</span> embeddings[<span class="st">&#39;sparse_embeddings&#39;</span>][<span class="st">&#39;BM25&#39;</span>][query_idx]</span>
<span id="cb129-34"><a href="#cb129-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(sparse_query_vector, <span class="st">&#39;indices&#39;</span>) <span class="kw">and</span> <span class="bu">hasattr</span>(sparse_query_vector, <span class="st">&#39;values&#39;</span>):</span>
<span id="cb129-35"><a href="#cb129-35" aria-hidden="true" tabindex="-1"></a>            sparse_query_vector <span class="op">=</span> SparseVector(</span>
<span id="cb129-36"><a href="#cb129-36" aria-hidden="true" tabindex="-1"></a>                indices<span class="op">=</span>sparse_query_vector.indices.tolist(),</span>
<span id="cb129-37"><a href="#cb129-37" aria-hidden="true" tabindex="-1"></a>                values<span class="op">=</span>sparse_query_vector.values.tolist()</span>
<span id="cb129-38"><a href="#cb129-38" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb129-39"><a href="#cb129-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb129-40"><a href="#cb129-40" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Skipping query </span><span class="sc">{</span>query_idx<span class="sc">}</span><span class="ss">: Invalid BM25 vector format&quot;</span>)</span>
<span id="cb129-41"><a href="#cb129-41" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb129-42"><a href="#cb129-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb129-43"><a href="#cb129-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get late interaction vector</span></span>
<span id="cb129-44"><a href="#cb129-44" aria-hidden="true" tabindex="-1"></a>        late_query_vector <span class="op">=</span> embeddings[<span class="st">&#39;late_interaction_embeddings&#39;</span>][<span class="st">&#39;ColBERT&#39;</span>][query_idx]</span>
<span id="cb129-45"><a href="#cb129-45" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb129-46"><a href="#cb129-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create prefetch queries for all models</span></span>
<span id="cb129-47"><a href="#cb129-47" aria-hidden="true" tabindex="-1"></a>        prefetch_queries <span class="op">=</span> [</span>
<span id="cb129-48"><a href="#cb129-48" aria-hidden="true" tabindex="-1"></a>            Prefetch(</span>
<span id="cb129-49"><a href="#cb129-49" aria-hidden="true" tabindex="-1"></a>                query<span class="op">=</span>dense_query_vectors[model_name],</span>
<span id="cb129-50"><a href="#cb129-50" aria-hidden="true" tabindex="-1"></a>                using<span class="op">=</span>model_name,</span>
<span id="cb129-51"><a href="#cb129-51" aria-hidden="true" tabindex="-1"></a>                limit<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb129-52"><a href="#cb129-52" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb129-53"><a href="#cb129-53" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> model_name <span class="kw">in</span> real_models</span>
<span id="cb129-54"><a href="#cb129-54" aria-hidden="true" tabindex="-1"></a>        ] <span class="op">+</span> [</span>
<span id="cb129-55"><a href="#cb129-55" aria-hidden="true" tabindex="-1"></a>            Prefetch(</span>
<span id="cb129-56"><a href="#cb129-56" aria-hidden="true" tabindex="-1"></a>                query<span class="op">=</span>sparse_query_vector,</span>
<span id="cb129-57"><a href="#cb129-57" aria-hidden="true" tabindex="-1"></a>                using<span class="op">=</span><span class="st">&quot;BM25&quot;</span>,</span>
<span id="cb129-58"><a href="#cb129-58" aria-hidden="true" tabindex="-1"></a>                limit<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb129-59"><a href="#cb129-59" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb129-60"><a href="#cb129-60" aria-hidden="true" tabindex="-1"></a>            Prefetch(</span>
<span id="cb129-61"><a href="#cb129-61" aria-hidden="true" tabindex="-1"></a>                query<span class="op">=</span>late_query_vector,</span>
<span id="cb129-62"><a href="#cb129-62" aria-hidden="true" tabindex="-1"></a>                using<span class="op">=</span><span class="st">&quot;ColBERT&quot;</span>,</span>
<span id="cb129-63"><a href="#cb129-63" aria-hidden="true" tabindex="-1"></a>                limit<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb129-64"><a href="#cb129-64" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb129-65"><a href="#cb129-65" aria-hidden="true" tabindex="-1"></a>        ]</span>
<span id="cb129-66"><a href="#cb129-66" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb129-67"><a href="#cb129-67" aria-hidden="true" tabindex="-1"></a>        results <span class="op">=</span> client.query_points(</span>
<span id="cb129-68"><a href="#cb129-68" aria-hidden="true" tabindex="-1"></a>            COLLECTION_NAME,</span>
<span id="cb129-69"><a href="#cb129-69" aria-hidden="true" tabindex="-1"></a>            prefetch<span class="op">=</span>prefetch_queries,</span>
<span id="cb129-70"><a href="#cb129-70" aria-hidden="true" tabindex="-1"></a>            query<span class="op">=</span>FusionQuery(</span>
<span id="cb129-71"><a href="#cb129-71" aria-hidden="true" tabindex="-1"></a>                fusion<span class="op">=</span>Fusion.RRF,</span>
<span id="cb129-72"><a href="#cb129-72" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb129-73"><a href="#cb129-73" aria-hidden="true" tabindex="-1"></a>            with_payload<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb129-74"><a href="#cb129-74" aria-hidden="true" tabindex="-1"></a>            limit<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb129-75"><a href="#cb129-75" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb129-76"><a href="#cb129-76" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb129-77"><a href="#cb129-77" aria-hidden="true" tabindex="-1"></a>        full_rrf_run_dict[query_id] <span class="op">=</span> {</span>
<span id="cb129-78"><a href="#cb129-78" aria-hidden="true" tabindex="-1"></a>            <span class="bu">str</span>(point.<span class="bu">id</span>): point.score</span>
<span id="cb129-79"><a href="#cb129-79" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> point <span class="kw">in</span> results.points</span>
<span id="cb129-80"><a href="#cb129-80" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb129-81"><a href="#cb129-81" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb129-82"><a href="#cb129-82" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Error with full fusion for query </span><span class="sc">{</span>query_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb129-83"><a href="#cb129-83" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print more details about the vectors to help diagnose the issue</span></span>
<span id="cb129-84"><a href="#cb129-84" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> model_name <span class="kw">in</span> real_models:</span>
<span id="cb129-85"><a href="#cb129-85" aria-hidden="true" tabindex="-1"></a>            vector <span class="op">=</span> dense_query_vectors.get(model_name)</span>
<span id="cb129-86"><a href="#cb129-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> vector:</span>
<span id="cb129-87"><a href="#cb129-87" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> vector type: </span><span class="sc">{</span><span class="bu">type</span>(vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb129-88"><a href="#cb129-88" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(vector, <span class="bu">list</span>):</span>
<span id="cb129-89"><a href="#cb129-89" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> vector length: </span><span class="sc">{</span><span class="bu">len</span>(vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb129-90"><a href="#cb129-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb129-91"><a href="#cb129-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-92"><a href="#cb129-92" aria-hidden="true" tabindex="-1"></a><span class="co"># Only create Run object if we have results</span></span>
<span id="cb129-93"><a href="#cb129-93" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> full_rrf_run_dict:</span>
<span id="cb129-94"><a href="#cb129-94" aria-hidden="true" tabindex="-1"></a>    full_rrf_run <span class="op">=</span> Run(full_rrf_run_dict, name<span class="op">=</span><span class="st">&quot;Full_RRF&quot;</span>)</span>
<span id="cb129-95"><a href="#cb129-95" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb129-96"><a href="#cb129-96" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;No successful queries for full fusion, skipping Run creation&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Evaluating fusion of all models...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:14&lt;00:00, 13.60it/s]
</code></pre>
</div>
</div>
<div id="a1306ef2" class="cell code" data-execution_count="51">
<div class="sourceCode" id="cb132"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define high-dimensional models with real embeddings (not simulated)</span></span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>high_dim_models <span class="op">=</span> [<span class="st">&#39;E5&#39;</span>, <span class="st">&#39;GTE&#39;</span>, <span class="st">&#39;BGE&#39;</span>, <span class="st">&#39;INF_RETRIEVER_V1&#39;</span> ,<span class="st">&#39;codellama&#39;</span>, <span class="st">&#39;OpenAI&#39;</span>]</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create fusion of high-dimensional models</span></span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluating fusion of high-dimensional models...&quot;</span>)</span>
<span id="cb132-6"><a href="#cb132-6" aria-hidden="true" tabindex="-1"></a>high_dim_fusion_run_dict <span class="op">=</span> {}</span>
<span id="cb132-7"><a href="#cb132-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-8"><a href="#cb132-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> query_idx, query <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(queries)):</span>
<span id="cb132-9"><a href="#cb132-9" aria-hidden="true" tabindex="-1"></a>    query_id <span class="op">=</span> <span class="bu">str</span>(query[<span class="st">&quot;_id&quot;</span>])</span>
<span id="cb132-10"><a href="#cb132-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb132-11"><a href="#cb132-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb132-12"><a href="#cb132-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get all high-dimensional embeddings for this query and preprocess them</span></span>
<span id="cb132-13"><a href="#cb132-13" aria-hidden="true" tabindex="-1"></a>        high_dim_query_vectors <span class="op">=</span> {}</span>
<span id="cb132-14"><a href="#cb132-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> model_name <span class="kw">in</span> high_dim_models:</span>
<span id="cb132-15"><a href="#cb132-15" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model_name <span class="kw">not</span> <span class="kw">in</span> embeddings[<span class="st">&#39;dense_embeddings&#39;</span>]:</span>
<span id="cb132-16"><a href="#cb132-16" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;Skipping </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> - not in embeddings dictionary&quot;</span>)</span>
<span id="cb132-17"><a href="#cb132-17" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb132-18"><a href="#cb132-18" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb132-19"><a href="#cb132-19" aria-hidden="true" tabindex="-1"></a>            vector <span class="op">=</span> embeddings[<span class="st">&#39;dense_embeddings&#39;</span>][model_name][query_idx]</span>
<span id="cb132-20"><a href="#cb132-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb132-21"><a href="#cb132-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fix INF_RETRIEVER_V1 dimensionality (remove the extra dimension)</span></span>
<span id="cb132-22"><a href="#cb132-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;INF_RETRIEVER_V1&#39;</span> <span class="kw">and</span> <span class="bu">isinstance</span>(vector, np.ndarray) <span class="kw">and</span> <span class="bu">len</span>(vector.shape) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb132-23"><a href="#cb132-23" aria-hidden="true" tabindex="-1"></a>                vector <span class="op">=</span> vector.reshape(<span class="op">-</span><span class="dv">1</span>)  <span class="co"># Flatten to 1D array</span></span>
<span id="cb132-24"><a href="#cb132-24" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb132-25"><a href="#cb132-25" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fix for OpenAI embeddings</span></span>
<span id="cb132-26"><a href="#cb132-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;OpenAI&#39;</span>:</span>
<span id="cb132-27"><a href="#cb132-27" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> <span class="bu">isinstance</span>(vector, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(vector) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb132-28"><a href="#cb132-28" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># If it&#39;s a list with one item, extract that item</span></span>
<span id="cb132-29"><a href="#cb132-29" aria-hidden="true" tabindex="-1"></a>                    vector <span class="op">=</span> vector[<span class="dv">0</span>]</span>
<span id="cb132-30"><a href="#cb132-30" aria-hidden="true" tabindex="-1"></a>                <span class="cf">elif</span> <span class="bu">isinstance</span>(vector, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">len</span>(vector) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb132-31"><a href="#cb132-31" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># If it&#39;s already a flattened vector in list form, keep as is</span></span>
<span id="cb132-32"><a href="#cb132-32" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">pass</span></span>
<span id="cb132-33"><a href="#cb132-33" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb132-34"><a href="#cb132-34" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Convert numpy arrays to lists for JSON serialization</span></span>
<span id="cb132-35"><a href="#cb132-35" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(vector, np.ndarray):</span>
<span id="cb132-36"><a href="#cb132-36" aria-hidden="true" tabindex="-1"></a>                vector <span class="op">=</span> vector.tolist()</span>
<span id="cb132-37"><a href="#cb132-37" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb132-38"><a href="#cb132-38" aria-hidden="true" tabindex="-1"></a>            high_dim_query_vectors[model_name] <span class="op">=</span> vector</span>
<span id="cb132-39"><a href="#cb132-39" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb132-40"><a href="#cb132-40" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create prefetch queries for all available high-dimensional models</span></span>
<span id="cb132-41"><a href="#cb132-41" aria-hidden="true" tabindex="-1"></a>        prefetch_queries <span class="op">=</span> []</span>
<span id="cb132-42"><a href="#cb132-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> model_name <span class="kw">in</span> high_dim_models:</span>
<span id="cb132-43"><a href="#cb132-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> model_name <span class="kw">in</span> high_dim_query_vectors:</span>
<span id="cb132-44"><a href="#cb132-44" aria-hidden="true" tabindex="-1"></a>                prefetch_queries.append(</span>
<span id="cb132-45"><a href="#cb132-45" aria-hidden="true" tabindex="-1"></a>                    Prefetch(</span>
<span id="cb132-46"><a href="#cb132-46" aria-hidden="true" tabindex="-1"></a>                        query<span class="op">=</span>high_dim_query_vectors[model_name],</span>
<span id="cb132-47"><a href="#cb132-47" aria-hidden="true" tabindex="-1"></a>                        using<span class="op">=</span>model_name,</span>
<span id="cb132-48"><a href="#cb132-48" aria-hidden="true" tabindex="-1"></a>                        limit<span class="op">=</span><span class="dv">20</span>,</span>
<span id="cb132-49"><a href="#cb132-49" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb132-50"><a href="#cb132-50" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb132-51"><a href="#cb132-51" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb132-52"><a href="#cb132-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Only proceed if we have at least one valid prefetch query</span></span>
<span id="cb132-53"><a href="#cb132-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> prefetch_queries:</span>
<span id="cb132-54"><a href="#cb132-54" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Skipping query </span><span class="sc">{</span>query_idx<span class="sc">}</span><span class="ss">: No valid prefetch queries&quot;</span>)</span>
<span id="cb132-55"><a href="#cb132-55" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb132-56"><a href="#cb132-56" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb132-57"><a href="#cb132-57" aria-hidden="true" tabindex="-1"></a>        results <span class="op">=</span> client.query_points(</span>
<span id="cb132-58"><a href="#cb132-58" aria-hidden="true" tabindex="-1"></a>            COLLECTION_NAME,</span>
<span id="cb132-59"><a href="#cb132-59" aria-hidden="true" tabindex="-1"></a>            prefetch<span class="op">=</span>prefetch_queries,</span>
<span id="cb132-60"><a href="#cb132-60" aria-hidden="true" tabindex="-1"></a>            query<span class="op">=</span>FusionQuery(</span>
<span id="cb132-61"><a href="#cb132-61" aria-hidden="true" tabindex="-1"></a>                fusion<span class="op">=</span>Fusion.RRF,</span>
<span id="cb132-62"><a href="#cb132-62" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb132-63"><a href="#cb132-63" aria-hidden="true" tabindex="-1"></a>            with_payload<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb132-64"><a href="#cb132-64" aria-hidden="true" tabindex="-1"></a>            limit<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb132-65"><a href="#cb132-65" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb132-66"><a href="#cb132-66" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb132-67"><a href="#cb132-67" aria-hidden="true" tabindex="-1"></a>        high_dim_fusion_run_dict[query_id] <span class="op">=</span> {</span>
<span id="cb132-68"><a href="#cb132-68" aria-hidden="true" tabindex="-1"></a>            <span class="bu">str</span>(point.<span class="bu">id</span>): point.score</span>
<span id="cb132-69"><a href="#cb132-69" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> point <span class="kw">in</span> results.points</span>
<span id="cb132-70"><a href="#cb132-70" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb132-71"><a href="#cb132-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb132-72"><a href="#cb132-72" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Error with high-dim fusion for query </span><span class="sc">{</span>query_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb132-73"><a href="#cb132-73" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Print more details about the vectors to help diagnose the issue</span></span>
<span id="cb132-74"><a href="#cb132-74" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> model_name, vector <span class="kw">in</span> high_dim_query_vectors.items():</span>
<span id="cb132-75"><a href="#cb132-75" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> vector type: </span><span class="sc">{</span><span class="bu">type</span>(vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb132-76"><a href="#cb132-76" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(vector, <span class="bu">list</span>):</span>
<span id="cb132-77"><a href="#cb132-77" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> vector length: </span><span class="sc">{</span><span class="bu">len</span>(vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb132-78"><a href="#cb132-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">continue</span></span>
<span id="cb132-79"><a href="#cb132-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb132-80"><a href="#cb132-80" aria-hidden="true" tabindex="-1"></a><span class="co"># Only create Run object if we have results</span></span>
<span id="cb132-81"><a href="#cb132-81" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> high_dim_fusion_run_dict:</span>
<span id="cb132-82"><a href="#cb132-82" aria-hidden="true" tabindex="-1"></a>    high_dim_fusion_run <span class="op">=</span> Run(high_dim_fusion_run_dict, name<span class="op">=</span><span class="st">&quot;HighDim_Fusion&quot;</span>)</span>
<span id="cb132-83"><a href="#cb132-83" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb132-84"><a href="#cb132-84" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;No successful queries for high-dimensional fusion, skipping Run creation&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Evaluating fusion of high-dimensional models...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [00:10&lt;00:00, 18.45it/s]
</code></pre>
</div>
</div>
<div id="c8342a75" class="cell code" data-execution_count="52">
<div class="sourceCode" id="cb135"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 9. Evaluate Instructor with Different Prompts</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Evaluating Instructor with different prompts...&quot;</span>)</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>instructor_runs <span class="op">=</span> {}</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-5"><a href="#cb135-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define different instruction prompts for code retrieval</span></span>
<span id="cb135-6"><a href="#cb135-6" aria-hidden="true" tabindex="-1"></a>instruction_prompts <span class="op">=</span> {</span>
<span id="cb135-7"><a href="#cb135-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Basic&quot;</span>: <span class="st">&quot;Represent code for retrieval: &quot;</span>,</span>
<span id="cb135-8"><a href="#cb135-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Detailed&quot;</span>: <span class="st">&quot;Represent this code snippet for semantic code search, focusing on functionality, variable names, and programming patterns: &quot;</span>,</span>
<span id="cb135-9"><a href="#cb135-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Function&quot;</span>: <span class="st">&quot;Represent this code to find similar functions and implementations: &quot;</span>,</span>
<span id="cb135-10"><a href="#cb135-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Documentation&quot;</span>: <span class="st">&quot;Represent this code to match with relevant documentation and usage examples: &quot;</span></span>
<span id="cb135-11"><a href="#cb135-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb135-12"><a href="#cb135-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-13"><a href="#cb135-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Precompute Instructor embeddings with different prompts</span></span>
<span id="cb135-14"><a href="#cb135-14" aria-hidden="true" tabindex="-1"></a>instructor_prompt_embeddings <span class="op">=</span> {}</span>
<span id="cb135-15"><a href="#cb135-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt_name, prompt_text <span class="kw">in</span> instruction_prompts.items():</span>
<span id="cb135-16"><a href="#cb135-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f&quot;Computing Instructor embeddings with </span><span class="sc">{</span>prompt_name<span class="sc">}</span><span class="ss"> prompt...&quot;</span>)</span>
<span id="cb135-17"><a href="#cb135-17" aria-hidden="true" tabindex="-1"></a>    prompt_vectors <span class="op">=</span> []</span>
<span id="cb135-18"><a href="#cb135-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-19"><a href="#cb135-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> query <span class="kw">in</span> tqdm(queries):</span>
<span id="cb135-20"><a href="#cb135-20" aria-hidden="true" tabindex="-1"></a>        query_text <span class="op">=</span> query[<span class="st">&quot;text&quot;</span>]</span>
<span id="cb135-21"><a href="#cb135-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Format with the specific instruction prompt</span></span>
<span id="cb135-22"><a href="#cb135-22" aria-hidden="true" tabindex="-1"></a>        prompt_vector <span class="op">=</span> inf_model.encode([[prompt_text, query_text]])</span>
<span id="cb135-23"><a href="#cb135-23" aria-hidden="true" tabindex="-1"></a>        prompt_vectors.append(prompt_vector)</span>
<span id="cb135-24"><a href="#cb135-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-25"><a href="#cb135-25" aria-hidden="true" tabindex="-1"></a>    instructor_prompt_embeddings[prompt_name] <span class="op">=</span> prompt_vectors</span>
<span id="cb135-26"><a href="#cb135-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb135-27"><a href="#cb135-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate each prompt variation</span></span>
<span id="cb135-28"><a href="#cb135-28" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> prompt_name, prompt_vectors <span class="kw">in</span> instructor_prompt_embeddings.items():</span>
<span id="cb135-29"><a href="#cb135-29" aria-hidden="true" tabindex="-1"></a>    prompt_run_dict <span class="op">=</span> {}</span>
<span id="cb135-30"><a href="#cb135-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-31"><a href="#cb135-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> query_idx, query <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(queries)):</span>
<span id="cb135-32"><a href="#cb135-32" aria-hidden="true" tabindex="-1"></a>        query_id <span class="op">=</span> <span class="bu">str</span>(query[<span class="st">&quot;_id&quot;</span>])</span>
<span id="cb135-33"><a href="#cb135-33" aria-hidden="true" tabindex="-1"></a>        query_vector <span class="op">=</span> prompt_vectors[query_idx]</span>
<span id="cb135-34"><a href="#cb135-34" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb135-35"><a href="#cb135-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">try</span>:</span>
<span id="cb135-36"><a href="#cb135-36" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Fix dimensionality - this is crucial</span></span>
<span id="cb135-37"><a href="#cb135-37" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(query_vector, np.ndarray) <span class="kw">and</span> <span class="bu">len</span>(query_vector.shape) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb135-38"><a href="#cb135-38" aria-hidden="true" tabindex="-1"></a>                <span class="co"># If shape is (1, 3584), flatten to (3584,)</span></span>
<span id="cb135-39"><a href="#cb135-39" aria-hidden="true" tabindex="-1"></a>                query_vector <span class="op">=</span> query_vector.reshape(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb135-40"><a href="#cb135-40" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb135-41"><a href="#cb135-41" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Convert to list for JSON serialization if needed</span></span>
<span id="cb135-42"><a href="#cb135-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(query_vector, np.ndarray):</span>
<span id="cb135-43"><a href="#cb135-43" aria-hidden="true" tabindex="-1"></a>                query_vector <span class="op">=</span> query_vector.tolist()</span>
<span id="cb135-44"><a href="#cb135-44" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb135-45"><a href="#cb135-45" aria-hidden="true" tabindex="-1"></a>            results <span class="op">=</span> client.query_points(</span>
<span id="cb135-46"><a href="#cb135-46" aria-hidden="true" tabindex="-1"></a>                COLLECTION_NAME,</span>
<span id="cb135-47"><a href="#cb135-47" aria-hidden="true" tabindex="-1"></a>                query<span class="op">=</span>query_vector,</span>
<span id="cb135-48"><a href="#cb135-48" aria-hidden="true" tabindex="-1"></a>                using<span class="op">=</span><span class="st">&quot;INF_RETRIEVER_V1&quot;</span>,</span>
<span id="cb135-49"><a href="#cb135-49" aria-hidden="true" tabindex="-1"></a>                with_payload<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb135-50"><a href="#cb135-50" aria-hidden="true" tabindex="-1"></a>                limit<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb135-51"><a href="#cb135-51" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb135-52"><a href="#cb135-52" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb135-53"><a href="#cb135-53" aria-hidden="true" tabindex="-1"></a>            prompt_run_dict[query_id] <span class="op">=</span> {</span>
<span id="cb135-54"><a href="#cb135-54" aria-hidden="true" tabindex="-1"></a>                <span class="bu">str</span>(point.<span class="bu">id</span>): point.score</span>
<span id="cb135-55"><a href="#cb135-55" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> point <span class="kw">in</span> results.points</span>
<span id="cb135-56"><a href="#cb135-56" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb135-57"><a href="#cb135-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb135-58"><a href="#cb135-58" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Error with </span><span class="sc">{</span>prompt_name<span class="sc">}</span><span class="ss"> prompt for query </span><span class="sc">{</span>query_id<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb135-59"><a href="#cb135-59" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Query vector shape: </span><span class="sc">{</span>query_vector<span class="sc">.</span>shape <span class="cf">if</span> <span class="bu">hasattr</span>(query_vector, <span class="st">&#39;shape&#39;</span>) <span class="cf">else</span> <span class="st">&#39;N/A&#39;</span><span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb135-60"><a href="#cb135-60" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Query vector type: </span><span class="sc">{</span><span class="bu">type</span>(query_vector)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb135-61"><a href="#cb135-61" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb135-62"><a href="#cb135-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb135-63"><a href="#cb135-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Only create Run object if we have results</span></span>
<span id="cb135-64"><a href="#cb135-64" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> prompt_run_dict:</span>
<span id="cb135-65"><a href="#cb135-65" aria-hidden="true" tabindex="-1"></a>        instructor_runs[prompt_name] <span class="op">=</span> Run(prompt_run_dict, name<span class="op">=</span><span class="ss">f&quot;Instructor_</span><span class="sc">{</span>prompt_name<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb135-66"><a href="#cb135-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb135-67"><a href="#cb135-67" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;No successful queries for </span><span class="sc">{</span>prompt_name<span class="sc">}</span><span class="ss"> prompt, skipping Run creation&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Evaluating Instructor with different prompts...
Computing Instructor embeddings with Basic prompt...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [07:00&lt;00:00,  2.10s/it]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Computing Instructor embeddings with Detailed prompt...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [09:08&lt;00:00,  2.74s/it]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Computing Instructor embeddings with Function prompt...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [07:49&lt;00:00,  2.35s/it]
</code></pre>
</div>
<div class="output stream stdout">
<pre><code>Computing Instructor embeddings with Documentation prompt...
</code></pre>
</div>
<div class="output stream stderr">
<pre><code>100%|██████████| 200/200 [07:53&lt;00:00,  2.37s/it]
100%|██████████| 200/200 [00:05&lt;00:00, 34.20it/s]
100%|██████████| 200/200 [00:06&lt;00:00, 33.01it/s]
100%|██████████| 200/200 [00:05&lt;00:00, 33.79it/s]
100%|██████████| 200/200 [00:05&lt;00:00, 34.50it/s]
</code></pre>
</div>
</div>
<div id="fa547929" class="cell code" data-execution_count="53">
<div class="sourceCode" id="cb144"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb144-1"><a href="#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 10. Compare All Models and Combinations</span></span>
<span id="cb144-2"><a href="#cb144-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb144-3"><a href="#cb144-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Collect all runs for comparison</span></span>
<span id="cb144-4"><a href="#cb144-4" aria-hidden="true" tabindex="-1"></a>runs_to_compare <span class="op">=</span> (</span>
<span id="cb144-5"><a href="#cb144-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">list</span>(dense_runs.values()) <span class="op">+</span>  <span class="co"># Individual dense models</span></span>
<span id="cb144-6"><a href="#cb144-6" aria-hidden="true" tabindex="-1"></a>    [bm25_run, colbert_run] <span class="op">+</span>    <span class="co"># BM25 and ColBERT</span></span>
<span id="cb144-7"><a href="#cb144-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">list</span>(rrf_runs.values()) <span class="op">+</span>    <span class="co"># Hybrid combinations</span></span>
<span id="cb144-8"><a href="#cb144-8" aria-hidden="true" tabindex="-1"></a>    [high_dim_fusion_run] <span class="op">+</span>      <span class="co"># High-dimensional fusion</span></span>
<span id="cb144-9"><a href="#cb144-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">list</span>(instructor_runs.values()) <span class="op">+</span>  <span class="co"># Instructor with different prompts</span></span>
<span id="cb144-10"><a href="#cb144-10" aria-hidden="true" tabindex="-1"></a>    [full_rrf_run]               <span class="co"># Full fusion</span></span>
<span id="cb144-11"><a href="#cb144-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="f7916b80" class="cell code" data-execution_count="69">
<div class="sourceCode" id="cb145"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define comprehensive metrics</span></span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [<span class="st">&quot;precision@10&quot;</span>, <span class="st">&quot;recall@10&quot;</span>, <span class="st">&quot;mrr@10&quot;</span>, <span class="st">&quot;ndcg@10&quot;</span>]</span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the comparison</span></span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Running comprehensive comparison of all models and combinations...&quot;</span>)</span>
<span id="cb145-6"><a href="#cb145-6" aria-hidden="true" tabindex="-1"></a>comparison_results <span class="op">=</span> compare(</span>
<span id="cb145-7"><a href="#cb145-7" aria-hidden="true" tabindex="-1"></a>    qrels<span class="op">=</span>qrels,</span>
<span id="cb145-8"><a href="#cb145-8" aria-hidden="true" tabindex="-1"></a>    runs<span class="op">=</span>runs_to_compare,</span>
<span id="cb145-9"><a href="#cb145-9" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>metrics,</span>
<span id="cb145-10"><a href="#cb145-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb145-11"><a href="#cb145-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-12"><a href="#cb145-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(comparison_results)</span>
<span id="cb145-13"><a href="#cb145-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-14"><a href="#cb145-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ## 11. Visualize Results</span></span>
<span id="cb145-15"><a href="#cb145-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-16"><a href="#cb145-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb145-17"><a href="#cb145-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb145-18"><a href="#cb145-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb145-19"><a href="#cb145-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-20"><a href="#cb145-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert comparison results to DataFrame for visualization</span></span>
<span id="cb145-21"><a href="#cb145-21" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> comparison_results.to_dataframe()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Running comprehensive comparison of all models and combinations...
#    Model                     P@10            Recall@10       MRR@10    NDCG@10
---  ------------------------  --------------  --------------  --------  ---------
a    E5_dense                  0.013ᵇ۹ᵛ        0.125ᵇ۹ᵛ        0.033ᵇᵒ   0.054ᵇ۹
b    GTE_dense                 0.005           0.050           0.018     0.026
c    BGE_dense                 0.007           0.070           0.018     0.030
d    INF_RETRIEVER_V1_dense    0.009           0.090           0.029     0.043
e    BGE_M3_dense              0.011ᵇ          0.110ᵇ          0.039     0.055ᵇ
f    OpenAI_dense              0.009           0.095           0.024     0.040
g    codellama_dense           0.012ᵇ۹         0.120ᵇ۹         0.029     0.050
h    BM25_sparse               0.014ᵇᶜᵏˡᵒ۹ᵗᵘᵛ  0.145ᵇᶜᵏˡᵒ۹ᵗᵘᵛ  0.031     0.056ᵇᵏˡᵒ
i    ColBERT_late              0.012ᵇ۹         0.115ᵇ۹         0.044ᵇ    0.060ᵇᵏᵒ۹
j    E5+BM25                   0.011           0.105           0.026     0.044
k    GTE+BM25                  0.006           0.060           0.020     0.029
l    BGE+BM25                  0.009           0.085           0.022     0.036
m    INF_RETRIEVER_V1+BM25     0.010           0.100           0.026     0.043
n    BGE_M3+BM25               0.009           0.095           0.031     0.046
o    OpenAI+BM25               0.007           0.070           0.020     0.032
p    codellama+BM25            0.011           0.110           0.028     0.046
q    HighDim_Fusion            0.006           0.055           0.023     0.031
r    Instructor_Basic          0.009           0.090           0.029     0.043
s    Instructor_Detailed       0.008           0.080           0.027     0.039
t    Instructor_Function       0.007           0.065           0.027     0.036
u    Instructor_Documentation  0.007           0.070           0.030     0.039
v    Full_RRF                  0.007           0.070           0.027     0.037
</code></pre>
</div>
</div>
<div id="af702114" class="cell code" data-execution_count="70">
<div class="sourceCode" id="cb147"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb147-4"><a href="#cb147-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-5"><a href="#cb147-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a mapping from numeric indices to descriptive model names</span></span>
<span id="cb147-6"><a href="#cb147-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjust this mapping to match your actual models</span></span>
<span id="cb147-7"><a href="#cb147-7" aria-hidden="true" tabindex="-1"></a>model_mapping <span class="op">=</span> {</span>
<span id="cb147-8"><a href="#cb147-8" aria-hidden="true" tabindex="-1"></a>    <span class="dv">0</span>: <span class="st">&#39;E5_dense&#39;</span>,</span>
<span id="cb147-9"><a href="#cb147-9" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span>: <span class="st">&#39;GTE_dense&#39;</span>,</span>
<span id="cb147-10"><a href="#cb147-10" aria-hidden="true" tabindex="-1"></a>    <span class="dv">2</span>: <span class="st">&#39;BGE_dense&#39;</span>,</span>
<span id="cb147-11"><a href="#cb147-11" aria-hidden="true" tabindex="-1"></a>    <span class="dv">3</span>: <span class="st">&#39;INF_RETRIEVER_V1_dense&#39;</span>,</span>
<span id="cb147-12"><a href="#cb147-12" aria-hidden="true" tabindex="-1"></a>    <span class="dv">4</span>: <span class="st">&#39;BGE_M3_dense&#39;</span>,</span>
<span id="cb147-13"><a href="#cb147-13" aria-hidden="true" tabindex="-1"></a>    <span class="dv">5</span>: <span class="st">&#39;OpenAI_dense&#39;</span>,</span>
<span id="cb147-14"><a href="#cb147-14" aria-hidden="true" tabindex="-1"></a>    <span class="dv">6</span>: <span class="st">&#39;codellama_dense&#39;</span>,</span>
<span id="cb147-15"><a href="#cb147-15" aria-hidden="true" tabindex="-1"></a>    <span class="dv">7</span>: <span class="st">&#39;BM25_sparse&#39;</span>,</span>
<span id="cb147-16"><a href="#cb147-16" aria-hidden="true" tabindex="-1"></a>    <span class="dv">8</span>: <span class="st">&#39;ColBERT_late&#39;</span>,</span>
<span id="cb147-17"><a href="#cb147-17" aria-hidden="true" tabindex="-1"></a>    <span class="dv">9</span>: <span class="st">&#39;E5+BM25&#39;</span>,</span>
<span id="cb147-18"><a href="#cb147-18" aria-hidden="true" tabindex="-1"></a>    <span class="dv">10</span>: <span class="st">&#39;GTE+BM25&#39;</span>,</span>
<span id="cb147-19"><a href="#cb147-19" aria-hidden="true" tabindex="-1"></a>    <span class="dv">11</span>: <span class="st">&#39;BGE+BM25&#39;</span>,</span>
<span id="cb147-20"><a href="#cb147-20" aria-hidden="true" tabindex="-1"></a>    <span class="dv">12</span>: <span class="st">&#39;INF_RETRIEVER_V1+BM25&#39;</span>,</span>
<span id="cb147-21"><a href="#cb147-21" aria-hidden="true" tabindex="-1"></a>    <span class="dv">13</span>: <span class="st">&#39;BGE_M3+BM25&#39;</span>,</span>
<span id="cb147-22"><a href="#cb147-22" aria-hidden="true" tabindex="-1"></a>    <span class="dv">14</span>: <span class="st">&#39;OpenAI+BM25&#39;</span>,</span>
<span id="cb147-23"><a href="#cb147-23" aria-hidden="true" tabindex="-1"></a>    <span class="dv">15</span>: <span class="st">&#39;codellama+BM25&#39;</span>,</span>
<span id="cb147-24"><a href="#cb147-24" aria-hidden="true" tabindex="-1"></a>    <span class="dv">16</span>: <span class="st">&#39;HighDim_Fusion&#39;</span>,</span>
<span id="cb147-25"><a href="#cb147-25" aria-hidden="true" tabindex="-1"></a>    <span class="dv">17</span>: <span class="st">&#39;Instructor_Basic&#39;</span>,</span>
<span id="cb147-26"><a href="#cb147-26" aria-hidden="true" tabindex="-1"></a>    <span class="dv">18</span>: <span class="st">&#39;Instructor_Detailed&#39;</span>,</span>
<span id="cb147-27"><a href="#cb147-27" aria-hidden="true" tabindex="-1"></a>    <span class="dv">19</span>: <span class="st">&#39;Instructor_Function&#39;</span>,</span>
<span id="cb147-28"><a href="#cb147-28" aria-hidden="true" tabindex="-1"></a>    <span class="dv">20</span>: <span class="st">&#39;Instructor_Documentation&#39;</span>,</span>
<span id="cb147-29"><a href="#cb147-29" aria-hidden="true" tabindex="-1"></a>    <span class="dv">21</span>: <span class="st">&#39;Full_RRF&#39;</span></span>
<span id="cb147-30"><a href="#cb147-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb147-31"><a href="#cb147-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-32"><a href="#cb147-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a copy of results_df to avoid modifying the original</span></span>
<span id="cb147-33"><a href="#cb147-33" aria-hidden="true" tabindex="-1"></a>plot_df <span class="op">=</span> results_df.copy()</span>
<span id="cb147-34"><a href="#cb147-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-35"><a href="#cb147-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Add descriptive model names</span></span>
<span id="cb147-36"><a href="#cb147-36" aria-hidden="true" tabindex="-1"></a>plot_df[<span class="st">&#39;Model_Name&#39;</span>] <span class="op">=</span> plot_df[<span class="st">&#39;model_names&#39;</span>].<span class="bu">map</span>(model_mapping)</span>
<span id="cb147-37"><a href="#cb147-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-38"><a href="#cb147-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate overall score with equal weighting</span></span>
<span id="cb147-39"><a href="#cb147-39" aria-hidden="true" tabindex="-1"></a>plot_df[<span class="st">&#39;overall_score&#39;</span>] <span class="op">=</span> (</span>
<span id="cb147-40"><a href="#cb147-40" aria-hidden="true" tabindex="-1"></a>    plot_df[<span class="st">&#39;precision@10&#39;</span>] <span class="op">*</span> <span class="fl">0.25</span> <span class="op">+</span></span>
<span id="cb147-41"><a href="#cb147-41" aria-hidden="true" tabindex="-1"></a>    plot_df[<span class="st">&#39;recall@10&#39;</span>] <span class="op">*</span> <span class="fl">0.25</span> <span class="op">+</span></span>
<span id="cb147-42"><a href="#cb147-42" aria-hidden="true" tabindex="-1"></a>    plot_df[<span class="st">&#39;mrr@10&#39;</span>] <span class="op">*</span> <span class="fl">0.25</span> <span class="op">+</span></span>
<span id="cb147-43"><a href="#cb147-43" aria-hidden="true" tabindex="-1"></a>    plot_df[<span class="st">&#39;ndcg@10&#39;</span>] <span class="op">*</span> <span class="fl">0.25</span></span>
<span id="cb147-44"><a href="#cb147-44" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb147-45"><a href="#cb147-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-46"><a href="#cb147-46" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by overall score</span></span>
<span id="cb147-47"><a href="#cb147-47" aria-hidden="true" tabindex="-1"></a>plot_df <span class="op">=</span> plot_df.sort_values(<span class="st">&#39;overall_score&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb147-48"><a href="#cb147-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-49"><a href="#cb147-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Categorize models</span></span>
<span id="cb147-50"><a href="#cb147-50" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> categorize_model(name):</span>
<span id="cb147-51"><a href="#cb147-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> name <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb147-52"><a href="#cb147-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Other&#39;</span></span>
<span id="cb147-53"><a href="#cb147-53" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb147-54"><a href="#cb147-54" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> <span class="bu">str</span>(name)</span>
<span id="cb147-55"><a href="#cb147-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&#39;E5_dense&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;GTE_dense&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;BGE_dense&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb147-56"><a href="#cb147-56" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;General Dense&#39;</span></span>
<span id="cb147-57"><a href="#cb147-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;INF_RETRIEVER_V1_dense&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;BGE_M3_dense&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;starcoder_dense&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb147-58"><a href="#cb147-58" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Code-Specific Dense&#39;</span></span>
<span id="cb147-59"><a href="#cb147-59" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;OpenAI_dense&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb147-60"><a href="#cb147-60" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Proprietary Dense&#39;</span></span>
<span id="cb147-61"><a href="#cb147-61" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;BM25_sparse&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb147-62"><a href="#cb147-62" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Sparse&#39;</span></span>
<span id="cb147-63"><a href="#cb147-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;ColBERT_late&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb147-64"><a href="#cb147-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Late Interaction&#39;</span></span>
<span id="cb147-65"><a href="#cb147-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;+BM25&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb147-66"><a href="#cb147-66" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Hybrid&#39;</span></span>
<span id="cb147-67"><a href="#cb147-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;Instructor_&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb147-68"><a href="#cb147-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Instruction-Based&#39;</span></span>
<span id="cb147-69"><a href="#cb147-69" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;Fusion&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;RRF&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb147-70"><a href="#cb147-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Fusion&#39;</span></span>
<span id="cb147-71"><a href="#cb147-71" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb147-72"><a href="#cb147-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Other&#39;</span></span>
<span id="cb147-73"><a href="#cb147-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-74"><a href="#cb147-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply categorization</span></span>
<span id="cb147-75"><a href="#cb147-75" aria-hidden="true" tabindex="-1"></a>plot_df[<span class="st">&#39;Category&#39;</span>] <span class="op">=</span> plot_df[<span class="st">&#39;model_names&#39;</span>].<span class="bu">apply</span>(categorize_model)</span>
<span id="cb147-76"><a href="#cb147-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-77"><a href="#cb147-77" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DataFrame for the CSV export</span></span>
<span id="cb147-78"><a href="#cb147-78" aria-hidden="true" tabindex="-1"></a>csv_df <span class="op">=</span> plot_df[[<span class="st">&#39;model_names&#39;</span>, <span class="st">&#39;overall_score&#39;</span>, <span class="st">&#39;precision@10&#39;</span>, <span class="st">&#39;recall@10&#39;</span>, <span class="st">&#39;mrr@10&#39;</span>, <span class="st">&#39;ndcg@10&#39;</span>, <span class="st">&#39;Category&#39;</span>]]</span>
<span id="cb147-79"><a href="#cb147-79" aria-hidden="true" tabindex="-1"></a>csv_df.columns <span class="op">=</span> [<span class="st">&#39;model_names&#39;</span>, <span class="st">&#39;Overall Score&#39;</span>, <span class="st">&#39;Precision@10&#39;</span>, <span class="st">&#39;Recall@10&#39;</span>, <span class="st">&#39;MRR@10&#39;</span>, <span class="st">&#39;NDCG@10&#39;</span>, <span class="st">&#39;Category&#39;</span>]</span>
<span id="cb147-80"><a href="#cb147-80" aria-hidden="true" tabindex="-1"></a>csv_df.insert(<span class="dv">0</span>, <span class="st">&#39;Rank&#39;</span>, <span class="bu">range</span>(<span class="dv">1</span>, <span class="bu">len</span>(csv_df) <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb147-81"><a href="#cb147-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-82"><a href="#cb147-82" aria-hidden="true" tabindex="-1"></a><span class="co"># Save to CSV</span></span>
<span id="cb147-83"><a href="#cb147-83" aria-hidden="true" tabindex="-1"></a>csv_df.to_csv(<span class="st">&#39;embedding_model_comparison.csv&#39;</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb147-84"><a href="#cb147-84" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Results saved to &#39;embedding_model_comparison.csv&#39;&quot;</span>)</span>
<span id="cb147-85"><a href="#cb147-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-86"><a href="#cb147-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb147-87"><a href="#cb147-87" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">10</span>))</span>
<span id="cb147-88"><a href="#cb147-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-89"><a href="#cb147-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Define category colors</span></span>
<span id="cb147-90"><a href="#cb147-90" aria-hidden="true" tabindex="-1"></a>category_colors <span class="op">=</span> {</span>
<span id="cb147-91"><a href="#cb147-91" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;General Dense&#39;</span>: <span class="st">&#39;#1f77b4&#39;</span>,</span>
<span id="cb147-92"><a href="#cb147-92" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Code-Specific Dense&#39;</span>: <span class="st">&#39;#ff7f0e&#39;</span>,</span>
<span id="cb147-93"><a href="#cb147-93" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Proprietary Dense&#39;</span>: <span class="st">&#39;#2ca02c&#39;</span>,</span>
<span id="cb147-94"><a href="#cb147-94" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Sparse&#39;</span>: <span class="st">&#39;#d62728&#39;</span>,</span>
<span id="cb147-95"><a href="#cb147-95" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Late Interaction&#39;</span>: <span class="st">&#39;#9467bd&#39;</span>,</span>
<span id="cb147-96"><a href="#cb147-96" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Hybrid&#39;</span>: <span class="st">&#39;#8c564b&#39;</span>,</span>
<span id="cb147-97"><a href="#cb147-97" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Instruction-Based&#39;</span>: <span class="st">&#39;#e377c2&#39;</span>,</span>
<span id="cb147-98"><a href="#cb147-98" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Fusion&#39;</span>: <span class="st">&#39;#7f7f7f&#39;</span>,</span>
<span id="cb147-99"><a href="#cb147-99" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Other&#39;</span>: <span class="st">&#39;#bcbd22&#39;</span></span>
<span id="cb147-100"><a href="#cb147-100" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb147-101"><a href="#cb147-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-102"><a href="#cb147-102" aria-hidden="true" tabindex="-1"></a><span class="co"># Get colors based on categories</span></span>
<span id="cb147-103"><a href="#cb147-103" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [category_colors.get(cat, <span class="st">&#39;#17becf&#39;</span>) <span class="cf">for</span> cat <span class="kw">in</span> plot_df[<span class="st">&#39;Category&#39;</span>]]</span>
<span id="cb147-104"><a href="#cb147-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-105"><a href="#cb147-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Create positions for bars</span></span>
<span id="cb147-106"><a href="#cb147-106" aria-hidden="true" tabindex="-1"></a>y_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(plot_df))</span>
<span id="cb147-107"><a href="#cb147-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-108"><a href="#cb147-108" aria-hidden="true" tabindex="-1"></a><span class="co"># Create horizontal bar chart</span></span>
<span id="cb147-109"><a href="#cb147-109" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.barh(y_pos, plot_df[<span class="st">&#39;overall_score&#39;</span>], color<span class="op">=</span>colors)</span>
<span id="cb147-110"><a href="#cb147-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-111"><a href="#cb147-111" aria-hidden="true" tabindex="-1"></a><span class="co"># Add value labels to bars</span></span>
<span id="cb147-112"><a href="#cb147-112" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(plot_df[<span class="st">&#39;overall_score&#39;</span>]):</span>
<span id="cb147-113"><a href="#cb147-113" aria-hidden="true" tabindex="-1"></a>    plt.text(v <span class="op">+</span> <span class="fl">0.001</span>, i, <span class="ss">f&#39;</span><span class="sc">{</span>v<span class="sc">:.4f}</span><span class="ss">&#39;</span>, va<span class="op">=</span><span class="st">&#39;center&#39;</span>, fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb147-114"><a href="#cb147-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-115"><a href="#cb147-115" aria-hidden="true" tabindex="-1"></a><span class="co"># Set y-ticks to model names</span></span>
<span id="cb147-116"><a href="#cb147-116" aria-hidden="true" tabindex="-1"></a>plt.yticks(y_pos, plot_df[<span class="st">&#39;model_names&#39;</span>])</span>
<span id="cb147-117"><a href="#cb147-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-118"><a href="#cb147-118" aria-hidden="true" tabindex="-1"></a><span class="co"># Add grid and titles</span></span>
<span id="cb147-119"><a href="#cb147-119" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">&#39;x&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb147-120"><a href="#cb147-120" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Overall Performance of Embedding Models (Combined Metrics)&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb147-121"><a href="#cb147-121" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Overall Score&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb147-122"><a href="#cb147-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-123"><a href="#cb147-123" aria-hidden="true" tabindex="-1"></a><span class="co"># Add legend</span></span>
<span id="cb147-124"><a href="#cb147-124" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.patches <span class="im">import</span> Patch</span>
<span id="cb147-125"><a href="#cb147-125" aria-hidden="true" tabindex="-1"></a>legend_elements <span class="op">=</span> [</span>
<span id="cb147-126"><a href="#cb147-126" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span>color, label<span class="op">=</span>cat) </span>
<span id="cb147-127"><a href="#cb147-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> cat, color <span class="kw">in</span> category_colors.items() </span>
<span id="cb147-128"><a href="#cb147-128" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cat <span class="kw">in</span> plot_df[<span class="st">&#39;Category&#39;</span>].unique()</span>
<span id="cb147-129"><a href="#cb147-129" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb147-130"><a href="#cb147-130" aria-hidden="true" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>legend_elements, title<span class="op">=</span><span class="st">&#39;Model Category&#39;</span>, loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb147-131"><a href="#cb147-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-132"><a href="#cb147-132" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb147-133"><a href="#cb147-133" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;embedding_model_comparison.png&#39;</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">&#39;tight&#39;</span>)</span>
<span id="cb147-134"><a href="#cb147-134" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb147-135"><a href="#cb147-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-136"><a href="#cb147-136" aria-hidden="true" tabindex="-1"></a><span class="co"># Create additional chart showing the individual metrics for top 10 models</span></span>
<span id="cb147-137"><a href="#cb147-137" aria-hidden="true" tabindex="-1"></a>top10_df <span class="op">=</span> plot_df.head(<span class="dv">10</span>).copy()</span>
<span id="cb147-138"><a href="#cb147-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-139"><a href="#cb147-139" aria-hidden="true" tabindex="-1"></a><span class="co"># Melt the DataFrame for easier plotting</span></span>
<span id="cb147-140"><a href="#cb147-140" aria-hidden="true" tabindex="-1"></a>metrics_df <span class="op">=</span> pd.melt(</span>
<span id="cb147-141"><a href="#cb147-141" aria-hidden="true" tabindex="-1"></a>    top10_df, </span>
<span id="cb147-142"><a href="#cb147-142" aria-hidden="true" tabindex="-1"></a>    id_vars<span class="op">=</span>[<span class="st">&#39;model_names&#39;</span>, <span class="st">&#39;Category&#39;</span>],</span>
<span id="cb147-143"><a href="#cb147-143" aria-hidden="true" tabindex="-1"></a>    value_vars<span class="op">=</span>[<span class="st">&#39;precision@10&#39;</span>, <span class="st">&#39;recall@10&#39;</span>, <span class="st">&#39;mrr@10&#39;</span>, <span class="st">&#39;ndcg@10&#39;</span>],</span>
<span id="cb147-144"><a href="#cb147-144" aria-hidden="true" tabindex="-1"></a>    var_name<span class="op">=</span><span class="st">&#39;Metric&#39;</span>, </span>
<span id="cb147-145"><a href="#cb147-145" aria-hidden="true" tabindex="-1"></a>    value_name<span class="op">=</span><span class="st">&#39;Score&#39;</span></span>
<span id="cb147-146"><a href="#cb147-146" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb147-147"><a href="#cb147-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-148"><a href="#cb147-148" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a grouped bar chart</span></span>
<span id="cb147-149"><a href="#cb147-149" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">8</span>))</span>
<span id="cb147-150"><a href="#cb147-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-151"><a href="#cb147-151" aria-hidden="true" tabindex="-1"></a><span class="co"># Get unique metrics and models</span></span>
<span id="cb147-152"><a href="#cb147-152" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> metrics_df[<span class="st">&#39;Metric&#39;</span>].unique()</span>
<span id="cb147-153"><a href="#cb147-153" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> top10_df[<span class="st">&#39;model_names&#39;</span>].values</span>
<span id="cb147-154"><a href="#cb147-154" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(<span class="bu">len</span>(models))</span>
<span id="cb147-155"><a href="#cb147-155" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb147-156"><a href="#cb147-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-157"><a href="#cb147-157" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot each metric as a group of bars</span></span>
<span id="cb147-158"><a href="#cb147-158" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, metric <span class="kw">in</span> <span class="bu">enumerate</span>(metrics):</span>
<span id="cb147-159"><a href="#cb147-159" aria-hidden="true" tabindex="-1"></a>    metric_data <span class="op">=</span> metrics_df[metrics_df[<span class="st">&#39;Metric&#39;</span>] <span class="op">==</span> metric]</span>
<span id="cb147-160"><a href="#cb147-160" aria-hidden="true" tabindex="-1"></a>    plt.bar(x <span class="op">+</span> (i <span class="op">-</span> <span class="fl">1.5</span>) <span class="op">*</span> width, metric_data[<span class="st">&#39;Score&#39;</span>], width, label<span class="op">=</span>metric)</span>
<span id="cb147-161"><a href="#cb147-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-162"><a href="#cb147-162" aria-hidden="true" tabindex="-1"></a><span class="co"># Customize the chart</span></span>
<span id="cb147-163"><a href="#cb147-163" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Model&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb147-164"><a href="#cb147-164" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Score&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb147-165"><a href="#cb147-165" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Performance Metrics for Top 10 Embedding Models&#39;</span>, fontsize<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb147-166"><a href="#cb147-166" aria-hidden="true" tabindex="-1"></a>plt.xticks(x, models, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb147-167"><a href="#cb147-167" aria-hidden="true" tabindex="-1"></a>plt.legend(title<span class="op">=</span><span class="st">&#39;Metric&#39;</span>)</span>
<span id="cb147-168"><a href="#cb147-168" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">&#39;y&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb147-169"><a href="#cb147-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-170"><a href="#cb147-170" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb147-171"><a href="#cb147-171" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;top10_models_metrics.png&#39;</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">&#39;tight&#39;</span>)</span>
<span id="cb147-172"><a href="#cb147-172" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb147-173"><a href="#cb147-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-174"><a href="#cb147-174" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Visualizations saved as &#39;embedding_model_comparison.png&#39; and &#39;top10_models_metrics.png&#39;&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Results saved to &#39;embedding_model_comparison.csv&#39;
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_7f8823aad92e4582b6ad79177749d011/321921fff8c7a1dba7e71ad77758c279109b0883.png" /></p>
</div>
<div class="output display_data">
<p><img
src="vertopal_7f8823aad92e4582b6ad79177749d011/d69007e635653d7db683493a6fe5c4afc05fdddd.png" /></p>
</div>
<div class="output stream stdout">
<pre><code>Visualizations saved as &#39;embedding_model_comparison.png&#39; and &#39;top10_models_metrics.png&#39;
</code></pre>
</div>
</div>
<div id="be7d72a4" class="cell code" data-execution_count="56">
<div class="sourceCode" id="cb150"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Columns in results_df:&quot;</span>, results_df.columns)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Columns in results_df: Index([&#39;model_names&#39;, &#39;precision@10&#39;, &#39;recall@10&#39;, &#39;mrr@10&#39;, &#39;ndcg@10&#39;], dtype=&#39;object&#39;)
</code></pre>
</div>
</div>
<div id="884cbb75" class="cell code" data-execution_count="57">
<div class="sourceCode" id="cb152"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_and_fix_vector_formats(embeddings_dict, model_names):</span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb152-3"><a href="#cb152-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Validates and fixes vector formats for fusion approaches.</span></span>
<span id="cb152-4"><a href="#cb152-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb152-5"><a href="#cb152-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb152-6"><a href="#cb152-6" aria-hidden="true" tabindex="-1"></a><span class="co">        embeddings_dict: Dictionary containing embeddings for different models</span></span>
<span id="cb152-7"><a href="#cb152-7" aria-hidden="true" tabindex="-1"></a><span class="co">        model_names: List of model names to check</span></span>
<span id="cb152-8"><a href="#cb152-8" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb152-9"><a href="#cb152-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb152-10"><a href="#cb152-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Dictionary with fixed embeddings and a report of issues found</span></span>
<span id="cb152-11"><a href="#cb152-11" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb152-12"><a href="#cb152-12" aria-hidden="true" tabindex="-1"></a>    <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb152-13"><a href="#cb152-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb152-14"><a href="#cb152-14" aria-hidden="true" tabindex="-1"></a>    fixed_embeddings <span class="op">=</span> {}</span>
<span id="cb152-15"><a href="#cb152-15" aria-hidden="true" tabindex="-1"></a>    issues_report <span class="op">=</span> {}</span>
<span id="cb152-16"><a href="#cb152-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb152-17"><a href="#cb152-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;Checking vector format consistency...&quot;</span>)</span>
<span id="cb152-18"><a href="#cb152-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb152-19"><a href="#cb152-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check if embeddings is a nested dictionary with &#39;dense_embeddings&#39;</span></span>
<span id="cb152-20"><a href="#cb152-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&#39;dense_embeddings&#39;</span> <span class="kw">in</span> embeddings_dict:</span>
<span id="cb152-21"><a href="#cb152-21" aria-hidden="true" tabindex="-1"></a>        embeddings_to_check <span class="op">=</span> embeddings_dict[<span class="st">&#39;dense_embeddings&#39;</span>]</span>
<span id="cb152-22"><a href="#cb152-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb152-23"><a href="#cb152-23" aria-hidden="true" tabindex="-1"></a>        embeddings_to_check <span class="op">=</span> embeddings_dict</span>
<span id="cb152-24"><a href="#cb152-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb152-25"><a href="#cb152-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name <span class="kw">in</span> model_names:</span>
<span id="cb152-26"><a href="#cb152-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_name <span class="kw">not</span> <span class="kw">in</span> embeddings_to_check:</span>
<span id="cb152-27"><a href="#cb152-27" aria-hidden="true" tabindex="-1"></a>            issues_report[model_name] <span class="op">=</span> <span class="st">&quot;Missing embeddings&quot;</span></span>
<span id="cb152-28"><a href="#cb152-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb152-29"><a href="#cb152-29" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb152-30"><a href="#cb152-30" aria-hidden="true" tabindex="-1"></a>        vectors <span class="op">=</span> embeddings_to_check[model_name]</span>
<span id="cb152-31"><a href="#cb152-31" aria-hidden="true" tabindex="-1"></a>        issues <span class="op">=</span> []</span>
<span id="cb152-32"><a href="#cb152-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb152-33"><a href="#cb152-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check if vectors exist</span></span>
<span id="cb152-34"><a href="#cb152-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> vectors <span class="kw">is</span> <span class="va">None</span> <span class="kw">or</span> <span class="bu">len</span>(vectors) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb152-35"><a href="#cb152-35" aria-hidden="true" tabindex="-1"></a>            issues.append(<span class="st">&quot;Empty vectors&quot;</span>)</span>
<span id="cb152-36"><a href="#cb152-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb152-37"><a href="#cb152-37" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb152-38"><a href="#cb152-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check for None values</span></span>
<span id="cb152-39"><a href="#cb152-39" aria-hidden="true" tabindex="-1"></a>        none_indices <span class="op">=</span> [i <span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(vectors) <span class="cf">if</span> v <span class="kw">is</span> <span class="va">None</span>]</span>
<span id="cb152-40"><a href="#cb152-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> none_indices:</span>
<span id="cb152-41"><a href="#cb152-41" aria-hidden="true" tabindex="-1"></a>            issues.append(<span class="ss">f&quot;None values at indices: </span><span class="sc">{</span>none_indices[:<span class="dv">5</span>]<span class="sc">}</span><span class="ss">...&quot;</span>)</span>
<span id="cb152-42"><a href="#cb152-42" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb152-43"><a href="#cb152-43" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Check dimensionality consistency</span></span>
<span id="cb152-44"><a href="#cb152-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(vectors, <span class="bu">list</span>) <span class="kw">and</span> <span class="bu">all</span>(<span class="bu">isinstance</span>(v, (<span class="bu">list</span>, np.ndarray)) <span class="cf">for</span> v <span class="kw">in</span> vectors <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>):</span>
<span id="cb152-45"><a href="#cb152-45" aria-hidden="true" tabindex="-1"></a>            dims <span class="op">=</span> [<span class="bu">len</span>(v) <span class="cf">for</span> v <span class="kw">in</span> vectors <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> <span class="bu">hasattr</span>(v, <span class="st">&#39;__len__&#39;</span>)]</span>
<span id="cb152-46"><a href="#cb152-46" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> dims <span class="kw">and</span> <span class="bu">len</span>(<span class="bu">set</span>(dims)) <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb152-47"><a href="#cb152-47" aria-hidden="true" tabindex="-1"></a>                issues.append(<span class="ss">f&quot;Inconsistent dimensions: </span><span class="sc">{</span><span class="bu">set</span>(dims)<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb152-48"><a href="#cb152-48" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb152-49"><a href="#cb152-49" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Fix dimensionality issues for specific models</span></span>
<span id="cb152-50"><a href="#cb152-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> model_name <span class="op">==</span> <span class="st">&#39;INF_RETRIEVER_V1&#39;</span> <span class="kw">or</span> <span class="st">&#39;Instructor_&#39;</span> <span class="kw">in</span> model_name:</span>
<span id="cb152-51"><a href="#cb152-51" aria-hidden="true" tabindex="-1"></a>            fixed_vectors <span class="op">=</span> []</span>
<span id="cb152-52"><a href="#cb152-52" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> v <span class="kw">in</span> vectors:</span>
<span id="cb152-53"><a href="#cb152-53" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb152-54"><a href="#cb152-54" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Fix extra dimension issues (shape like [1, X] instead of [X])</span></span>
<span id="cb152-55"><a href="#cb152-55" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> <span class="bu">isinstance</span>(v, np.ndarray) <span class="kw">and</span> <span class="bu">len</span>(v.shape) <span class="op">&gt;</span> <span class="dv">1</span> <span class="kw">and</span> v.shape[<span class="dv">0</span>] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb152-56"><a href="#cb152-56" aria-hidden="true" tabindex="-1"></a>                        fixed_vectors.append(v.reshape(<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb152-57"><a href="#cb152-57" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb152-58"><a href="#cb152-58" aria-hidden="true" tabindex="-1"></a>                        fixed_vectors.append(v)</span>
<span id="cb152-59"><a href="#cb152-59" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb152-60"><a href="#cb152-60" aria-hidden="true" tabindex="-1"></a>                    fixed_vectors.append(<span class="va">None</span>)</span>
<span id="cb152-61"><a href="#cb152-61" aria-hidden="true" tabindex="-1"></a>            vectors <span class="op">=</span> fixed_vectors</span>
<span id="cb152-62"><a href="#cb152-62" aria-hidden="true" tabindex="-1"></a>            issues.append(<span class="st">&quot;Fixed dimensionality issues&quot;</span>)</span>
<span id="cb152-63"><a href="#cb152-63" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb152-64"><a href="#cb152-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Convert all numpy arrays to lists for JSON serialization</span></span>
<span id="cb152-65"><a href="#cb152-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(vectors, <span class="bu">list</span>):</span>
<span id="cb152-66"><a href="#cb152-66" aria-hidden="true" tabindex="-1"></a>            fixed_vectors <span class="op">=</span> []</span>
<span id="cb152-67"><a href="#cb152-67" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> v <span class="kw">in</span> vectors:</span>
<span id="cb152-68"><a href="#cb152-68" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> v <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb152-69"><a href="#cb152-69" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> <span class="bu">isinstance</span>(v, np.ndarray):</span>
<span id="cb152-70"><a href="#cb152-70" aria-hidden="true" tabindex="-1"></a>                        fixed_vectors.append(v.tolist())</span>
<span id="cb152-71"><a href="#cb152-71" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">else</span>:</span>
<span id="cb152-72"><a href="#cb152-72" aria-hidden="true" tabindex="-1"></a>                        fixed_vectors.append(v)</span>
<span id="cb152-73"><a href="#cb152-73" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span>
<span id="cb152-74"><a href="#cb152-74" aria-hidden="true" tabindex="-1"></a>                    fixed_vectors.append(<span class="va">None</span>)</span>
<span id="cb152-75"><a href="#cb152-75" aria-hidden="true" tabindex="-1"></a>            vectors <span class="op">=</span> fixed_vectors</span>
<span id="cb152-76"><a href="#cb152-76" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb152-77"><a href="#cb152-77" aria-hidden="true" tabindex="-1"></a>        fixed_embeddings[model_name] <span class="op">=</span> vectors</span>
<span id="cb152-78"><a href="#cb152-78" aria-hidden="true" tabindex="-1"></a>        issues_report[model_name] <span class="op">=</span> issues <span class="cf">if</span> issues <span class="cf">else</span> <span class="st">&quot;No issues found&quot;</span></span>
<span id="cb152-79"><a href="#cb152-79" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb152-80"><a href="#cb152-80" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print report</span></span>
<span id="cb152-81"><a href="#cb152-81" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">&quot;</span><span class="ch">\n</span><span class="st">Vector format check report:&quot;</span>)</span>
<span id="cb152-82"><a href="#cb152-82" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model, issues <span class="kw">in</span> issues_report.items():</span>
<span id="cb152-83"><a href="#cb152-83" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;</span><span class="sc">{</span>model<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>issues<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb152-84"><a href="#cb152-84" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb152-85"><a href="#cb152-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> fixed_embeddings</span>
<span id="cb152-86"><a href="#cb152-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-87"><a href="#cb152-87" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the function correctly with your nested structure</span></span>
<span id="cb152-88"><a href="#cb152-88" aria-hidden="true" tabindex="-1"></a>fixed_embeddings <span class="op">=</span> check_and_fix_vector_formats(</span>
<span id="cb152-89"><a href="#cb152-89" aria-hidden="true" tabindex="-1"></a>    embeddings, </span>
<span id="cb152-90"><a href="#cb152-90" aria-hidden="true" tabindex="-1"></a>    [<span class="st">&#39;E5&#39;</span>, <span class="st">&#39;GTE&#39;</span>, <span class="st">&#39;BGE&#39;</span>, <span class="st">&#39;INF_RETRIEVER_V1&#39;</span>, <span class="st">&#39;BGE_M3&#39;</span>, <span class="st">&#39;OpenAI&#39;</span>, <span class="st">&#39;codellama&#39;</span>]</span>
<span id="cb152-91"><a href="#cb152-91" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb152-92"><a href="#cb152-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb152-93"><a href="#cb152-93" aria-hidden="true" tabindex="-1"></a><span class="co"># Update your embeddings dictionary correctly</span></span>
<span id="cb152-94"><a href="#cb152-94" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">&#39;dense_embeddings&#39;</span> <span class="kw">in</span> embeddings:</span>
<span id="cb152-95"><a href="#cb152-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model_name, fixed_vectors <span class="kw">in</span> fixed_embeddings.items():</span>
<span id="cb152-96"><a href="#cb152-96" aria-hidden="true" tabindex="-1"></a>        embeddings[<span class="st">&#39;dense_embeddings&#39;</span>][model_name] <span class="op">=</span> fixed_vectors</span>
<span id="cb152-97"><a href="#cb152-97" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb152-98"><a href="#cb152-98" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If not nested, update directly</span></span>
<span id="cb152-99"><a href="#cb152-99" aria-hidden="true" tabindex="-1"></a>    embeddings.update(fixed_embeddings)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Checking vector format consistency...

Vector format check report:
E5: No issues found
GTE: No issues found
BGE: No issues found
INF_RETRIEVER_V1: [&#39;Fixed dimensionality issues&#39;]
BGE_M3: No issues found
OpenAI: No issues found
codellama: No issues found
</code></pre>
</div>
</div>
<div id="ead272c2" class="cell code" data-execution_count="58">
<div class="sourceCode" id="cb154"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define categories for the models based on their names</span></span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> categorize_model(name):</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>    name <span class="op">=</span> <span class="bu">str</span>(name)  <span class="co"># Ensure name is a string</span></span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&#39;E5_dense&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;GTE_dense&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;BGE_dense&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;General Dense&#39;</span></span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;codellama_dense&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;INF_RETRIEVER_V1_dense&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;BGE_M3_dense&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Code-Specific Dense&#39;</span></span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;OpenAI_dense&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Proprietary Dense&#39;</span></span>
<span id="cb154-10"><a href="#cb154-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;BM25_sparse&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb154-11"><a href="#cb154-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Sparse&#39;</span></span>
<span id="cb154-12"><a href="#cb154-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;ColBERT_late&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb154-13"><a href="#cb154-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Late Interaction&#39;</span></span>
<span id="cb154-14"><a href="#cb154-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;+BM25&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb154-15"><a href="#cb154-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Hybrid&#39;</span></span>
<span id="cb154-16"><a href="#cb154-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;Instructor_&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb154-17"><a href="#cb154-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Instruction-Based&#39;</span></span>
<span id="cb154-18"><a href="#cb154-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> <span class="st">&#39;Fusion&#39;</span> <span class="kw">in</span> name <span class="kw">or</span> <span class="st">&#39;RRF&#39;</span> <span class="kw">in</span> name:</span>
<span id="cb154-19"><a href="#cb154-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Fusion&#39;</span></span>
<span id="cb154-20"><a href="#cb154-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb154-21"><a href="#cb154-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">&#39;Other&#39;</span></span>
<span id="cb154-22"><a href="#cb154-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-23"><a href="#cb154-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the categorization</span></span>
<span id="cb154-24"><a href="#cb154-24" aria-hidden="true" tabindex="-1"></a>results_df[<span class="st">&#39;Category&#39;</span>] <span class="op">=</span> results_df[<span class="st">&#39;model_names&#39;</span>].<span class="bu">apply</span>(categorize_model)</span></code></pre></div>
</div>
<div id="3e5b2f91" class="cell code" data-execution_count="59">
<div class="sourceCode" id="cb155"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb155-2"><a href="#cb155-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.patches <span class="im">import</span> Patch</span>
<span id="cb155-3"><a href="#cb155-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-4"><a href="#cb155-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the original results</span></span>
<span id="cb155-5"><a href="#cb155-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">8</span>))</span>
<span id="cb155-6"><a href="#cb155-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-7"><a href="#cb155-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by performance</span></span>
<span id="cb155-8"><a href="#cb155-8" aria-hidden="true" tabindex="-1"></a>results_df <span class="op">=</span> results_df.sort_values(<span class="st">&#39;ndcg@10&#39;</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb155-9"><a href="#cb155-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-10"><a href="#cb155-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Define colors based on category</span></span>
<span id="cb155-11"><a href="#cb155-11" aria-hidden="true" tabindex="-1"></a>category_colors <span class="op">=</span> {</span>
<span id="cb155-12"><a href="#cb155-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;General Dense&#39;</span>: <span class="st">&#39;#1f77b4&#39;</span>,</span>
<span id="cb155-13"><a href="#cb155-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Code-Specific Dense&#39;</span>: <span class="st">&#39;#ff7f0e&#39;</span>,</span>
<span id="cb155-14"><a href="#cb155-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Proprietary Dense&#39;</span>: <span class="st">&#39;#2ca02c&#39;</span>,</span>
<span id="cb155-15"><a href="#cb155-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Sparse&#39;</span>: <span class="st">&#39;#d62728&#39;</span>,</span>
<span id="cb155-16"><a href="#cb155-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Late Interaction&#39;</span>: <span class="st">&#39;#9467bd&#39;</span>,</span>
<span id="cb155-17"><a href="#cb155-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Hybrid&#39;</span>: <span class="st">&#39;#8c564b&#39;</span>,</span>
<span id="cb155-18"><a href="#cb155-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Instruction-Based&#39;</span>: <span class="st">&#39;#e377c2&#39;</span>,</span>
<span id="cb155-19"><a href="#cb155-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Fusion&#39;</span>: <span class="st">&#39;#7f7f7f&#39;</span>,</span>
<span id="cb155-20"><a href="#cb155-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Other&#39;</span>: <span class="st">&#39;#17becf&#39;</span></span>
<span id="cb155-21"><a href="#cb155-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb155-22"><a href="#cb155-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-23"><a href="#cb155-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Get colors for each bar</span></span>
<span id="cb155-24"><a href="#cb155-24" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [category_colors.get(cat, <span class="st">&#39;#17becf&#39;</span>) <span class="cf">for</span> cat <span class="kw">in</span> results_df[<span class="st">&#39;Category&#39;</span>]]</span>
<span id="cb155-25"><a href="#cb155-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-26"><a href="#cb155-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create bar chart</span></span>
<span id="cb155-27"><a href="#cb155-27" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(<span class="bu">range</span>(<span class="bu">len</span>(results_df)), results_df[<span class="st">&#39;ndcg@10&#39;</span>], color<span class="op">=</span>colors)</span>
<span id="cb155-28"><a href="#cb155-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-29"><a href="#cb155-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Add value labels</span></span>
<span id="cb155-30"><a href="#cb155-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, v <span class="kw">in</span> <span class="bu">enumerate</span>(results_df[<span class="st">&#39;ndcg@10&#39;</span>]):</span>
<span id="cb155-31"><a href="#cb155-31" aria-hidden="true" tabindex="-1"></a>    plt.text(i, v <span class="op">+</span> <span class="fl">0.001</span>, <span class="ss">f&#39;</span><span class="sc">{</span>v<span class="sc">:.3f}</span><span class="ss">&#39;</span>, ha<span class="op">=</span><span class="st">&#39;center&#39;</span>, va<span class="op">=</span><span class="st">&#39;bottom&#39;</span>, fontsize<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb155-32"><a href="#cb155-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-33"><a href="#cb155-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Set x-tick labels to model names</span></span>
<span id="cb155-34"><a href="#cb155-34" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(results_df)), results_df[<span class="st">&#39;model_names&#39;</span>], rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb155-35"><a href="#cb155-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-36"><a href="#cb155-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Add grid, titles</span></span>
<span id="cb155-37"><a href="#cb155-37" aria-hidden="true" tabindex="-1"></a>plt.grid(axis<span class="op">=</span><span class="st">&#39;y&#39;</span>, linestyle<span class="op">=</span><span class="st">&#39;--&#39;</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb155-38"><a href="#cb155-38" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Current NDCG@10 Scores for All Models&#39;</span>, fontsize<span class="op">=</span><span class="dv">14</span>)</span>
<span id="cb155-39"><a href="#cb155-39" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;NDCG@10 Score&#39;</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb155-40"><a href="#cb155-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-41"><a href="#cb155-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Add legend</span></span>
<span id="cb155-42"><a href="#cb155-42" aria-hidden="true" tabindex="-1"></a>legend_elements <span class="op">=</span> [</span>
<span id="cb155-43"><a href="#cb155-43" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span>color, label<span class="op">=</span>cat) </span>
<span id="cb155-44"><a href="#cb155-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> cat, color <span class="kw">in</span> category_colors.items() </span>
<span id="cb155-45"><a href="#cb155-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> cat <span class="kw">in</span> results_df[<span class="st">&#39;Category&#39;</span>].unique()</span>
<span id="cb155-46"><a href="#cb155-46" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb155-47"><a href="#cb155-47" aria-hidden="true" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>legend_elements, title<span class="op">=</span><span class="st">&#39;Model Category&#39;</span>, loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</span>
<span id="cb155-48"><a href="#cb155-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-49"><a href="#cb155-49" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb155-50"><a href="#cb155-50" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">&#39;current_model_results.png&#39;</span>, dpi<span class="op">=</span><span class="dv">300</span>, bbox_inches<span class="op">=</span><span class="st">&#39;tight&#39;</span>)</span>
<span id="cb155-51"><a href="#cb155-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_7f8823aad92e4582b6ad79177749d011/92e61c24d9a279a93f8e995227ddc3da43e7ff23.png" /></p>
</div>
</div>
<div id="7e1c299a" class="cell code">
<div class="sourceCode" id="cb156"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div id="ace9c022" class="cell code">
<div class="sourceCode" id="cb157"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div id="3d557ca3" class="cell code">
<div class="sourceCode" id="cb158"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div id="c57c8773" class="cell code">
<div class="sourceCode" id="cb159"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
